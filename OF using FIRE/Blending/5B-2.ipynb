{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dc06b17-fcee-4505-bd74-d98376ce3ed9",
   "metadata": {},
   "source": [
    "# Train Blending (BERT cased, DistilBERT uncased, DeBERTa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed25c7a-5ad2-4d0f-855d-82f4aa671e0e",
   "metadata": {},
   "source": [
    "Best F1 score BERT model on HS_C dataset are used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d841c17f-f52e-4124-b37b-c3b3fb714be4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T07:52:51.030162Z",
     "iopub.status.busy": "2024-09-17T07:52:51.030099Z",
     "iopub.status.idle": "2024-09-17T07:52:51.141539Z",
     "shell.execute_reply": "2024-09-17T07:52:51.141253Z",
     "shell.execute_reply.started": "2024-09-17T07:52:51.030155Z"
    }
   },
   "outputs": [],
   "source": [
    "# This automates data tabulation onto google sheets \n",
    "\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "import os\n",
    "\n",
    "# new directory path\n",
    "new_directory = '/Users/levan/ATENEO MASTERAL/Thesis'\n",
    "\n",
    "# Change the current working directory\n",
    "os.chdir(new_directory)\n",
    "\n",
    "# Use creds to create a client to interact with the Google Drive API\n",
    "scope = ['https://spreadsheets.google.com/feeds','https://www.googleapis.com/auth/drive']\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_name('thesis-432315-12daec8d1ff6.json', scope)\n",
    "\n",
    "service = build('sheets', 'v4', credentials=creds)\n",
    "\n",
    "client = gspread.authorize(creds)\n",
    "\n",
    "spreadsheet_id = '13Fk5oXX9B_mdHmNpMKQMy29y9iiHWrgQCa4hUTiQKD0' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d70bdb-0504-41ef-913d-e4b7f778f561",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7b193db-3f30-4e5f-a38b-c254bf1e1976",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T07:52:51.142020Z",
     "iopub.status.busy": "2024-09-17T07:52:51.141932Z",
     "iopub.status.idle": "2024-09-17T07:52:52.848495Z",
     "shell.execute_reply": "2024-09-17T07:52:52.848208Z",
     "shell.execute_reply.started": "2024-09-17T07:52:51.142013Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AutoConfig\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_recall_curve, f1_score, confusion_matrix, precision_score, recall_score, accuracy_score\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "# new directory path\n",
    "new_directory = '/Users/levan/ATENEO MASTERAL/Thesis/Development'\n",
    "\n",
    "# Change the current working directory\n",
    "os.chdir(new_directory)\n",
    "\n",
    "# Adjust file paths to local system\n",
    "file_path = 'Corpus/FiReCS/FiReCS_data_b.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Split the data\n",
    "holdout_df, test_df = train_test_split(df, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a307e67b-00c3-47aa-8f83-34bc62c93f83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-11T10:08:58.783500Z",
     "iopub.status.busy": "2024-04-11T10:08:58.782872Z",
     "iopub.status.idle": "2024-04-11T10:08:58.788089Z",
     "shell.execute_reply": "2024-04-11T10:08:58.787147Z",
     "shell.execute_reply.started": "2024-04-11T10:08:58.783465Z"
    }
   },
   "source": [
    "## Load Models and Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e666f7e-9db0-4666-a112-2af127307162",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T07:52:52.849054Z",
     "iopub.status.busy": "2024-09-17T07:52:52.848956Z",
     "iopub.status.idle": "2024-09-17T07:52:57.460224Z",
     "shell.execute_reply": "2024-09-17T07:52:57.459726Z",
     "shell.execute_reply.started": "2024-09-17T07:52:52.849047Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_model_and_tokenizer(model_path, tokenizer_path, base_model):\n",
    "    # Load the tokenizer from the local directory\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "    \n",
    "    # Load the configuration from the base model\n",
    "    config = AutoConfig.from_pretrained(base_model, num_labels=3)\n",
    "\n",
    "    # Initialize the model with the configuration\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_path, config=config)\n",
    "\n",
    "    # Ensure the model is in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    return model, tokenizer\n",
    "\n",
    "model_info = {\n",
    "\n",
    "    'DistilBERT cased': {\n",
    "        'model_path': 'BERT models/1 FiReCS/fire_distilbert-base-cased-finetuned',\n",
    "        'tokenizer_path': 'BERT models/1 FiReCS/fire_distilbert-base-cased-finetuned',\n",
    "        'base_model': 'distilbert/distilbert-base-cased'\n",
    "    },\n",
    "\n",
    "    'DeBERTa': {\n",
    "        'model_path': 'BERT models/1 FiReCS/fire_DeBERTa-finetuned',\n",
    "        'tokenizer_path': 'BERT models/1 FiReCS/fire_DeBERTa-finetuned',\n",
    "        'base_model': 'microsoft/deberta-v3-base'\n",
    "    },\n",
    "\n",
    "    'HateBERT': {\n",
    "        'model_path': 'BERT models/1 FiReCS/fire_HateBERT-finetuned',\n",
    "        'tokenizer_path': 'BERT models/1 FiReCS/fire_HateBERT-finetuned',\n",
    "        'base_model': 'GroNLP/hateBERT'\n",
    "    },\n",
    "\n",
    "    'BERT cased': {\n",
    "        'model_path': 'BERT models/1 FiReCS/fire_bert-base-cased-finetuned',\n",
    "        'tokenizer_path': 'BERT models/1 FiReCS/fire_bert-base-cased-finetuned',\n",
    "        'base_model': 'google-bert/bert-base-cased'\n",
    "    },\n",
    "\n",
    "    'Roberta Tag cased': {\n",
    "        'model_path': 'BERT models/1 FiReCS/fire_Tag-Roberta-finetuned',\n",
    "        'tokenizer_path': 'BERT models/1 FiReCS/fire_Tag-Roberta-finetuned',\n",
    "        'base_model': 'jcblaise/roberta-tagalog-base'\n",
    "    },\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "models_and_tokenizers = {name: load_model_and_tokenizer(info['model_path'], \n",
    "                                                        info['tokenizer_path'], \n",
    "                                                        info['base_model']) \n",
    "                         for name, info in model_info.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a9b906-a837-4de8-b8a2-05aa44074c5c",
   "metadata": {},
   "source": [
    "## Apply Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be4981ce-3268-449d-9cb4-6ba780177756",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T07:52:57.461213Z",
     "iopub.status.busy": "2024-09-17T07:52:57.460965Z",
     "iopub.status.idle": "2024-09-17T07:52:57.463542Z",
     "shell.execute_reply": "2024-09-17T07:52:57.463291Z",
     "shell.execute_reply.started": "2024-09-17T07:52:57.461204Z"
    }
   },
   "outputs": [],
   "source": [
    "def texts_to_dataloader(texts, tokenizer, batch_size=32):\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    encodings = tokenizer(texts, truncation=True, padding=True, max_length=512, return_tensors=\"pt\")\n",
    "    \n",
    "    dataset = TensorDataset(encodings['input_ids'], encodings['attention_mask'])\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d574483-f790-48ba-a7d0-07cc8f2973d4",
   "metadata": {},
   "source": [
    "## Perform Blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5beaf28b-e640-41ad-9ce1-388389309ae9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T07:52:57.463984Z",
     "iopub.status.busy": "2024-09-17T07:52:57.463917Z",
     "iopub.status.idle": "2024-09-17T07:52:57.472930Z",
     "shell.execute_reply": "2024-09-17T07:52:57.472577Z",
     "shell.execute_reply.started": "2024-09-17T07:52:57.463978Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89d13637-7546-4338-8e57-cde7377a7c97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T07:52:57.475473Z",
     "iopub.status.busy": "2024-09-17T07:52:57.475338Z",
     "iopub.status.idle": "2024-09-17T07:54:35.394336Z",
     "shell.execute_reply": "2024-09-17T07:54:35.394015Z",
     "shell.execute_reply.started": "2024-09-17T07:52:57.475462Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1613.73 MiB, increment: 109.72 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "\n",
    "def get_meta_features(model, tokenizer, df, device):\n",
    "    texts = df['review'].tolist()\n",
    "    dataloader = texts_to_dataloader(texts, tokenizer, batch_size=32)\n",
    "    \n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    meta_features = []\n",
    "    with torch.no_grad():\n",
    "        for input_ids, attention_mask in dataloader:\n",
    "            input_ids, attention_mask = input_ids.to(device), attention_mask.to(device)\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            probs = F.softmax(outputs.logits, dim=1)\n",
    "            meta_features.append(probs.cpu().numpy())\n",
    "    return np.concatenate(meta_features)\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# Generate meta-features for holdout and test sets\n",
    "holdout_meta_features = [get_meta_features(model, tokenizer, holdout_df, device) for model, tokenizer in models_and_tokenizers.values()]\n",
    "test_meta_features = [get_meta_features(model, tokenizer, test_df, device) for model, tokenizer in models_and_tokenizers.values()]\n",
    "\n",
    "# Stack meta-features\n",
    "holdout_meta_features = np.hstack(holdout_meta_features)\n",
    "test_meta_features = np.hstack(test_meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdae5044-793a-494c-b9f9-0c90839f854b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T07:54:35.395702Z",
     "iopub.status.busy": "2024-09-17T07:54:35.395627Z",
     "iopub.status.idle": "2024-09-17T07:55:00.312529Z",
     "shell.execute_reply": "2024-09-17T07:55:00.312209Z",
     "shell.execute_reply.started": "2024-09-17T07:54:35.395696Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking base model predictions for DistilBERT cased...\n",
      "Predictions distribution: [0.3628004  0.27689946 0.36030024]\n",
      "Checking base model predictions for DeBERTa...\n",
      "Predictions distribution: [0.33203426 0.3266011  0.34136456]\n",
      "Checking base model predictions for HateBERT...\n",
      "Predictions distribution: [0.29686573 0.38674074 0.31639358]\n",
      "Checking base model predictions for BERT cased...\n",
      "Predictions distribution: [0.34362876 0.36963773 0.28673354]\n",
      "Checking base model predictions for Roberta Tag cased...\n",
      "Predictions distribution: [0.29041162 0.42791063 0.28167725]\n"
     ]
    }
   ],
   "source": [
    "# Check the base model predictions\n",
    "for name, (model, tokenizer) in models_and_tokenizers.items():\n",
    "    print(f\"Checking base model predictions for {name}...\")\n",
    "    base_model_preds = get_meta_features(model, tokenizer, test_df, device)\n",
    "    print(\"Predictions distribution:\", np.mean(base_model_preds, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4add97-1099-4447-aa88-e4cfbff99e10",
   "metadata": {},
   "source": [
    "### Train LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66cb131a-a14d-4bf5-9508-59951ea5deb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T07:55:00.313170Z",
     "iopub.status.busy": "2024-09-17T07:55:00.313087Z",
     "iopub.status.idle": "2024-09-17T07:55:01.077979Z",
     "shell.execute_reply": "2024-09-17T07:55:01.077608Z",
     "shell.execute_reply.started": "2024-09-17T07:55:00.313163Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1157.80 MiB, increment: 1.45 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "# Train the LR meta-classifier\n",
    "lr_meta_classifier = LogisticRegression()\n",
    "lr_meta_classifier.fit(holdout_meta_features, holdout_df['label'].values)\n",
    "\n",
    "lr_final_predictions = lr_meta_classifier.predict(test_meta_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa369d0-24ed-448a-be71-a88956188cb5",
   "metadata": {},
   "source": [
    "### Train NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ba1d864-f4eb-426a-92fb-5a88061d87c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T07:55:01.078689Z",
     "iopub.status.busy": "2024-09-17T07:55:01.078594Z",
     "iopub.status.idle": "2024-09-17T07:55:02.442717Z",
     "shell.execute_reply": "2024-09-17T07:55:02.442389Z",
     "shell.execute_reply.started": "2024-09-17T07:55:01.078681Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1157.88 MiB, increment: 0.06 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "# Train the NB meta-classifier\n",
    "nb_meta_classifier = GaussianNB()\n",
    "nb_meta_classifier.fit(holdout_meta_features, holdout_df['label'].values)\n",
    "\n",
    "nb_final_predictions = nb_meta_classifier.predict(test_meta_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8027b313-ee9e-4799-8b8c-01280f99815c",
   "metadata": {},
   "source": [
    "### Train DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "301edb53-18a6-41bc-ab03-f1c714a4ae0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T07:55:02.443427Z",
     "iopub.status.busy": "2024-09-17T07:55:02.443328Z",
     "iopub.status.idle": "2024-09-17T07:55:03.035192Z",
     "shell.execute_reply": "2024-09-17T07:55:03.034830Z",
     "shell.execute_reply.started": "2024-09-17T07:55:02.443419Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1158.20 MiB, increment: 0.31 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "# Train the DT meta-classifier\n",
    "dt_meta_classifier = DecisionTreeClassifier(max_depth=None)  \n",
    "dt_meta_classifier.fit(holdout_meta_features, holdout_df['label'].values)\n",
    "\n",
    "dt_final_predictions = dt_meta_classifier.predict(test_meta_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9904b9-f678-4a2a-b8a5-6e4af9d5b8e1",
   "metadata": {},
   "source": [
    "### Train SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87e4db68-5d39-4459-8e47-b1ed2033f743",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T07:55:03.035871Z",
     "iopub.status.busy": "2024-09-17T07:55:03.035790Z",
     "iopub.status.idle": "2024-09-17T07:55:03.657742Z",
     "shell.execute_reply": "2024-09-17T07:55:03.657397Z",
     "shell.execute_reply.started": "2024-09-17T07:55:03.035863Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1169.56 MiB, increment: 11.36 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "# Train the SVM meta-classifier\n",
    "svm_meta_classifier = SVC(kernel='linear', probability=True)\n",
    "svm_meta_classifier.fit(holdout_meta_features, holdout_df['label'].values)\n",
    "\n",
    "svm_final_predictions = svm_meta_classifier.predict(test_meta_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a902e13a-e9ad-4e5c-8bde-97119c5ebc88",
   "metadata": {},
   "source": [
    "## Evaluate Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1dd5cf-d1fd-4837-80b6-01641a4a4823",
   "metadata": {},
   "source": [
    "### LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20019879-4510-487b-b378-92b49756d548",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T07:55:03.658444Z",
     "iopub.status.busy": "2024-09-17T07:55:03.658349Z",
     "iopub.status.idle": "2024-09-17T07:55:03.664300Z",
     "shell.execute_reply": "2024-09-17T07:55:03.664087Z",
     "shell.execute_reply.started": "2024-09-17T07:55:03.658436Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Precision: 0.8191\n",
      "Recall: 0.8173\n",
      "Ensemble accuracy: 0.8157\n",
      "F1 Score: 0.8181\n",
      "Confusion Matrix:\n",
      "[[396  78   1]\n",
      " [ 76 369  46]\n",
      " [  7  53 390]]\n"
     ]
    }
   ],
   "source": [
    "lr_final_predictions = lr_meta_classifier.predict(test_meta_features)\n",
    "\n",
    "# Evaluate\n",
    "precision = precision_score(test_df['label'].values, lr_final_predictions, average='macro')\n",
    "recall = recall_score(test_df['label'].values, lr_final_predictions, average='macro')\n",
    "accuracy = accuracy_score(test_df['label'].values, lr_final_predictions)\n",
    "f1 = f1_score(test_df['label'].values, lr_final_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(test_df['label'].values, lr_final_predictions)\n",
    "\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Ensemble accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73bdca4b-3649-4046-83f8-34233902b4cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T07:55:03.664728Z",
     "iopub.status.busy": "2024-09-17T07:55:03.664659Z",
     "iopub.status.idle": "2024-09-17T07:55:03.674589Z",
     "shell.execute_reply": "2024-09-17T07:55:03.674377Z",
     "shell.execute_reply.started": "2024-09-17T07:55:03.664723Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized thresholds for each class: [0.2847189886207234, 0.21041838594991225, 0.3871452849818187]\n",
      "Logistic Regression\n",
      "Precision: 0.8191\n",
      "Recall: 0.8173\n",
      "Ensemble accuracy: 0.8157\n",
      "F1 Score: 0.8180865528441243\n",
      "Confusion Matrix:\n",
      "[[396  78   1]\n",
      " [ 76 369  46]\n",
      " [  7  53 390]]\n"
     ]
    }
   ],
   "source": [
    "probabilities = lr_meta_classifier.predict_proba(test_meta_features)\n",
    "\n",
    "# Calculate precision-recall curve and find optimal thresholds for each class\n",
    "lr_thresh = []\n",
    "for i in range(probabilities.shape[1]):  # Iterate over each class\n",
    "    precision, recall, thresholds = precision_recall_curve(test_df['label'].values == i, probabilities[:, i])\n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "    optimal_idx = np.nanargmax(f1_scores)  # Handle cases where precision and recall are both zero\n",
    "    lr_thresh.append(thresholds[optimal_idx])\n",
    "\n",
    "# Apply the optimized thresholds to make adjusted predictions\n",
    "adjusted_predictions = np.array([np.argmax([probabilities[i, j] if probabilities[i, j] >= lr_thresh[j] else 0\n",
    "                                         for j in range(probabilities.shape[1])])\n",
    "                              for i in range(len(probabilities))])\n",
    "\n",
    "# Evaluate\n",
    "adjusted_precision = precision_score(test_df['label'].values, adjusted_predictions, average='macro')\n",
    "adjusted_recall = recall_score(test_df['label'].values, adjusted_predictions, average='macro')\n",
    "adjusted_accuracy = accuracy_score(test_df['label'].values, adjusted_predictions)\n",
    "adjusted_f1 = f1_score(test_df['label'].values, adjusted_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(test_df['label'].values, adjusted_predictions)\n",
    "\n",
    "print(\"Optimized thresholds for each class:\", lr_thresh)\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Precision: {adjusted_precision:.4f}\")\n",
    "print(f\"Recall: {adjusted_recall:.4f}\")\n",
    "print(f\"Ensemble accuracy: {adjusted_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {adjusted_f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b32c3ed1-b3f1-445b-bd78-9047bc433e7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T07:55:03.675189Z",
     "iopub.status.busy": "2024-09-17T07:55:03.675066Z",
     "iopub.status.idle": "2024-09-17T07:55:04.493429Z",
     "shell.execute_reply": "2024-09-17T07:55:04.492385Z",
     "shell.execute_reply.started": "2024-09-17T07:55:03.675182Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated cells count: 4\n"
     ]
    }
   ],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '5-2!B8:E8'  \n",
    "\n",
    "values = [[\n",
    "    f\"{adjusted_precision * 100:.2f}\",\n",
    "    f\"{adjusted_recall * 100:.2f}\",\n",
    "    f\"{adjusted_accuracy * 100:.2f}\",\n",
    "    f\"{adjusted_f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8803f8a-f44a-40f3-bed3-6a137f6a8ced",
   "metadata": {},
   "source": [
    "### NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f816faf-f1a2-4474-9e56-7cb303b3611f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T07:55:04.496630Z",
     "iopub.status.busy": "2024-09-17T07:55:04.496252Z",
     "iopub.status.idle": "2024-09-17T07:55:04.516032Z",
     "shell.execute_reply": "2024-09-17T07:55:04.514959Z",
     "shell.execute_reply.started": "2024-09-17T07:55:04.496608Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes\n",
      "Precision: 0.8162\n",
      "Recall: 0.8146458474768048\n",
      "Ensemble accuracy: 0.8129\n",
      "F1 Score: 0.8153\n",
      "Confusion Matrix:\n",
      "[[399  76   0]\n",
      " [ 83 362  46]\n",
      " [  3  57 390]]\n"
     ]
    }
   ],
   "source": [
    "nb_final_predictions = nb_meta_classifier.predict(test_meta_features)\n",
    "\n",
    "# Evaluate\n",
    "precision = precision_score(test_df['label'].values, nb_final_predictions, average='macro')\n",
    "recall = recall_score(test_df['label'].values, nb_final_predictions, average='macro')\n",
    "accuracy = accuracy_score(test_df['label'].values, nb_final_predictions)\n",
    "f1 = f1_score(test_df['label'].values, nb_final_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(test_df['label'].values, nb_final_predictions)\n",
    "\n",
    "print(\"Naive Bayes\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Ensemble accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd5e6dd9-2846-4fa3-bbb9-ff92060e4ead",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T07:55:04.517149Z",
     "iopub.status.busy": "2024-09-17T07:55:04.517003Z",
     "iopub.status.idle": "2024-09-17T07:55:04.531956Z",
     "shell.execute_reply": "2024-09-17T07:55:04.531342Z",
     "shell.execute_reply.started": "2024-09-17T07:55:04.517137Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized thresholds for each class: [0.006524526989390554, 2.5311525971457893e-10, 3.56782714018465e-05]\n",
      "Logistic Regression\n",
      "Precision: 0.8162\n",
      "Recall: 0.8146\n",
      "Ensemble accuracy: 0.8129\n",
      "F1 Score: 0.8152970308929985\n",
      "Confusion Matrix:\n",
      "[[399  76   0]\n",
      " [ 83 362  46]\n",
      " [  3  57 390]]\n"
     ]
    }
   ],
   "source": [
    "probabilities = nb_meta_classifier.predict_proba(test_meta_features)\n",
    "\n",
    "# Calculate precision-recall curve and find optimal thresholds for each class\n",
    "nb_thresh = []\n",
    "for i in range(probabilities.shape[1]):  # Iterate over each class\n",
    "    precision, recall, thresholds = precision_recall_curve(test_df['label'].values == i, probabilities[:, i])\n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "    optimal_idx = np.nanargmax(f1_scores)  # Handle cases where precision and recall are both zero\n",
    "    nb_thresh.append(thresholds[optimal_idx])\n",
    "\n",
    "# Apply the optimized thresholds to make adjusted predictions\n",
    "adjusted_predictions = np.array([np.argmax([probabilities[i, j] if probabilities[i, j] >= nb_thresh[j] else 0\n",
    "                                         for j in range(probabilities.shape[1])])\n",
    "                              for i in range(len(probabilities))])\n",
    "\n",
    "# Evaluate\n",
    "adjusted_precision = precision_score(test_df['label'].values, adjusted_predictions, average='macro')\n",
    "adjusted_recall = recall_score(test_df['label'].values, adjusted_predictions, average='macro')\n",
    "adjusted_accuracy = accuracy_score(test_df['label'].values, adjusted_predictions)\n",
    "adjusted_f1 = f1_score(test_df['label'].values, adjusted_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(test_df['label'].values, adjusted_predictions)\n",
    "\n",
    "print(\"Optimized thresholds for each class:\", nb_thresh)\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Precision: {adjusted_precision:.4f}\")\n",
    "print(f\"Recall: {adjusted_recall:.4f}\")\n",
    "print(f\"Ensemble accuracy: {adjusted_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {adjusted_f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4909900-8aeb-498f-a1c2-ebecf3dd7eb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T07:55:04.532749Z",
     "iopub.status.busy": "2024-09-17T07:55:04.532619Z",
     "iopub.status.idle": "2024-09-17T07:55:04.855308Z",
     "shell.execute_reply": "2024-09-17T07:55:04.853620Z",
     "shell.execute_reply.started": "2024-09-17T07:55:04.532741Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated cells count: 4\n"
     ]
    }
   ],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '5-2!B9:E9'  \n",
    "\n",
    "values = [[\n",
    "    f\"{adjusted_precision * 100:.2f}\",\n",
    "    f\"{adjusted_recall * 100:.2f}\",\n",
    "    f\"{adjusted_accuracy * 100:.2f}\",\n",
    "    f\"{adjusted_f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92b519a-7274-4651-8707-33c5e2ce81f7",
   "metadata": {},
   "source": [
    "### DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "112a6839-2256-4652-8923-5a8204fa3d51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T07:55:04.862104Z",
     "iopub.status.busy": "2024-09-17T07:55:04.860915Z",
     "iopub.status.idle": "2024-09-17T07:55:04.878873Z",
     "shell.execute_reply": "2024-09-17T07:55:04.878118Z",
     "shell.execute_reply.started": "2024-09-17T07:55:04.861972Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Precision: 0.7539\n",
      "Recall: 0.7557\n",
      "Ensemble accuracy: 0.7528\n",
      "F1 Score: 0.7547\n",
      "Confusion Matrix:\n",
      "[[363 104   8]\n",
      " [ 96 320  75]\n",
      " [  8  59 383]]\n"
     ]
    }
   ],
   "source": [
    "dt_final_predictions = dt_meta_classifier.predict(test_meta_features)\n",
    "\n",
    "# Evaluate\n",
    "precision = precision_score(test_df['label'].values, dt_final_predictions, average='macro')\n",
    "recall = recall_score(test_df['label'].values, dt_final_predictions, average='macro')\n",
    "accuracy = accuracy_score(test_df['label'].values, dt_final_predictions)\n",
    "f1 = f1_score(test_df['label'].values, dt_final_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(test_df['label'].values, dt_final_predictions)\n",
    "\n",
    "print(\"Decision Tree\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Ensemble accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "125f0b72-c5ce-4281-8efc-595018b098e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T07:55:04.880570Z",
     "iopub.status.busy": "2024-09-17T07:55:04.880230Z",
     "iopub.status.idle": "2024-09-17T07:55:04.895698Z",
     "shell.execute_reply": "2024-09-17T07:55:04.895339Z",
     "shell.execute_reply.started": "2024-09-17T07:55:04.880547Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized thresholds for each class: [1.0, 1.0, 1.0]\n",
      "Logistic Regression\n",
      "Precision: 0.7539\n",
      "Recall: 0.7557\n",
      "Ensemble accuracy: 0.7528\n",
      "F1 Score: 0.7546764557796987\n",
      "Confusion Matrix:\n",
      "[[363 104   8]\n",
      " [ 96 320  75]\n",
      " [  8  59 383]]\n"
     ]
    }
   ],
   "source": [
    "probabilities = dt_meta_classifier.predict_proba(test_meta_features)\n",
    "\n",
    "# Calculate precision-recall curve and find optimal thresholds for each class\n",
    "dt_thresh = []\n",
    "for i in range(probabilities.shape[1]):  # Iterate over each class\n",
    "    precision, recall, thresholds = precision_recall_curve(test_df['label'].values == i, probabilities[:, i])\n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "    optimal_idx = np.nanargmax(f1_scores)  # Handle cases where precision and recall are both zero\n",
    "    dt_thresh.append(thresholds[optimal_idx])\n",
    "\n",
    "# Apply the optimized thresholds to make adjusted predictions\n",
    "adjusted_predictions = np.array([np.argmax([probabilities[i, j] if probabilities[i, j] >= dt_thresh[j] else 0\n",
    "                                         for j in range(probabilities.shape[1])])\n",
    "                              for i in range(len(probabilities))])\n",
    "\n",
    "# Evaluate\n",
    "adjusted_precision = precision_score(test_df['label'].values, adjusted_predictions, average='macro')\n",
    "adjusted_recall = recall_score(test_df['label'].values, adjusted_predictions, average='macro')\n",
    "adjusted_accuracy = accuracy_score(test_df['label'].values, adjusted_predictions)\n",
    "adjusted_f1 = f1_score(test_df['label'].values, adjusted_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(test_df['label'].values, adjusted_predictions)\n",
    "\n",
    "print(\"Optimized thresholds for each class:\", dt_thresh)\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Precision: {adjusted_precision:.4f}\")\n",
    "print(f\"Recall: {adjusted_recall:.4f}\")\n",
    "print(f\"Ensemble accuracy: {adjusted_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {adjusted_f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f3be76e-56d6-4e8b-92fa-f87534b9d2b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T07:55:04.899754Z",
     "iopub.status.busy": "2024-09-17T07:55:04.899512Z",
     "iopub.status.idle": "2024-09-17T07:55:05.237305Z",
     "shell.execute_reply": "2024-09-17T07:55:05.236351Z",
     "shell.execute_reply.started": "2024-09-17T07:55:04.899745Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated cells count: 4\n"
     ]
    }
   ],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '5-2!B10:E10'  \n",
    "\n",
    "values = [[\n",
    "    f\"{adjusted_precision * 100:.2f}\",\n",
    "    f\"{adjusted_recall * 100:.2f}\",\n",
    "    f\"{adjusted_accuracy * 100:.2f}\",\n",
    "    f\"{adjusted_f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c8fbf8-8467-470a-b23d-c7368f16192c",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56c161df-ddf2-4392-86ce-cdad4ee3472d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T07:55:05.239807Z",
     "iopub.status.busy": "2024-09-17T07:55:05.239303Z",
     "iopub.status.idle": "2024-09-17T07:55:05.291803Z",
     "shell.execute_reply": "2024-09-17T07:55:05.291407Z",
     "shell.execute_reply.started": "2024-09-17T07:55:05.239774Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "Precision: 0.8207\n",
      "Recall: 0.8178\n",
      "Ensemble accuracy: 0.8164\n",
      "F1 Score: 0.8190\n",
      "Confusion Matrix:\n",
      "[[395  78   2]\n",
      " [ 75 374  42]\n",
      " [  7  56 387]]\n"
     ]
    }
   ],
   "source": [
    "svm_final_predictions = svm_meta_classifier.predict(test_meta_features)\n",
    "\n",
    "# Evaluate\n",
    "precision = precision_score(test_df['label'].values, svm_final_predictions, average='macro')\n",
    "recall = recall_score(test_df['label'].values, svm_final_predictions, average='macro')\n",
    "accuracy = accuracy_score(test_df['label'].values, svm_final_predictions)\n",
    "f1 = f1_score(test_df['label'].values, svm_final_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(test_df['label'].values, svm_final_predictions)\n",
    "\n",
    "print(\"SVM\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Ensemble accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc999cb0-01ec-42d9-ba23-2358c92a4610",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T07:55:05.292648Z",
     "iopub.status.busy": "2024-09-17T07:55:05.292399Z",
     "iopub.status.idle": "2024-09-17T07:55:05.328296Z",
     "shell.execute_reply": "2024-09-17T07:55:05.327996Z",
     "shell.execute_reply.started": "2024-09-17T07:55:05.292630Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized thresholds for each class: [0.2593363938941126, 0.2023649314002989, 0.2542120251786156]\n",
      "Logistic Regression\n",
      "Precision: 0.8197\n",
      "Recall: 0.8164\n",
      "Ensemble accuracy: 0.8150\n",
      "F1 Score: 0.817782458919985\n",
      "Confusion Matrix:\n",
      "[[391  82   2]\n",
      " [ 73 375  43]\n",
      " [  6  56 388]]\n"
     ]
    }
   ],
   "source": [
    "probabilities = svm_meta_classifier.predict_proba(test_meta_features)\n",
    "\n",
    "# Calculate precision-recall curve and find optimal thresholds for each class\n",
    "svm_thresh = []\n",
    "for i in range(probabilities.shape[1]):  # Iterate over each class\n",
    "    precision, recall, thresholds = precision_recall_curve(test_df['label'].values == i, probabilities[:, i])\n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "    optimal_idx = np.nanargmax(f1_scores)  # Handle cases where precision and recall are both zero\n",
    "    svm_thresh.append(thresholds[optimal_idx])\n",
    "\n",
    "# Apply the optimized thresholds to make adjusted predictions\n",
    "adjusted_predictions = np.array([np.argmax([probabilities[i, j] if probabilities[i, j] >= svm_thresh[j] else 0\n",
    "                                         for j in range(probabilities.shape[1])])\n",
    "                              for i in range(len(probabilities))])\n",
    "\n",
    "# Evaluate\n",
    "adjusted_precision = precision_score(test_df['label'].values, adjusted_predictions, average='macro')\n",
    "adjusted_recall = recall_score(test_df['label'].values, adjusted_predictions, average='macro')\n",
    "adjusted_accuracy = accuracy_score(test_df['label'].values, adjusted_predictions)\n",
    "adjusted_f1 = f1_score(test_df['label'].values, adjusted_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(test_df['label'].values, adjusted_predictions)\n",
    "\n",
    "print(\"Optimized thresholds for each class:\", svm_thresh)\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Precision: {adjusted_precision:.4f}\")\n",
    "print(f\"Recall: {adjusted_recall:.4f}\")\n",
    "print(f\"Ensemble accuracy: {adjusted_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {adjusted_f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06aef1c8-e91b-4401-8c9c-a1ab43a5b4b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T07:55:05.328924Z",
     "iopub.status.busy": "2024-09-17T07:55:05.328830Z",
     "iopub.status.idle": "2024-09-17T07:55:05.717127Z",
     "shell.execute_reply": "2024-09-17T07:55:05.715570Z",
     "shell.execute_reply.started": "2024-09-17T07:55:05.328917Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated cells count: 4\n"
     ]
    }
   ],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '5-2!B11:E11'  \n",
    "\n",
    "values = [[\n",
    "    f\"{adjusted_precision * 100:.2f}\",\n",
    "    f\"{adjusted_recall * 100:.2f}\",\n",
    "    f\"{adjusted_accuracy * 100:.2f}\",\n",
    "    f\"{adjusted_f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2045a9-4a51-4880-b22f-b3ff2b11881d",
   "metadata": {},
   "source": [
    "# Validate on Data C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f3295c-4ff1-44ea-857b-82a80bb44ff3",
   "metadata": {},
   "source": [
    "## Load Data C Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06f318e7-8089-4e51-8494-de0f6a11b10b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T07:55:05.720945Z",
     "iopub.status.busy": "2024-09-17T07:55:05.720535Z",
     "iopub.status.idle": "2024-09-17T07:55:05.735899Z",
     "shell.execute_reply": "2024-09-17T07:55:05.735219Z",
     "shell.execute_reply.started": "2024-09-17T07:55:05.720922Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Load validation data\n",
    "validation_file_path = 'Corpus/FiReCS/FiReCS_data_c.csv'\n",
    "validation_df = pd.read_csv(validation_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ce9332-4160-4859-85e1-5b1d4184d1b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-11T13:00:14.207089Z",
     "iopub.status.busy": "2024-04-11T13:00:14.206594Z",
     "iopub.status.idle": "2024-04-11T13:00:14.209788Z",
     "shell.execute_reply": "2024-04-11T13:00:14.209108Z",
     "shell.execute_reply.started": "2024-04-11T13:00:14.207047Z"
    }
   },
   "source": [
    "## Perform Blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9397f5dc-4155-435b-b189-d720dd902f68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T07:55:05.737453Z",
     "iopub.status.busy": "2024-09-17T07:55:05.736890Z",
     "iopub.status.idle": "2024-09-17T07:55:26.686221Z",
     "shell.execute_reply": "2024-09-17T07:55:26.685897Z",
     "shell.execute_reply.started": "2024-09-17T07:55:05.737430Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1455.19 MiB, increment: 148.20 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "\n",
    "# Generate meta-features for validation set\n",
    "validation_meta_features = [get_meta_features(model, tokenizer, validation_df, device) \n",
    "                            for model, tokenizer in models_and_tokenizers.values()]\n",
    "\n",
    "# Stack meta-features\n",
    "validation_meta_features = np.hstack(validation_meta_features)\n",
    "\n",
    "# Predict with LR meta-classifier\n",
    "lr_validation_predictions = lr_meta_classifier.predict(validation_meta_features)\n",
    "\n",
    "# Predict with NB meta-classifier\n",
    "nb_validation_predictions = nb_meta_classifier.predict(validation_meta_features)\n",
    "\n",
    "# Predict with DT meta-classifier\n",
    "dt_validation_predictions = dt_meta_classifier.predict(validation_meta_features)\n",
    "\n",
    "# Predict with SVM meta-classifier\n",
    "svm_validation_predictions = svm_meta_classifier.predict(validation_meta_features)\n",
    "\n",
    "# Extract true labels from the validation set\n",
    "true_labels = validation_df['label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da263a8-cbf9-4cff-b41b-e88a5e2512b4",
   "metadata": {},
   "source": [
    "## Validate Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73574aa4-26e8-4d0a-bc95-478361fcc2e6",
   "metadata": {},
   "source": [
    "### LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "df42fe2c-46bb-486d-90ba-404043f52e9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T07:55:26.686881Z",
     "iopub.status.busy": "2024-09-17T07:55:26.686800Z",
     "iopub.status.idle": "2024-09-17T07:55:26.692364Z",
     "shell.execute_reply": "2024-09-17T07:55:26.692134Z",
     "shell.execute_reply.started": "2024-09-17T07:55:26.686874Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Accuracy: 0.8236\n",
      "Precision: 0.8294\n",
      "Recall: 0.8243\n",
      "F1 Score: 0.8262\n",
      "Confusion Matrix:\n",
      " [[281  59   1]\n",
      " [ 45 288  31]\n",
      " [  4  45 295]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "accuracy = accuracy_score(true_labels, lr_validation_predictions)\n",
    "precision = precision_score(true_labels, lr_validation_predictions, average='macro')\n",
    "recall = recall_score(true_labels, lr_validation_predictions, average='macro')\n",
    "f1 = f1_score(true_labels, lr_validation_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(true_labels, lr_validation_predictions)\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646d69bb-fb97-4d6d-8120-71f545822c5f",
   "metadata": {},
   "source": [
    "#### Optimized LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "066745e4-0dcb-4a51-8032-f2e762eb2429",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T07:55:26.692912Z",
     "iopub.status.busy": "2024-09-17T07:55:26.692836Z",
     "iopub.status.idle": "2024-09-17T07:55:26.699968Z",
     "shell.execute_reply": "2024-09-17T07:55:26.699746Z",
     "shell.execute_reply.started": "2024-09-17T07:55:26.692906Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results\n",
      "Precision: 0.8287\n",
      "Recall: 0.8233\n",
      "Accuracy: 0.8227\n",
      "F1 Score: 0.8254\n",
      "Confusion Matrix:\n",
      "[[281  59   1]\n",
      " [ 45 288  31]\n",
      " [  4  46 294]]\n"
     ]
    }
   ],
   "source": [
    "lr_validation_probabilities = lr_meta_classifier.predict_proba(validation_meta_features)\n",
    "\n",
    "# Apply thresholds to the validation set probabilities to make final predictions\n",
    "lr_validation_predictions = np.array([np.argmax([lr_validation_probabilities[i, j] if lr_validation_probabilities[i, j] >= lr_thresh[j] else 0\n",
    "                                              for j in range(lr_validation_probabilities.shape[1])])\n",
    "                                   for i in range(len(lr_validation_probabilities))])\n",
    "\n",
    "# Evaluate threshold on validation set\n",
    "adjusted_precision = precision_score(true_labels, lr_validation_predictions, average='macro')\n",
    "adjusted_recall = recall_score(true_labels, lr_validation_predictions, average='macro')\n",
    "adjusted_accuracy = accuracy_score(true_labels, lr_validation_predictions)\n",
    "adjusted_f1 = f1_score(true_labels, lr_validation_predictions, average='macro')\n",
    "adjusted_conf_matrix = confusion_matrix(true_labels, lr_validation_predictions)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Validation Results\")\n",
    "print(f\"Precision: {adjusted_precision:.4f}\")\n",
    "print(f\"Recall: {adjusted_recall:.4f}\")\n",
    "print(f\"Accuracy: {adjusted_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {adjusted_f1:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(adjusted_conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e5f1a22-24d9-4e81-95bd-78eae0de91fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T07:55:26.700642Z",
     "iopub.status.busy": "2024-09-17T07:55:26.700543Z",
     "iopub.status.idle": "2024-09-17T07:55:27.117524Z",
     "shell.execute_reply": "2024-09-17T07:55:27.116247Z",
     "shell.execute_reply.started": "2024-09-17T07:55:26.700636Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated cells count: 4\n"
     ]
    }
   ],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '5-2!F8:I8'  \n",
    "\n",
    "values = [[\n",
    "    f\"{adjusted_precision * 100:.2f}\",\n",
    "    f\"{adjusted_recall * 100:.2f}\",\n",
    "    f\"{adjusted_accuracy * 100:.2f}\",\n",
    "    f\"{adjusted_f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c303f4-b9fd-4c43-b082-8eb20af98b9d",
   "metadata": {},
   "source": [
    "#### Save Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ec064b9f-9afe-40ac-a84f-33d3179cc317",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T07:55:27.120405Z",
     "iopub.status.busy": "2024-09-17T07:55:27.118918Z",
     "iopub.status.idle": "2024-09-17T07:55:27.330064Z",
     "shell.execute_reply": "2024-09-17T07:55:27.329803Z",
     "shell.execute_reply.started": "2024-09-17T07:55:27.120375Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-1d63a533192c4f11bf180524ef3b6f3e.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-1d63a533192c4f11bf180524ef3b6f3e.vega-embed details,\n",
       "  #altair-viz-1d63a533192c4f11bf180524ef3b6f3e.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-1d63a533192c4f11bf180524ef3b6f3e\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-1d63a533192c4f11bf180524ef3b6f3e\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-1d63a533192c4f11bf180524ef3b6f3e\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"rect\"}, \"encoding\": {\"color\": {\"field\": \"Count\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"True\", \"type\": \"ordinal\"}, {\"field\": \"Predicted\", \"type\": \"ordinal\"}, {\"field\": \"Count\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Predicted\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}, \"y\": {\"field\": \"True\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}}, \"title\": \"OF_Using_FIRE 5B-2 LR\"}, {\"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"middle\", \"fontSize\": 12}, \"encoding\": {\"color\": {\"condition\": {\"test\": \"(datum.Count > 147.0)\", \"value\": \"white\"}, \"value\": \"black\"}, \"text\": {\"field\": \"Count\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"True\", \"type\": \"ordinal\"}, {\"field\": \"Predicted\", \"type\": \"ordinal\"}, {\"field\": \"Count\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Predicted\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}, \"y\": {\"field\": \"True\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}}, \"title\": \"OF_Using_FIRE 5B-2 LR\"}], \"data\": {\"name\": \"data-550103ab16615e5dce7a6f11312120e1\"}, \"height\": 300, \"width\": 400, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-550103ab16615e5dce7a6f11312120e1\": [{\"True\": \"Negative\", \"Predicted\": \"Negative\", \"Count\": 281}, {\"True\": \"Neutral\", \"Predicted\": \"Negative\", \"Count\": 45}, {\"True\": \"Positive\", \"Predicted\": \"Negative\", \"Count\": 4}, {\"True\": \"Negative\", \"Predicted\": \"Neutral\", \"Count\": 59}, {\"True\": \"Neutral\", \"Predicted\": \"Neutral\", \"Count\": 288}, {\"True\": \"Positive\", \"Predicted\": \"Neutral\", \"Count\": 46}, {\"True\": \"Negative\", \"Predicted\": \"Positive\", \"Count\": 1}, {\"True\": \"Neutral\", \"Predicted\": \"Positive\", \"Count\": 31}, {\"True\": \"Positive\", \"Predicted\": \"Positive\", \"Count\": 294}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import altair as alt\n",
    "import altair_saver\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(true_labels, lr_validation_predictions)\n",
    "\n",
    "# Define class names\n",
    "class_names = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "# Convert confusion matrix to DataFrame\n",
    "cm_df = pd.DataFrame(cm, index=class_names, columns=class_names).reset_index().melt(id_vars='index')\n",
    "cm_df.columns = ['True', 'Predicted', 'Count']\n",
    "\n",
    "# Ensure the order of categories\n",
    "cm_df['True'] = pd.Categorical(cm_df['True'], categories=class_names, ordered=True)\n",
    "cm_df['Predicted'] = pd.Categorical(cm_df['Predicted'], categories=class_names, ordered=True)\n",
    "\n",
    "# Create the Altair plot\n",
    "heatmap = alt.Chart(cm_df).mark_rect().encode(\n",
    "    x=alt.X('Predicted:O', sort=class_names),\n",
    "    y=alt.Y('True:O', sort=class_names),\n",
    "    color='Count:Q',\n",
    "    tooltip=['True', 'Predicted', 'Count']\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=300,\n",
    "    title='OF_Using_FIRE 5B-2 LR'\n",
    ")\n",
    "\n",
    "# Add text labels\n",
    "text = heatmap.mark_text(\n",
    "    align='center',\n",
    "    baseline='middle',\n",
    "    fontSize=12\n",
    ").encode(\n",
    "    text='Count:Q',\n",
    "    color=alt.condition(\n",
    "        alt.datum.Count > cm.max() / 2,\n",
    "        alt.value('white'),\n",
    "        alt.value('black')\n",
    "    )\n",
    ")\n",
    "\n",
    "# Combine heatmap and text\n",
    "final_chart = heatmap + text\n",
    "\n",
    "# Display the plot\n",
    "final_chart.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c84bccf-bca1-4687-a5c4-cbaba95eaefb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T07:55:27.330627Z",
     "iopub.status.busy": "2024-09-17T07:55:27.330513Z",
     "iopub.status.idle": "2024-09-17T07:55:27.733838Z",
     "shell.execute_reply": "2024-09-17T07:55:27.733509Z",
     "shell.execute_reply.started": "2024-09-17T07:55:27.330620Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to Results/Ensemble Model Results/On FireCS dataset/OF Using FIRE ENSEMBLE/Blending/OF_Using_FIRE 5B-2 LR.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Specify the folder path\n",
    "folder_path = os.path.expanduser('Results/Ensemble Model Results/On FireCS dataset/OF Using FIRE ENSEMBLE/Blending/')\n",
    "\n",
    "# Save the plot using vl-convert\n",
    "file_path_png = os.path.join(folder_path, 'OF_Using_FIRE 5B-2 LR.png')\n",
    "final_chart.save(file_path_png)\n",
    "\n",
    "print(f\"Plot saved to {file_path_png}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3649998-d30c-429a-9cc5-db6259d6c39e",
   "metadata": {},
   "source": [
    "### NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "88863a6c-c113-4347-84ed-3ef930aeaba4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T07:55:27.734349Z",
     "iopub.status.busy": "2024-09-17T07:55:27.734270Z",
     "iopub.status.idle": "2024-09-17T07:55:27.739198Z",
     "shell.execute_reply": "2024-09-17T07:55:27.738995Z",
     "shell.execute_reply.started": "2024-09-17T07:55:27.734342Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes\n",
      "Accuracy: 0.8074\n",
      "Precision: 0.8112\n",
      "Recall: 0.8086\n",
      "F1 Score: 0.8098\n",
      "Confusion Matrix:\n",
      " [[280  60   1]\n",
      " [ 54 272  38]\n",
      " [  3  46 295]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "accuracy = accuracy_score(true_labels, nb_validation_predictions)\n",
    "precision = precision_score(true_labels, nb_validation_predictions, average='macro')\n",
    "recall = recall_score(true_labels, nb_validation_predictions, average='macro')\n",
    "f1 = f1_score(true_labels, nb_validation_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(true_labels, nb_validation_predictions)\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Naive Bayes\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2169b1-2326-484e-afab-e8f5bc9110cd",
   "metadata": {},
   "source": [
    "#### Optimized NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48adaca5-619e-4e11-8720-4624e78f7d01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T07:55:27.739681Z",
     "iopub.status.busy": "2024-09-17T07:55:27.739601Z",
     "iopub.status.idle": "2024-09-17T07:55:27.746580Z",
     "shell.execute_reply": "2024-09-17T07:55:27.746361Z",
     "shell.execute_reply.started": "2024-09-17T07:55:27.739675Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results\n",
      "Precision: 0.8112\n",
      "Recall: 0.8086\n",
      "Accuracy: 0.8074\n",
      "F1 Score: 0.8098\n",
      "Confusion Matrix:\n",
      "[[280  60   1]\n",
      " [ 54 272  38]\n",
      " [  3  46 295]]\n"
     ]
    }
   ],
   "source": [
    "nb_validation_probabilities = nb_meta_classifier.predict_proba(validation_meta_features)\n",
    "\n",
    "# Apply thresholds to the validation set probabilities to make final predictions\n",
    "nb_validation_predictions = np.array([np.argmax([nb_validation_probabilities[i, j] if nb_validation_probabilities[i, j] >= nb_thresh[j] else 0\n",
    "                                              for j in range(nb_validation_probabilities.shape[1])])\n",
    "                                   for i in range(len(nb_validation_probabilities))])\n",
    "\n",
    "# Evaluate threshold on validation set\n",
    "adjusted_precision = precision_score(true_labels, nb_validation_predictions, average='macro')\n",
    "adjusted_recall = recall_score(true_labels, nb_validation_predictions, average='macro')\n",
    "adjusted_accuracy = accuracy_score(true_labels, nb_validation_predictions)\n",
    "adjusted_f1 = f1_score(true_labels, nb_validation_predictions, average='macro')\n",
    "adjusted_conf_matrix = confusion_matrix(true_labels, nb_validation_predictions)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Validation Results\")\n",
    "print(f\"Precision: {adjusted_precision:.4f}\")\n",
    "print(f\"Recall: {adjusted_recall:.4f}\")\n",
    "print(f\"Accuracy: {adjusted_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {adjusted_f1:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(adjusted_conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3385f279-f825-4037-b938-5ce665e1c933",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T07:55:27.746984Z",
     "iopub.status.busy": "2024-09-17T07:55:27.746909Z",
     "iopub.status.idle": "2024-09-17T07:55:28.142868Z",
     "shell.execute_reply": "2024-09-17T07:55:28.141596Z",
     "shell.execute_reply.started": "2024-09-17T07:55:27.746978Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated cells count: 4\n"
     ]
    }
   ],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '5-2!F9:I9'  \n",
    "\n",
    "values = [[\n",
    "    f\"{adjusted_precision * 100:.2f}\",\n",
    "    f\"{adjusted_recall * 100:.2f}\",\n",
    "    f\"{adjusted_accuracy * 100:.2f}\",\n",
    "    f\"{adjusted_f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713bd6ec-92aa-4870-ac78-885d8932f907",
   "metadata": {},
   "source": [
    "#### Save Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cce31e47-a2e4-4178-869e-59b4c7fdf968",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T07:55:28.144910Z",
     "iopub.status.busy": "2024-09-17T07:55:28.144413Z",
     "iopub.status.idle": "2024-09-17T07:55:28.193824Z",
     "shell.execute_reply": "2024-09-17T07:55:28.193478Z",
     "shell.execute_reply.started": "2024-09-17T07:55:28.144883Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-7ad47553e66f49a297e0cac2bc705166.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-7ad47553e66f49a297e0cac2bc705166.vega-embed details,\n",
       "  #altair-viz-7ad47553e66f49a297e0cac2bc705166.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-7ad47553e66f49a297e0cac2bc705166\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-7ad47553e66f49a297e0cac2bc705166\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-7ad47553e66f49a297e0cac2bc705166\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"rect\"}, \"encoding\": {\"color\": {\"field\": \"Count\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"True\", \"type\": \"ordinal\"}, {\"field\": \"Predicted\", \"type\": \"ordinal\"}, {\"field\": \"Count\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Predicted\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}, \"y\": {\"field\": \"True\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}}, \"title\": \"OF_Using_FIRE 5B-2 NB\"}, {\"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"middle\", \"fontSize\": 12}, \"encoding\": {\"color\": {\"condition\": {\"test\": \"(datum.Count > 147.5)\", \"value\": \"white\"}, \"value\": \"black\"}, \"text\": {\"field\": \"Count\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"True\", \"type\": \"ordinal\"}, {\"field\": \"Predicted\", \"type\": \"ordinal\"}, {\"field\": \"Count\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Predicted\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}, \"y\": {\"field\": \"True\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}}, \"title\": \"OF_Using_FIRE 5B-2 NB\"}], \"data\": {\"name\": \"data-2a539d8dcd4414c27debf6c26ab126ed\"}, \"height\": 300, \"width\": 400, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-2a539d8dcd4414c27debf6c26ab126ed\": [{\"True\": \"Negative\", \"Predicted\": \"Negative\", \"Count\": 280}, {\"True\": \"Neutral\", \"Predicted\": \"Negative\", \"Count\": 54}, {\"True\": \"Positive\", \"Predicted\": \"Negative\", \"Count\": 3}, {\"True\": \"Negative\", \"Predicted\": \"Neutral\", \"Count\": 60}, {\"True\": \"Neutral\", \"Predicted\": \"Neutral\", \"Count\": 272}, {\"True\": \"Positive\", \"Predicted\": \"Neutral\", \"Count\": 46}, {\"True\": \"Negative\", \"Predicted\": \"Positive\", \"Count\": 1}, {\"True\": \"Neutral\", \"Predicted\": \"Positive\", \"Count\": 38}, {\"True\": \"Positive\", \"Predicted\": \"Positive\", \"Count\": 295}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import altair as alt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(true_labels, nb_validation_predictions)\n",
    "\n",
    "# Define class names\n",
    "class_names = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "# Convert confusion matrix to DataFrame\n",
    "cm_df = pd.DataFrame(cm, index=class_names, columns=class_names).reset_index().melt(id_vars='index')\n",
    "cm_df.columns = ['True', 'Predicted', 'Count']\n",
    "\n",
    "# Ensure the order of categories\n",
    "cm_df['True'] = pd.Categorical(cm_df['True'], categories=class_names, ordered=True)\n",
    "cm_df['Predicted'] = pd.Categorical(cm_df['Predicted'], categories=class_names, ordered=True)\n",
    "\n",
    "# Create the Altair plot\n",
    "heatmap = alt.Chart(cm_df).mark_rect().encode(\n",
    "    x=alt.X('Predicted:O', sort=class_names),\n",
    "    y=alt.Y('True:O', sort=class_names),\n",
    "    color='Count:Q',\n",
    "    tooltip=['True', 'Predicted', 'Count']\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=300,\n",
    "    title='OF_Using_FIRE 5B-2 NB'\n",
    ")\n",
    "\n",
    "# Add text labels\n",
    "text = heatmap.mark_text(\n",
    "    align='center',\n",
    "    baseline='middle',\n",
    "    fontSize=12\n",
    ").encode(\n",
    "    text='Count:Q',\n",
    "    color=alt.condition(\n",
    "        alt.datum.Count > cm.max() / 2,\n",
    "        alt.value('white'),\n",
    "        alt.value('black')\n",
    "    )\n",
    ")\n",
    "\n",
    "# Combine heatmap and text\n",
    "final_chart = heatmap + text\n",
    "\n",
    "# Display the plot\n",
    "final_chart.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "81f17b08-bd45-4091-aa78-efa4bad633d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T07:55:28.194434Z",
     "iopub.status.busy": "2024-09-17T07:55:28.194344Z",
     "iopub.status.idle": "2024-09-17T07:55:28.238111Z",
     "shell.execute_reply": "2024-09-17T07:55:28.237825Z",
     "shell.execute_reply.started": "2024-09-17T07:55:28.194426Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to Results/Ensemble Model Results/On FireCS dataset/OF Using FIRE ENSEMBLE/Blending/OF_Using_FIRE 5B-2 NB.png\n"
     ]
    }
   ],
   "source": [
    "# Specify the folder path\n",
    "folder_path = os.path.expanduser('Results/Ensemble Model Results/On FireCS dataset/OF Using FIRE ENSEMBLE/Blending/')\n",
    "\n",
    "# Save the plot using vl-convert\n",
    "file_path_png = os.path.join(folder_path, 'OF_Using_FIRE 5B-2 NB.png')\n",
    "final_chart.save(file_path_png)\n",
    "\n",
    "print(f\"Plot saved to {file_path_png}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2d3e3d-90ee-45fd-9934-756f226ee6e1",
   "metadata": {},
   "source": [
    "### DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e549350b-ed54-4425-a913-7401ec7d676e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T07:55:28.238663Z",
     "iopub.status.busy": "2024-09-17T07:55:28.238578Z",
     "iopub.status.idle": "2024-09-17T07:55:28.243953Z",
     "shell.execute_reply": "2024-09-17T07:55:28.243692Z",
     "shell.execute_reply.started": "2024-09-17T07:55:28.238655Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Accuracy: 0.7560\n",
      "Precision: 0.7596\n",
      "Recall: 0.7574\n",
      "F1 Score: 0.7583\n",
      "Confusion Matrix:\n",
      " [[258  78   5]\n",
      " [ 61 248  55]\n",
      " [  6  51 287]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "accuracy = accuracy_score(true_labels, dt_validation_predictions)\n",
    "precision = precision_score(true_labels, dt_validation_predictions, average='macro')\n",
    "recall = recall_score(true_labels, dt_validation_predictions, average='macro')\n",
    "f1 = f1_score(true_labels, dt_validation_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(true_labels, dt_validation_predictions)\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Decision Tree\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fd4d69-bbe3-49a2-adc7-5797413066a0",
   "metadata": {},
   "source": [
    "#### Optimized DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "402e240b-712d-491a-9cfb-18f050dc8e10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T07:55:28.244564Z",
     "iopub.status.busy": "2024-09-17T07:55:28.244452Z",
     "iopub.status.idle": "2024-09-17T07:55:28.252220Z",
     "shell.execute_reply": "2024-09-17T07:55:28.251994Z",
     "shell.execute_reply.started": "2024-09-17T07:55:28.244558Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results\n",
      "Precision: 0.7596\n",
      "Recall: 0.7574\n",
      "Accuracy: 0.7560\n",
      "F1 Score: 0.7583\n",
      "Confusion Matrix:\n",
      "[[258  78   5]\n",
      " [ 61 248  55]\n",
      " [  6  51 287]]\n"
     ]
    }
   ],
   "source": [
    "dt_validation_probabilities = dt_meta_classifier.predict_proba(validation_meta_features)\n",
    "\n",
    "# Apply thresholds to the validation set probabilities to make final predictions\n",
    "dt_validation_predictions = np.array([np.argmax([dt_validation_probabilities[i, j] if dt_validation_probabilities[i, j] >= dt_thresh[j] else 0\n",
    "                                              for j in range(dt_validation_probabilities.shape[1])])\n",
    "                                   for i in range(len(dt_validation_probabilities))])\n",
    "\n",
    "# Evaluate threshold on validation set\n",
    "adjusted_precision = precision_score(true_labels, dt_validation_predictions, average='macro')\n",
    "adjusted_recall = recall_score(true_labels, dt_validation_predictions, average='macro')\n",
    "adjusted_accuracy = accuracy_score(true_labels, dt_validation_predictions)\n",
    "adjusted_f1 = f1_score(true_labels, dt_validation_predictions, average='macro')\n",
    "adjusted_conf_matrix = confusion_matrix(true_labels, dt_validation_predictions)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Validation Results\")\n",
    "print(f\"Precision: {adjusted_precision:.4f}\")\n",
    "print(f\"Recall: {adjusted_recall:.4f}\")\n",
    "print(f\"Accuracy: {adjusted_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {adjusted_f1:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(adjusted_conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9a8b1491-a04a-4b41-8964-146b60f0a3bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T07:55:28.252806Z",
     "iopub.status.busy": "2024-09-17T07:55:28.252686Z",
     "iopub.status.idle": "2024-09-17T07:55:28.654894Z",
     "shell.execute_reply": "2024-09-17T07:55:28.652832Z",
     "shell.execute_reply.started": "2024-09-17T07:55:28.252799Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated cells count: 4\n"
     ]
    }
   ],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '5-2!F10:I10'  \n",
    "\n",
    "values = [[\n",
    "    f\"{adjusted_precision * 100:.2f}\",\n",
    "    f\"{adjusted_recall * 100:.2f}\",\n",
    "    f\"{adjusted_accuracy * 100:.2f}\",\n",
    "    f\"{adjusted_f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b80cdde-08b4-45bf-8a7f-9e042d310d28",
   "metadata": {},
   "source": [
    "#### Save Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "132bbe60-3e4d-42ba-a631-5518a8fc5ccc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T07:55:28.657095Z",
     "iopub.status.busy": "2024-09-17T07:55:28.656704Z",
     "iopub.status.idle": "2024-09-17T07:55:28.701864Z",
     "shell.execute_reply": "2024-09-17T07:55:28.701557Z",
     "shell.execute_reply.started": "2024-09-17T07:55:28.657075Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-960ab0128ce247928282ef9c6ed09f11.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-960ab0128ce247928282ef9c6ed09f11.vega-embed details,\n",
       "  #altair-viz-960ab0128ce247928282ef9c6ed09f11.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-960ab0128ce247928282ef9c6ed09f11\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-960ab0128ce247928282ef9c6ed09f11\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-960ab0128ce247928282ef9c6ed09f11\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"rect\"}, \"encoding\": {\"color\": {\"field\": \"Count\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"True\", \"type\": \"ordinal\"}, {\"field\": \"Predicted\", \"type\": \"ordinal\"}, {\"field\": \"Count\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Predicted\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}, \"y\": {\"field\": \"True\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}}, \"title\": \"OF_Using_FIRE 5B-2 DT\"}, {\"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"middle\", \"fontSize\": 12}, \"encoding\": {\"color\": {\"condition\": {\"test\": \"(datum.Count > 143.5)\", \"value\": \"white\"}, \"value\": \"black\"}, \"text\": {\"field\": \"Count\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"True\", \"type\": \"ordinal\"}, {\"field\": \"Predicted\", \"type\": \"ordinal\"}, {\"field\": \"Count\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Predicted\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}, \"y\": {\"field\": \"True\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}}, \"title\": \"OF_Using_FIRE 5B-2 DT\"}], \"data\": {\"name\": \"data-fed44e47e87f8fe5a03bc76a83021b6a\"}, \"height\": 300, \"width\": 400, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-fed44e47e87f8fe5a03bc76a83021b6a\": [{\"True\": \"Negative\", \"Predicted\": \"Negative\", \"Count\": 258}, {\"True\": \"Neutral\", \"Predicted\": \"Negative\", \"Count\": 61}, {\"True\": \"Positive\", \"Predicted\": \"Negative\", \"Count\": 6}, {\"True\": \"Negative\", \"Predicted\": \"Neutral\", \"Count\": 78}, {\"True\": \"Neutral\", \"Predicted\": \"Neutral\", \"Count\": 248}, {\"True\": \"Positive\", \"Predicted\": \"Neutral\", \"Count\": 51}, {\"True\": \"Negative\", \"Predicted\": \"Positive\", \"Count\": 5}, {\"True\": \"Neutral\", \"Predicted\": \"Positive\", \"Count\": 55}, {\"True\": \"Positive\", \"Predicted\": \"Positive\", \"Count\": 287}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import altair as alt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(true_labels, dt_validation_predictions)\n",
    "\n",
    "# Define class names\n",
    "class_names = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "# Convert confusion matrix to DataFrame\n",
    "cm_df = pd.DataFrame(cm, index=class_names, columns=class_names).reset_index().melt(id_vars='index')\n",
    "cm_df.columns = ['True', 'Predicted', 'Count']\n",
    "\n",
    "# Ensure the order of categories\n",
    "cm_df['True'] = pd.Categorical(cm_df['True'], categories=class_names, ordered=True)\n",
    "cm_df['Predicted'] = pd.Categorical(cm_df['Predicted'], categories=class_names, ordered=True)\n",
    "\n",
    "# Create the Altair plot\n",
    "heatmap = alt.Chart(cm_df).mark_rect().encode(\n",
    "    x=alt.X('Predicted:O', sort=class_names),\n",
    "    y=alt.Y('True:O', sort=class_names),\n",
    "    color='Count:Q',\n",
    "    tooltip=['True', 'Predicted', 'Count']\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=300,\n",
    "    title='OF_Using_FIRE 5B-2 DT'\n",
    ")\n",
    "\n",
    "# Add text labels\n",
    "text = heatmap.mark_text(\n",
    "    align='center',\n",
    "    baseline='middle',\n",
    "    fontSize=12\n",
    ").encode(\n",
    "    text='Count:Q',\n",
    "    color=alt.condition(\n",
    "        alt.datum.Count > cm.max() / 2,\n",
    "        alt.value('white'),\n",
    "        alt.value('black')\n",
    "    )\n",
    ")\n",
    "\n",
    "# Combine heatmap and text\n",
    "final_chart = heatmap + text\n",
    "\n",
    "# Display the plot\n",
    "final_chart.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fd980aa3-972b-4c5a-bcff-db353c916d50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T07:55:28.702362Z",
     "iopub.status.busy": "2024-09-17T07:55:28.702288Z",
     "iopub.status.idle": "2024-09-17T07:55:28.745828Z",
     "shell.execute_reply": "2024-09-17T07:55:28.745550Z",
     "shell.execute_reply.started": "2024-09-17T07:55:28.702355Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to Results/Ensemble Model Results/On FireCS dataset/OF Using FIRE ENSEMBLE/Blending/OF_Using_FIRE 5B-2 DT.png\n"
     ]
    }
   ],
   "source": [
    "# Specify the folder path\n",
    "folder_path = os.path.expanduser('Results/Ensemble Model Results/On FireCS dataset/OF Using FIRE ENSEMBLE/Blending/')\n",
    "\n",
    "# Save the plot using vl-convert\n",
    "file_path_png = os.path.join(folder_path, 'OF_Using_FIRE 5B-2 DT.png')\n",
    "final_chart.save(file_path_png)\n",
    "\n",
    "print(f\"Plot saved to {file_path_png}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617d6721-27ff-4989-98c9-63c9f5bf6017",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a09fcca8-2569-41cd-b218-d4d368329c02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T07:55:28.746680Z",
     "iopub.status.busy": "2024-09-17T07:55:28.746390Z",
     "iopub.status.idle": "2024-09-17T07:55:28.751889Z",
     "shell.execute_reply": "2024-09-17T07:55:28.751615Z",
     "shell.execute_reply.started": "2024-09-17T07:55:28.746656Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "Accuracy: 0.8198\n",
      "Precision: 0.8262\n",
      "Recall: 0.8205\n",
      "F1 Score: 0.8227\n",
      "Confusion Matrix:\n",
      " [[281  60   0]\n",
      " [ 48 286  30]\n",
      " [  4  47 293]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "accuracy = accuracy_score(true_labels, svm_validation_predictions)\n",
    "precision = precision_score(true_labels, svm_validation_predictions, average='macro')\n",
    "recall = recall_score(true_labels, svm_validation_predictions, average='macro')\n",
    "f1 = f1_score(true_labels, svm_validation_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(true_labels, svm_validation_predictions)\n",
    "\n",
    "# Print the metrics\n",
    "print(\"SVM\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23a28f0-e330-4f4f-ae3a-efab329ebd5b",
   "metadata": {},
   "source": [
    "#### Optimized SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "392837af-79b9-4dad-a890-7e9d19a08197",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T07:55:28.752495Z",
     "iopub.status.busy": "2024-09-17T07:55:28.752392Z",
     "iopub.status.idle": "2024-09-17T07:55:28.775444Z",
     "shell.execute_reply": "2024-09-17T07:55:28.775113Z",
     "shell.execute_reply.started": "2024-09-17T07:55:28.752488Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results\n",
      "Precision: 0.8297\n",
      "Recall: 0.8232\n",
      "Accuracy: 0.8227\n",
      "F1 Score: 0.8256\n",
      "Confusion Matrix:\n",
      "[[281  60   0]\n",
      " [ 45 289  30]\n",
      " [  3  48 293]]\n"
     ]
    }
   ],
   "source": [
    "svm_validation_probabilities = svm_meta_classifier.predict_proba(validation_meta_features)\n",
    "\n",
    "# Apply thresholds to the validation set probabilities to make final predictions\n",
    "svm_validation_predictions = np.array([np.argmax([svm_validation_probabilities[i, j] if svm_validation_probabilities[i, j] >= svm_thresh[j] else 0\n",
    "                                              for j in range(svm_validation_probabilities.shape[1])])\n",
    "                                   for i in range(len(svm_validation_probabilities))])\n",
    "\n",
    "# Evaluate threshold on validation set\n",
    "adjusted_precision = precision_score(true_labels, svm_validation_predictions, average='macro')\n",
    "adjusted_recall = recall_score(true_labels, svm_validation_predictions, average='macro')\n",
    "adjusted_accuracy = accuracy_score(true_labels, svm_validation_predictions)\n",
    "adjusted_f1 = f1_score(true_labels, svm_validation_predictions, average='macro')\n",
    "adjusted_conf_matrix = confusion_matrix(true_labels, svm_validation_predictions)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Validation Results\")\n",
    "print(f\"Precision: {adjusted_precision:.4f}\")\n",
    "print(f\"Recall: {adjusted_recall:.4f}\")\n",
    "print(f\"Accuracy: {adjusted_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {adjusted_f1:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(adjusted_conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "79945954-0d97-4ce4-b7d8-83fcde7b355a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T07:55:28.776019Z",
     "iopub.status.busy": "2024-09-17T07:55:28.775939Z",
     "iopub.status.idle": "2024-09-17T07:55:29.167251Z",
     "shell.execute_reply": "2024-09-17T07:55:29.164762Z",
     "shell.execute_reply.started": "2024-09-17T07:55:28.776013Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated cells count: 4\n"
     ]
    }
   ],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '5-2!F11:I11'  \n",
    "\n",
    "values = [[\n",
    "    f\"{adjusted_precision * 100:.2f}\",\n",
    "    f\"{adjusted_recall * 100:.2f}\",\n",
    "    f\"{adjusted_accuracy * 100:.2f}\",\n",
    "    f\"{adjusted_f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42cfc96-7466-49d1-bf23-9fa95538e84a",
   "metadata": {},
   "source": [
    "#### Save Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1ab5ac70-3881-4aea-b426-0aec5075e619",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T07:55:29.172090Z",
     "iopub.status.busy": "2024-09-17T07:55:29.170207Z",
     "iopub.status.idle": "2024-09-17T07:55:29.221733Z",
     "shell.execute_reply": "2024-09-17T07:55:29.221373Z",
     "shell.execute_reply.started": "2024-09-17T07:55:29.172063Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-6ca74808e6684662a5217e8442d469d8.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-6ca74808e6684662a5217e8442d469d8.vega-embed details,\n",
       "  #altair-viz-6ca74808e6684662a5217e8442d469d8.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-6ca74808e6684662a5217e8442d469d8\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-6ca74808e6684662a5217e8442d469d8\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-6ca74808e6684662a5217e8442d469d8\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"rect\"}, \"encoding\": {\"color\": {\"field\": \"Count\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"True\", \"type\": \"ordinal\"}, {\"field\": \"Predicted\", \"type\": \"ordinal\"}, {\"field\": \"Count\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Predicted\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}, \"y\": {\"field\": \"True\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}}, \"title\": \"OF_Using_FIRE 5B-2 SVM\"}, {\"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"middle\", \"fontSize\": 12}, \"encoding\": {\"color\": {\"condition\": {\"test\": \"(datum.Count > 146.5)\", \"value\": \"white\"}, \"value\": \"black\"}, \"text\": {\"field\": \"Count\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"True\", \"type\": \"ordinal\"}, {\"field\": \"Predicted\", \"type\": \"ordinal\"}, {\"field\": \"Count\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Predicted\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}, \"y\": {\"field\": \"True\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}}, \"title\": \"OF_Using_FIRE 5B-2 SVM\"}], \"data\": {\"name\": \"data-4811055dd3406847ea62f1020051a241\"}, \"height\": 300, \"width\": 400, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-4811055dd3406847ea62f1020051a241\": [{\"True\": \"Negative\", \"Predicted\": \"Negative\", \"Count\": 281}, {\"True\": \"Neutral\", \"Predicted\": \"Negative\", \"Count\": 45}, {\"True\": \"Positive\", \"Predicted\": \"Negative\", \"Count\": 3}, {\"True\": \"Negative\", \"Predicted\": \"Neutral\", \"Count\": 60}, {\"True\": \"Neutral\", \"Predicted\": \"Neutral\", \"Count\": 289}, {\"True\": \"Positive\", \"Predicted\": \"Neutral\", \"Count\": 48}, {\"True\": \"Negative\", \"Predicted\": \"Positive\", \"Count\": 0}, {\"True\": \"Neutral\", \"Predicted\": \"Positive\", \"Count\": 30}, {\"True\": \"Positive\", \"Predicted\": \"Positive\", \"Count\": 293}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import altair as alt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(true_labels, svm_validation_predictions)\n",
    "\n",
    "# Define class names\n",
    "class_names = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "# Convert confusion matrix to DataFrame\n",
    "cm_df = pd.DataFrame(cm, index=class_names, columns=class_names).reset_index().melt(id_vars='index')\n",
    "cm_df.columns = ['True', 'Predicted', 'Count']\n",
    "\n",
    "# Ensure the order of categories\n",
    "cm_df['True'] = pd.Categorical(cm_df['True'], categories=class_names, ordered=True)\n",
    "cm_df['Predicted'] = pd.Categorical(cm_df['Predicted'], categories=class_names, ordered=True)\n",
    "\n",
    "# Create the Altair plot\n",
    "heatmap = alt.Chart(cm_df).mark_rect().encode(\n",
    "    x=alt.X('Predicted:O', sort=class_names),\n",
    "    y=alt.Y('True:O', sort=class_names),\n",
    "    color='Count:Q',\n",
    "    tooltip=['True', 'Predicted', 'Count']\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=300,\n",
    "    title='OF_Using_FIRE 5B-2 SVM'\n",
    ")\n",
    "\n",
    "# Add text labels\n",
    "text = heatmap.mark_text(\n",
    "    align='center',\n",
    "    baseline='middle',\n",
    "    fontSize=12\n",
    ").encode(\n",
    "    text='Count:Q',\n",
    "    color=alt.condition(\n",
    "        alt.datum.Count > cm.max() / 2,\n",
    "        alt.value('white'),\n",
    "        alt.value('black')\n",
    "    )\n",
    ")\n",
    "\n",
    "# Combine heatmap and text\n",
    "final_chart = heatmap + text\n",
    "\n",
    "# Display the plot\n",
    "final_chart.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7edc2136-92a2-43da-ad64-0c21567703ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T07:55:29.222449Z",
     "iopub.status.busy": "2024-09-17T07:55:29.222341Z",
     "iopub.status.idle": "2024-09-17T07:55:29.267710Z",
     "shell.execute_reply": "2024-09-17T07:55:29.267212Z",
     "shell.execute_reply.started": "2024-09-17T07:55:29.222439Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to Results/Ensemble Model Results/On FireCS dataset/OF Using FIRE ENSEMBLE/Blending/OF_Using_FIRE 5B-2 SVM.png\n"
     ]
    }
   ],
   "source": [
    "# Specify the folder path\n",
    "folder_path = os.path.expanduser('Results/Ensemble Model Results/On FireCS dataset/OF Using FIRE ENSEMBLE/Blending/')\n",
    "\n",
    "# Save the plot using vl-convert\n",
    "file_path_png = os.path.join(folder_path, 'OF_Using_FIRE 5B-2 SVM.png')\n",
    "final_chart.save(file_path_png)\n",
    "\n",
    "print(f\"Plot saved to {file_path_png}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
