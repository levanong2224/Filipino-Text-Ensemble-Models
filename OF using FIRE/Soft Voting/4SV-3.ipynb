{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rAnJPEXtfyAH"
   },
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-09-22T15:23:40.314822Z",
     "iopub.status.busy": "2024-09-22T15:23:40.314656Z",
     "iopub.status.idle": "2024-09-22T15:23:40.426160Z",
     "shell.execute_reply": "2024-09-22T15:23:40.425919Z",
     "shell.execute_reply.started": "2024-09-22T15:23:40.314813Z"
    },
    "executionInfo": {
     "elapsed": 61789,
     "status": "ok",
     "timestamp": 1711541571499,
     "user": {
      "displayName": "LEONARD EVAN ONG",
      "userId": "13738954157101619104"
     },
     "user_tz": -480
    },
    "id": "lUT7AZcc1vgS",
    "outputId": "de0df3e0-048d-43ed-f146-28de1f7bf832"
   },
   "outputs": [],
   "source": [
    "# This automates data tabulation onto google sheets \n",
    "\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "import os\n",
    "\n",
    "# new directory path\n",
    "new_directory = '/Users/levan/ATENEO MASTERAL/Thesis'\n",
    "\n",
    "# Change the current working directory\n",
    "os.chdir(new_directory)\n",
    "\n",
    "# Use creds to create a client to interact with the Google Drive API\n",
    "scope = ['https://spreadsheets.google.com/feeds','https://www.googleapis.com/auth/drive']\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_name('thesis-432315-12daec8d1ff6.json', scope)\n",
    "\n",
    "service = build('sheets', 'v4', credentials=creds)\n",
    "\n",
    "client = gspread.authorize(creds)\n",
    "\n",
    "spreadsheet_id = '13Fk5oXX9B_mdHmNpMKQMy29y9iiHWrgQCa4hUTiQKD0' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "huMwc5Rqej4Z"
   },
   "source": [
    "# SOFT Voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T15:23:40.426697Z",
     "iopub.status.busy": "2024-09-22T15:23:40.426585Z",
     "iopub.status.idle": "2024-09-22T15:23:40.428101Z",
     "shell.execute_reply": "2024-09-22T15:23:40.427861Z",
     "shell.execute_reply.started": "2024-09-22T15:23:40.426691Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Specify the new directory path\n",
    "new_directory = '/Users/levan/ATENEO MASTERAL/Thesis/Development'\n",
    "\n",
    "# Change the current working directory\n",
    "os.chdir(new_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-09-22T15:23:40.428525Z",
     "iopub.status.busy": "2024-09-22T15:23:40.428460Z",
     "iopub.status.idle": "2024-09-22T15:23:42.072248Z",
     "shell.execute_reply": "2024-09-22T15:23:42.071947Z",
     "shell.execute_reply.started": "2024-09-22T15:23:40.428519Z"
    },
    "executionInfo": {
     "elapsed": 8623,
     "status": "ok",
     "timestamp": 1711542962088,
     "user": {
      "displayName": "LEONARD EVAN ONG",
      "userId": "13738954157101619104"
     },
     "user_tz": -480
    },
    "id": "sem7dvIrhBcS",
    "outputId": "a4b45244-dbd0-44d7-a7e6-06c6ef54678b"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AutoConfig\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "file_path = 'Corpus/FiReCS/FiReCS_data_b.csv'\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Split the data into training and test sets (70-30 split)\n",
    "train_df, test_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "\n",
    "# Extract texts and labels\n",
    "train_texts = train_df['review'].tolist()\n",
    "train_labels = train_df['label'].tolist()\n",
    "\n",
    "test_texts = test_df['review'].tolist()\n",
    "test_labels = test_df['label'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Models and Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T15:23:42.072872Z",
     "iopub.status.busy": "2024-09-22T15:23:42.072751Z",
     "iopub.status.idle": "2024-09-22T15:23:45.501132Z",
     "shell.execute_reply": "2024-09-22T15:23:45.500681Z",
     "shell.execute_reply.started": "2024-09-22T15:23:42.072864Z"
    },
    "executionInfo": {
     "elapsed": 8097,
     "status": "ok",
     "timestamp": 1711543494761,
     "user": {
      "displayName": "LEONARD EVAN ONG",
      "userId": "13738954157101619104"
     },
     "user_tz": -480
    },
    "id": "WJA7YA-s0ZoY"
   },
   "outputs": [],
   "source": [
    "def load_model_and_tokenizer(model_path, tokenizer_path, base_model):\n",
    "    # Load the tokenizer from the local directory\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "    \n",
    "    # Load the configuration from the base model, then update configuration if needed\n",
    "    config = AutoConfig.from_pretrained(base_model, num_labels=3)\n",
    "\n",
    "    # Initialize the model with the configuration\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_path, config=config)\n",
    "\n",
    "    # Ensure the model is in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    return model, tokenizer\n",
    "\n",
    "model_info = {   \n",
    "    \n",
    "    'HateBERT': {\n",
    "        'model_path': 'BERT models/1 FiReCS/fire_HateBERT-finetuned',\n",
    "        'tokenizer_path': 'BERT models/1 FiReCS/fire_HateBERT-finetuned',\n",
    "        'base_model': 'GroNLP/hateBERT'\n",
    "    },\n",
    "\n",
    "    'TagBERT': {\n",
    "        'model_path': 'BERT models/1 FiReCS/fire_Tag-Roberta-finetuned',\n",
    "        'tokenizer_path': 'BERT models/1 FiReCS/fire_Tag-Roberta-finetuned',\n",
    "        'base_model': 'jcblaise/roberta-tagalog-base'\n",
    "    },\n",
    "\n",
    "    'DeBERTa': {\n",
    "        'model_path': 'BERT models/1 FiReCS/fire_DeBERTa-finetuned',\n",
    "        'tokenizer_path': 'BERT models/1 FiReCS/fire_DeBERTa-finetuned',\n",
    "        'base_model': 'microsoft/deberta-v3-base'\n",
    "    },\n",
    "\n",
    "    'DistilBERT uncased': {\n",
    "        'model_path': 'BERT models/1 FiReCS/fire_distilbert-base-uncased-finetuned',\n",
    "        'tokenizer_path': 'BERT models/1 FiReCS/fire_distilbert-base-uncased-finetuned',\n",
    "        'base_model': 'distilbert/distilbert-base-uncased'\n",
    "    },    \n",
    "}\n",
    "\n",
    "models_and_tokenizers = {name: load_model_and_tokenizer(info['model_path'], \n",
    "                                                        info['tokenizer_path'], \n",
    "                                                        info['base_model']) \n",
    "                         for name, info in model_info.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T15:23:45.501914Z",
     "iopub.status.busy": "2024-09-22T15:23:45.501803Z",
     "iopub.status.idle": "2024-09-22T15:23:45.504293Z",
     "shell.execute_reply": "2024-09-22T15:23:45.504059Z",
     "shell.execute_reply.started": "2024-09-22T15:23:45.501907Z"
    }
   },
   "outputs": [],
   "source": [
    "def texts_to_dataloader(texts, tokenizer, batch_size=32):\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    encodings = tokenizer(texts, truncation=True, padding=True, max_length=512, return_tensors=\"pt\")\n",
    "\n",
    "    # Move tensors to the specified device\n",
    "    input_ids = encodings['input_ids'].to(device)\n",
    "    attention_mask = encodings['attention_mask'].to(device)\n",
    "    \n",
    "    dataset = TensorDataset(encodings['input_ids'], encodings['attention_mask'])\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Soft Voting and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T15:23:45.505750Z",
     "iopub.status.busy": "2024-09-22T15:23:45.505680Z",
     "iopub.status.idle": "2024-09-22T15:23:45.509305Z",
     "shell.execute_reply": "2024-09-22T15:23:45.509050Z",
     "shell.execute_reply.started": "2024-09-22T15:23:45.505744Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-09-22T15:23:45.509702Z",
     "iopub.status.busy": "2024-09-22T15:23:45.509641Z",
     "iopub.status.idle": "2024-09-22T15:24:06.466111Z",
     "shell.execute_reply": "2024-09-22T15:24:06.465739Z",
     "shell.execute_reply.started": "2024-09-22T15:23:45.509696Z"
    },
    "executionInfo": {
     "elapsed": 597765,
     "status": "ok",
     "timestamp": 1711544099100,
     "user": {
      "displayName": "LEONARD EVAN ONG",
      "userId": "13738954157101619104"
     },
     "user_tz": -480
    },
    "id": "BJBwRQqX5cGz",
    "outputId": "e75bd4e5-ea47-4f7f-9727-5b479b46d2e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1315.25 MiB, increment: 1.06 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "\n",
    "def soft_voting_predict(models_and_tokenizers, texts):\n",
    "    sum_probs = None\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    \n",
    "    # Loop through each model and its corresponding tokenizer\n",
    "    for name, (model, tokenizer) in models_and_tokenizers.items():\n",
    "        \n",
    "        # Explicitly move each model to the MPS device if available\n",
    "        model.to(device)\n",
    "        \n",
    "        dataloader = texts_to_dataloader(texts, tokenizer)\n",
    "        model_probs_list = []\n",
    "        for batch in dataloader:\n",
    "            input_ids, attention_mask = batch\n",
    "            input_ids, attention_mask = input_ids.to(device), attention_mask.to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "                model_probs_list.append(probs.cpu().numpy())\n",
    "        \n",
    "        model_probs = np.concatenate(model_probs_list)\n",
    "        \n",
    "        if sum_probs is None:\n",
    "            sum_probs = model_probs\n",
    "        else:\n",
    "            sum_probs += model_probs\n",
    "\n",
    "    # Average the probabilities\n",
    "    avg_probs = sum_probs / len(models_and_tokenizers)\n",
    "    \n",
    "    # Perform voting based on highest average probabilities\n",
    "    final_preds = np.argmax(avg_probs, axis=-1)\n",
    "    return final_preds\n",
    "\n",
    "# Perform inference and voting\n",
    "final_predictions = soft_voting_predict(models_and_tokenizers, test_texts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-09-22T15:24:06.466786Z",
     "iopub.status.busy": "2024-09-22T15:24:06.466703Z",
     "iopub.status.idle": "2024-09-22T15:24:06.473367Z",
     "shell.execute_reply": "2024-09-22T15:24:06.473132Z",
     "shell.execute_reply.started": "2024-09-22T15:24:06.466777Z"
    },
    "executionInfo": {
     "elapsed": 353,
     "status": "ok",
     "timestamp": 1711544865406,
     "user": {
      "displayName": "LEONARD EVAN ONG",
      "userId": "13738954157101619104"
     },
     "user_tz": -480
    },
    "id": "kfOa-DfAAvim",
    "outputId": "4f0a53a2-b147-49bc-ade9-efd21112bff2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8203919856830423\n",
      "Recall: 0.8157640650619533\n",
      "Ensemble accuracy: 0.8142655367231638\n",
      "F1 Score: 0.817405851659192\n",
      "Confusion Matrix:\n",
      "[[375  98   2]\n",
      " [ 65 383  43]\n",
      " [  6  49 395]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Calculate precision, recall, accuracy, and F1 score\n",
    "precision = precision_score(test_labels, final_predictions, average='macro')  # Adjust 'macro' as needed\n",
    "recall = recall_score(test_labels, final_predictions, average='macro')  # Adjust 'macro' as needed\n",
    "accuracy = accuracy_score(test_labels, final_predictions)  # Use the original test_labels list\n",
    "f1 = f1_score(test_labels, final_predictions, average='macro')  # Adjust 'macro' as needed\n",
    "\n",
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, final_predictions)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Ensemble accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T15:24:06.473750Z",
     "iopub.status.busy": "2024-09-22T15:24:06.473682Z",
     "iopub.status.idle": "2024-09-22T15:24:07.311271Z",
     "shell.execute_reply": "2024-09-22T15:24:07.309231Z",
     "shell.execute_reply.started": "2024-09-22T15:24:06.473744Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated cells count: 4\n"
     ]
    }
   ],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '4-3!B3:E3'  \n",
    "\n",
    "values = [[\n",
    "    f\"{precision * 100:.2f}\",\n",
    "    f\"{recall * 100:.2f}\",\n",
    "    f\"{accuracy * 100:.2f}\",\n",
    "    f\"{f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate on Data C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T15:24:07.314058Z",
     "iopub.status.busy": "2024-09-22T15:24:07.312966Z",
     "iopub.status.idle": "2024-09-22T15:24:07.331505Z",
     "shell.execute_reply": "2024-09-22T15:24:07.330776Z",
     "shell.execute_reply.started": "2024-09-22T15:24:07.314027Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Load validation data\n",
    "validation_file_path = 'Corpus/FiReCS/FiReCS_data_c.csv'\n",
    "validation_df = pd.read_csv(validation_file_path)\n",
    "\n",
    "\n",
    "# Prepare the validation texts and labels\n",
    "validation_texts = validation_df['review'].tolist()\n",
    "validation_labels = validation_df['label'].values  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Soft Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T15:24:07.333167Z",
     "iopub.status.busy": "2024-09-22T15:24:07.332679Z",
     "iopub.status.idle": "2024-09-22T15:24:22.620772Z",
     "shell.execute_reply": "2024-09-22T15:24:22.620430Z",
     "shell.execute_reply.started": "2024-09-22T15:24:07.333143Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1510.02 MiB, increment: 138.77 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "# Perform inference and voting on the validation texts\n",
    "validation_predictions = soft_voting_predict(models_and_tokenizers, validation_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T15:24:22.621433Z",
     "iopub.status.busy": "2024-09-22T15:24:22.621351Z",
     "iopub.status.idle": "2024-09-22T15:24:22.627049Z",
     "shell.execute_reply": "2024-09-22T15:24:22.626827Z",
     "shell.execute_reply.started": "2024-09-22T15:24:22.621425Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8266569596625901\n",
      "Recall: 0.8150497914188838\n",
      "Validation accuracy: 0.8150619637750238\n",
      "F1 Score: 0.8185208866155157\n",
      "Confusion Matrix:\n",
      "[[266  75   0]\n",
      " [ 35 295  34]\n",
      " [  2  48 294]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate precision, recall, accuracy, and F1 score\n",
    "precision = precision_score(validation_labels, validation_predictions, average='macro')  \n",
    "recall = recall_score(validation_labels, validation_predictions, average='macro')  \n",
    "accuracy = accuracy_score(validation_labels, validation_predictions)\n",
    "f1 = f1_score(validation_labels, validation_predictions, average='macro')  \n",
    "\n",
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(validation_labels, validation_predictions)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Validation accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T15:24:22.627563Z",
     "iopub.status.busy": "2024-09-22T15:24:22.627461Z",
     "iopub.status.idle": "2024-09-22T15:24:22.987037Z",
     "shell.execute_reply": "2024-09-22T15:24:22.986210Z",
     "shell.execute_reply.started": "2024-09-22T15:24:22.627557Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated cells count: 4\n"
     ]
    }
   ],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '4-3!F3:I3'  \n",
    "\n",
    "values = [[\n",
    "    f\"{precision * 100:.2f}\",\n",
    "    f\"{recall * 100:.2f}\",\n",
    "    f\"{accuracy * 100:.2f}\",\n",
    "    f\"{f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T15:24:22.989972Z",
     "iopub.status.busy": "2024-09-22T15:24:22.989538Z",
     "iopub.status.idle": "2024-09-22T15:24:23.172311Z",
     "shell.execute_reply": "2024-09-22T15:24:23.171942Z",
     "shell.execute_reply.started": "2024-09-22T15:24:22.989941Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-e45e91fbbf1346adaf826120b3ca69ec.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-e45e91fbbf1346adaf826120b3ca69ec.vega-embed details,\n",
       "  #altair-viz-e45e91fbbf1346adaf826120b3ca69ec.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-e45e91fbbf1346adaf826120b3ca69ec\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-e45e91fbbf1346adaf826120b3ca69ec\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-e45e91fbbf1346adaf826120b3ca69ec\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"rect\"}, \"encoding\": {\"color\": {\"field\": \"Count\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"True\", \"type\": \"ordinal\"}, {\"field\": \"Predicted\", \"type\": \"ordinal\"}, {\"field\": \"Count\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Predicted\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}, \"y\": {\"field\": \"True\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}}, \"title\": \"OF_Using_FIRE 4SV-3\"}, {\"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"middle\", \"fontSize\": 12}, \"encoding\": {\"color\": {\"condition\": {\"test\": \"(datum.Count > 147.5)\", \"value\": \"white\"}, \"value\": \"black\"}, \"text\": {\"field\": \"Count\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"True\", \"type\": \"ordinal\"}, {\"field\": \"Predicted\", \"type\": \"ordinal\"}, {\"field\": \"Count\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Predicted\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}, \"y\": {\"field\": \"True\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}}, \"title\": \"OF_Using_FIRE 4SV-3\"}], \"data\": {\"name\": \"data-4507101156b39f1df22cb80394923186\"}, \"height\": 300, \"width\": 400, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-4507101156b39f1df22cb80394923186\": [{\"True\": \"Negative\", \"Predicted\": \"Negative\", \"Count\": 266}, {\"True\": \"Neutral\", \"Predicted\": \"Negative\", \"Count\": 35}, {\"True\": \"Positive\", \"Predicted\": \"Negative\", \"Count\": 2}, {\"True\": \"Negative\", \"Predicted\": \"Neutral\", \"Count\": 75}, {\"True\": \"Neutral\", \"Predicted\": \"Neutral\", \"Count\": 295}, {\"True\": \"Positive\", \"Predicted\": \"Neutral\", \"Count\": 48}, {\"True\": \"Negative\", \"Predicted\": \"Positive\", \"Count\": 0}, {\"True\": \"Neutral\", \"Predicted\": \"Positive\", \"Count\": 34}, {\"True\": \"Positive\", \"Predicted\": \"Positive\", \"Count\": 294}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import altair as alt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(validation_labels, validation_predictions)\n",
    "\n",
    "# Define class names\n",
    "class_names = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "# Convert confusion matrix to DataFrame\n",
    "cm_df = pd.DataFrame(cm, index=class_names, columns=class_names).reset_index().melt(id_vars='index')\n",
    "cm_df.columns = ['True', 'Predicted', 'Count']\n",
    "\n",
    "# Ensure the order of categories\n",
    "cm_df['True'] = pd.Categorical(cm_df['True'], categories=class_names, ordered=True)\n",
    "cm_df['Predicted'] = pd.Categorical(cm_df['Predicted'], categories=class_names, ordered=True)\n",
    "\n",
    "# Create the Altair plot\n",
    "heatmap = alt.Chart(cm_df).mark_rect().encode(\n",
    "    x=alt.X('Predicted:O', sort=class_names),\n",
    "    y=alt.Y('True:O', sort=class_names),\n",
    "    color='Count:Q',\n",
    "    tooltip=['True', 'Predicted', 'Count']\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=300,\n",
    "    title='OF_Using_FIRE 4SV-3'\n",
    ")\n",
    "\n",
    "# Add text labels\n",
    "text = heatmap.mark_text(\n",
    "    align='center',\n",
    "    baseline='middle',\n",
    "    fontSize=12\n",
    ").encode(\n",
    "    text='Count:Q',\n",
    "    color=alt.condition(\n",
    "        alt.datum.Count > cm.max() / 2,\n",
    "        alt.value('white'),\n",
    "        alt.value('black')\n",
    "    )\n",
    ")\n",
    "\n",
    "# Combine heatmap and text\n",
    "final_chart = heatmap + text\n",
    "\n",
    "# Display the plot\n",
    "final_chart.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T15:24:23.172887Z",
     "iopub.status.busy": "2024-09-22T15:24:23.172803Z",
     "iopub.status.idle": "2024-09-22T15:24:23.609598Z",
     "shell.execute_reply": "2024-09-22T15:24:23.609266Z",
     "shell.execute_reply.started": "2024-09-22T15:24:23.172879Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to Results/Ensemble Model Results/On FireCS dataset/OF Using FIRE ENSEMBLE/Soft Voting/OF_Using_FIRE 4SV-3.png\n"
     ]
    }
   ],
   "source": [
    "# Specify the folder path\n",
    "folder_path = os.path.expanduser('Results/Ensemble Model Results/On FireCS dataset/OF Using FIRE ENSEMBLE/Soft Voting/')\n",
    "\n",
    "# Save the plot using vl-convert\n",
    "file_path_png = os.path.join(folder_path, 'OF_Using_FIRE 4SV-3.png')\n",
    "final_chart.save(file_path_png)\n",
    "\n",
    "print(f\"Plot saved to {file_path_png}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOelzqcxikjHNiyC4eC309U",
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0638df159ea540faae91dfa869dd2569": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ef14f76cfd8d43dfbe7ee25186cc759d",
      "placeholder": "​",
      "style": "IPY_MODEL_98b190a34515469c8018d8ea86ef64e9",
      "value": "config.json: 100%"
     }
    },
    "18ca60da34f74f01877b9cdd4f9e7b3f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2152101fab2c4bcdb6de728e2727e8ab",
      "max": 604,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_86388af23c6b444599df0eccfcd09aeb",
      "value": 604
     }
    },
    "2152101fab2c4bcdb6de728e2727e8ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6e37394538a842949cb0eac6ba4b715e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "86388af23c6b444599df0eccfcd09aeb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "98b190a34515469c8018d8ea86ef64e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b2bd860e5a134a4c824f1351502cd420": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6e37394538a842949cb0eac6ba4b715e",
      "placeholder": "​",
      "style": "IPY_MODEL_f04b6c43b7f0487ca4998f083cecac63",
      "value": " 604/604 [00:00&lt;00:00, 45.8kB/s]"
     }
    },
    "cd6b3893819949d6b46c44d4f34e1d44": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e3eb10c00acc4167b879e893e7784d80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0638df159ea540faae91dfa869dd2569",
       "IPY_MODEL_18ca60da34f74f01877b9cdd4f9e7b3f",
       "IPY_MODEL_b2bd860e5a134a4c824f1351502cd420"
      ],
      "layout": "IPY_MODEL_cd6b3893819949d6b46c44d4f34e1d44"
     }
    },
    "ef14f76cfd8d43dfbe7ee25186cc759d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f04b6c43b7f0487ca4998f083cecac63": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
