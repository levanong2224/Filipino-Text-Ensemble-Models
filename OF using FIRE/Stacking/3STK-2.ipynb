{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dc06b17-fcee-4505-bd74-d98376ce3ed9",
   "metadata": {},
   "source": [
    "# Train Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e69fd0a5-acb6-41af-8971-6adc9a85fcb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T05:27:17.438349Z",
     "iopub.status.busy": "2024-09-25T05:27:17.438272Z",
     "iopub.status.idle": "2024-09-25T05:27:17.994205Z",
     "shell.execute_reply": "2024-09-25T05:27:17.993918Z",
     "shell.execute_reply.started": "2024-09-25T05:27:17.438343Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.backends.mps.is_available():\n",
    "        # Currently, there's no separate manual seed function for MPS like torch.cuda.manual_seed_all()\n",
    "        pass \n",
    "    else:\n",
    "        print(\"MPS device not available. Using CPU.\")\n",
    "        \n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c6a724-b17e-46f6-aee6-90ef2f7877a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T15:08:53.465538Z",
     "iopub.status.busy": "2024-08-13T15:08:53.465321Z",
     "iopub.status.idle": "2024-08-13T15:08:53.469076Z",
     "shell.execute_reply": "2024-08-13T15:08:53.468592Z",
     "shell.execute_reply.started": "2024-08-13T15:08:53.465526Z"
    }
   },
   "source": [
    "Best F1 score BERT model on HS_C dataset are used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3823c3e6-976a-4eb9-a651-2cfeaa1a3cc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T05:27:17.994728Z",
     "iopub.status.busy": "2024-09-25T05:27:17.994605Z",
     "iopub.status.idle": "2024-09-25T05:27:18.129602Z",
     "shell.execute_reply": "2024-09-25T05:27:18.129242Z",
     "shell.execute_reply.started": "2024-09-25T05:27:17.994720Z"
    }
   },
   "outputs": [],
   "source": [
    "# This automates data tabulation onto google sheets \n",
    "\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "import os\n",
    "\n",
    "# new directory path\n",
    "new_directory = '/Users/levan/ATENEO MASTERAL/Thesis'\n",
    "\n",
    "# Change the current working directory\n",
    "os.chdir(new_directory)\n",
    "\n",
    "# Use creds to create a client to interact with the Google Drive API\n",
    "scope = ['https://spreadsheets.google.com/feeds','https://www.googleapis.com/auth/drive']\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_name('thesis-432315-12daec8d1ff6.json', scope)\n",
    "\n",
    "service = build('sheets', 'v4', credentials=creds)\n",
    "\n",
    "client = gspread.authorize(creds)\n",
    "\n",
    "spreadsheet_id = '13Fk5oXX9B_mdHmNpMKQMy29y9iiHWrgQCa4hUTiQKD0' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d70bdb-0504-41ef-913d-e4b7f778f561",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7b193db-3f30-4e5f-a38b-c254bf1e1976",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T05:27:18.130085Z",
     "iopub.status.busy": "2024-09-25T05:27:18.129990Z",
     "iopub.status.idle": "2024-09-25T05:27:19.446439Z",
     "shell.execute_reply": "2024-09-25T05:27:19.446125Z",
     "shell.execute_reply.started": "2024-09-25T05:27:18.130077Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AutoConfig\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_recall_curve, f1_score, confusion_matrix, precision_score, recall_score, accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "# new directory path\n",
    "new_directory = '/Users/levan/ATENEO MASTERAL/Thesis/Development'\n",
    "\n",
    "# Change the current working directory\n",
    "os.chdir(new_directory)\n",
    "\n",
    "#Load Data\n",
    "df = pd.read_csv('Corpus/FiReCS/FiReCS_data_b.csv')\n",
    "X = df['review'].values\n",
    "y = df['label'].values\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a307e67b-00c3-47aa-8f83-34bc62c93f83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-11T10:08:58.783500Z",
     "iopub.status.busy": "2024-04-11T10:08:58.782872Z",
     "iopub.status.idle": "2024-04-11T10:08:58.788089Z",
     "shell.execute_reply": "2024-04-11T10:08:58.787147Z",
     "shell.execute_reply.started": "2024-04-11T10:08:58.783465Z"
    }
   },
   "source": [
    "## Load Models and Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e666f7e-9db0-4666-a112-2af127307162",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T05:27:19.447000Z",
     "iopub.status.busy": "2024-09-25T05:27:19.446932Z",
     "iopub.status.idle": "2024-09-25T05:27:21.269970Z",
     "shell.execute_reply": "2024-09-25T05:27:21.269713Z",
     "shell.execute_reply.started": "2024-09-25T05:27:19.446994Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_model_and_tokenizer(model_path, tokenizer_path, base_model):\n",
    "    # Load the tokenizer from the local directory\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "    \n",
    "    # Load the configuration from the base model, then update configuration if needed\n",
    "    config = AutoConfig.from_pretrained(base_model, num_labels=3)\n",
    "\n",
    "    # Initialize the model with the configuration\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_path, config=config)\n",
    "\n",
    "    # Ensure the model is in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    return model, tokenizer\n",
    "\n",
    "model_info = {\n",
    "    \n",
    "    'DistilBERT cased': {\n",
    "        'model_path': 'BERT models/1 FiReCS/fire_distilbert-base-cased-finetuned',\n",
    "        'tokenizer_path': 'BERT models/1 FiReCS/fire_distilbert-base-cased-finetuned',\n",
    "        'base_model': 'distilbert/distilbert-base-cased'\n",
    "    },\n",
    "\n",
    "    'DeBERTa': {\n",
    "        'model_path': 'BERT models/1 FiReCS/fire_DeBERTa-finetuned',\n",
    "        'tokenizer_path': 'BERT models/1 FiReCS/fire_DeBERTa-finetuned',\n",
    "        'base_model': 'microsoft/deberta-v3-base'\n",
    "    },\n",
    "\n",
    "    'HateBERT': {\n",
    "        'model_path': 'BERT models/1 FiReCS/fire_HateBERT-finetuned',\n",
    "        'tokenizer_path': 'BERT models/1 FiReCS/fire_HateBERT-finetuned',\n",
    "        'base_model': 'GroNLP/hateBERT'\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "models_and_tokenizers = {name: load_model_and_tokenizer(info['model_path'], \n",
    "                                                        info['tokenizer_path'], \n",
    "                                                        info['base_model']) \n",
    "                         for name, info in model_info.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a9b906-a837-4de8-b8a2-05aa44074c5c",
   "metadata": {},
   "source": [
    "## Apply Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05f7b2f9-3bc4-4d6d-8595-8971899238c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T05:27:21.270547Z",
     "iopub.status.busy": "2024-09-25T05:27:21.270466Z",
     "iopub.status.idle": "2024-09-25T05:27:21.273331Z",
     "shell.execute_reply": "2024-09-25T05:27:21.273100Z",
     "shell.execute_reply.started": "2024-09-25T05:27:21.270540Z"
    }
   },
   "outputs": [],
   "source": [
    "class MultiModelTextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, labels, models_and_tokenizers, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.models_and_tokenizers = models_and_tokenizers\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.texts[index])\n",
    "        label = self.labels[index]\n",
    "\n",
    "        model_inputs = {}\n",
    "        for name, (model, tokenizer) in self.models_and_tokenizers.items():\n",
    "            encoding = tokenizer.encode_plus(\n",
    "                text,\n",
    "                add_special_tokens=True,\n",
    "                max_length=self.max_len,\n",
    "                return_token_type_ids=False,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                return_attention_mask=True,\n",
    "                return_tensors='pt',\n",
    "            )\n",
    "            model_inputs[name] = {\n",
    "                'input_ids': encoding['input_ids'].squeeze(0),  # Remove batch dimension\n",
    "                'attention_mask': encoding['attention_mask'].squeeze(0)  # Remove batch dimension\n",
    "            }\n",
    "        return {'model_inputs': model_inputs, 'label': torch.tensor(label, dtype=torch.long)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d574483-f790-48ba-a7d0-07cc8f2973d4",
   "metadata": {},
   "source": [
    "## BERT Training for Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e6167c5-79fd-4536-815c-237ec599453a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T05:27:21.274762Z",
     "iopub.status.busy": "2024-09-25T05:27:21.274679Z",
     "iopub.status.idle": "2024-09-25T05:27:21.277999Z",
     "shell.execute_reply": "2024-09-25T05:27:21.277782Z",
     "shell.execute_reply.started": "2024-09-25T05:27:21.274756Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_base_learner(model, data_loader, optimizer, device):\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    correct_predictions = 0\n",
    "    losses = []\n",
    "\n",
    "    for batch in data_loader:\n",
    "        # Accessing inputs for the current model\n",
    "        inputs = batch['model_inputs']\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        for model_name, model_inputs in inputs.items():\n",
    "            # Forward pass\n",
    "            outputs = model(input_ids=model_inputs['input_ids'].squeeze(1).to(device),\n",
    "                attention_mask=model_inputs['attention_mask'].squeeze(1).to(device),\n",
    "                labels=labels)\n",
    "\n",
    "            loss = outputs.loss\n",
    "            preds = outputs.logits.argmax(dim=1)\n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    return correct_predictions.float() / len(data_loader.dataset), np.mean(losses).astype(np.float32)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def eval_model(model, data_loader, device):\n",
    "    model = model.eval()\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for d in data_loader:\n",
    "            input_ids = d[\"input_ids\"].to(device)\n",
    "            attention_mask = d[\"attention_mask\"].to(device)\n",
    "            labels = d[\"label\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            preds = outputs.logits.argmax(dim=1)\n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "\n",
    "    return correct_predictions.double() / len(data_loader.dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b36fee-48a1-4eda-bf0b-c59982cbba14",
   "metadata": {},
   "source": [
    "## Train Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99eb6be0-fb6e-441b-bfaa-853e75a01983",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T05:27:21.279006Z",
     "iopub.status.busy": "2024-09-25T05:27:21.278947Z",
     "iopub.status.idle": "2024-09-25T05:27:21.286918Z",
     "shell.execute_reply": "2024-09-25T05:27:21.286673Z",
     "shell.execute_reply.started": "2024-09-25T05:27:21.279000Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, confusion_matrix\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "\n",
    "def train_stacking_classifier(models_and_tokenizers, X_train, y_train, device, max_len=128):\n",
    "    n_splits = 4\n",
    "    skf = StratifiedKFold(n_splits=n_splits)\n",
    "    base_learners_predictions_train = np.zeros((len(X_train), len(models_and_tokenizers)))\n",
    "    fold_idx = 0\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_train, y_train):\n",
    "        fold_idx += 1\n",
    "        print(f\"Training fold {fold_idx}/{n_splits}...\")\n",
    "        train_texts, val_texts = X_train[train_idx], X_train[val_idx]\n",
    "        train_labels, val_labels = y_train[train_idx], y_train[val_idx]\n",
    "        \n",
    "        model_idx = 0\n",
    "        for name, info in model_info.items():\n",
    "            # Reload the model and tokenizer to reset weights\n",
    "            model, tokenizer = load_model_and_tokenizer(info['model_path'], info['tokenizer_path'], info['base_model'])\n",
    "            model.to(device)\n",
    "            \n",
    "            train_dataset = MultiModelTextDataset(train_texts, train_labels, {name: (model, tokenizer)}, max_len)\n",
    "            val_dataset = MultiModelTextDataset(val_texts, val_labels, {name: (model, tokenizer)}, max_len)\n",
    "            train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "            \n",
    "            optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "            train_base_learner(model, train_loader, optimizer, device)\n",
    "            \n",
    "            val_preds = []\n",
    "            model.eval()\n",
    "            for batch in val_loader:\n",
    "                inputs = batch['model_inputs'][name]\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(input_ids=inputs['input_ids'].to(device), attention_mask=inputs['attention_mask'].to(device))\n",
    "                val_preds.extend(outputs.logits.argmax(dim=1).cpu().numpy())\n",
    "            \n",
    "            base_learners_predictions_train[val_idx, model_idx] = np.array(val_preds)\n",
    "            model_idx += 1\n",
    "\n",
    "    return base_learners_predictions_train, y_train\n",
    "    \n",
    "\n",
    "def get_predictions(model_info, X, y, device, max_len=128):\n",
    "    predictions = np.zeros((len(X), len(model_info)))\n",
    "    model_idx = 0\n",
    "    for name, info in model_info.items():\n",
    "        # Reload the model and tokenizer\n",
    "        model, tokenizer = load_model_and_tokenizer(info['model_path'], info['tokenizer_path'], info['base_model'])\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        \n",
    "        dataset = MultiModelTextDataset(X, y, {name: (model, tokenizer)}, max_len)\n",
    "        loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
    "        \n",
    "        preds = []\n",
    "        for batch in loader:\n",
    "            inputs = batch['model_inputs'][name]\n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_ids=inputs['input_ids'].to(device), attention_mask=inputs['attention_mask'].to(device))\n",
    "            preds.extend(outputs.logits.argmax(dim=1).cpu().numpy())\n",
    "        \n",
    "        predictions[:, model_idx] = np.array(preds)\n",
    "        model_idx += 1\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58472c03-8cb9-4a28-b8f3-fd5227c0e620",
   "metadata": {},
   "source": [
    "## Perform Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da0e67bd-3f57-4bf1-aa4e-1537a9132002",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T05:27:21.287536Z",
     "iopub.status.busy": "2024-09-25T05:27:21.287402Z",
     "iopub.status.idle": "2024-09-25T05:27:21.290885Z",
     "shell.execute_reply": "2024-09-25T05:27:21.290598Z",
     "shell.execute_reply.started": "2024-09-25T05:27:21.287529Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36436c2d-846d-46ab-ae3c-b36c5bdda6a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T05:27:21.291350Z",
     "iopub.status.busy": "2024-09-25T05:27:21.291274Z",
     "iopub.status.idle": "2024-09-25T05:35:57.315823Z",
     "shell.execute_reply": "2024-09-25T05:35:57.315481Z",
     "shell.execute_reply.started": "2024-09-25T05:27:21.291344Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/transformers/optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 2/4...\n",
      "Training fold 3/4...\n",
      "Training fold 4/4...\n",
      "peak memory: 3690.56 MiB, increment: 1774.05 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# Train stacking classifier (using 4-fold cross validation for each BERT model) on Train Set and retrieve training meta-features\n",
    "train_meta_features, _ = train_stacking_classifier(model_info, X_train, y_train, device)\n",
    "\n",
    "# Generate predictions for the test set to be used as test meta-features\n",
    "test_meta_features = get_predictions(model_info, X_test, y_test, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d42e0b-1855-4774-8f83-599a6158e526",
   "metadata": {},
   "source": [
    "### Train LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "265a5311-c2a4-48a0-9f21-d803350fb89f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T05:35:57.316512Z",
     "iopub.status.busy": "2024-09-25T05:35:57.316412Z",
     "iopub.status.idle": "2024-09-25T05:35:58.224284Z",
     "shell.execute_reply": "2024-09-25T05:35:58.223856Z",
     "shell.execute_reply.started": "2024-09-25T05:35:57.316503Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 2210.11 MiB, increment: 1.61 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "\n",
    "lr_meta_classifier = LogisticRegression()\n",
    "lr_meta_classifier.fit(train_meta_features, y_train)\n",
    "\n",
    "lr_final_predictions = lr_meta_classifier.predict(test_meta_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ea06bb-fab4-4f49-99e4-19680ec1b870",
   "metadata": {},
   "source": [
    "### Train NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "244b0f68-e401-4d18-913f-a3a153dd8104",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T05:35:58.225149Z",
     "iopub.status.busy": "2024-09-25T05:35:58.225038Z",
     "iopub.status.idle": "2024-09-25T05:35:59.163272Z",
     "shell.execute_reply": "2024-09-25T05:35:59.162901Z",
     "shell.execute_reply.started": "2024-09-25T05:35:58.225137Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 2210.27 MiB, increment: 0.14 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "\n",
    "nb_meta_classifier = GaussianNB()\n",
    "nb_meta_classifier.fit(train_meta_features, y_train)\n",
    "\n",
    "nb_final_predictions = nb_meta_classifier.predict(test_meta_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e50604f-9bef-4db4-bf92-89f9d2874e89",
   "metadata": {},
   "source": [
    "### Train DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3990ca03-b860-4b65-97e7-47f551754ab7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T05:35:59.163946Z",
     "iopub.status.busy": "2024-09-25T05:35:59.163859Z",
     "iopub.status.idle": "2024-09-25T05:36:00.634390Z",
     "shell.execute_reply": "2024-09-25T05:36:00.634047Z",
     "shell.execute_reply.started": "2024-09-25T05:35:59.163938Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 2210.59 MiB, increment: 0.33 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "\n",
    "dt_meta_classifier = DecisionTreeClassifier(max_depth=None)\n",
    "dt_meta_classifier.fit(train_meta_features, y_train)\n",
    "\n",
    "dt_final_predictions = dt_meta_classifier.predict(test_meta_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986bd8f0-b569-4eaf-8e13-a51529e871e6",
   "metadata": {},
   "source": [
    "### Train SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "460a4087-b343-4249-b794-db90baabf11c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T05:36:00.635072Z",
     "iopub.status.busy": "2024-09-25T05:36:00.634978Z",
     "iopub.status.idle": "2024-09-25T05:36:01.487119Z",
     "shell.execute_reply": "2024-09-25T05:36:01.486726Z",
     "shell.execute_reply.started": "2024-09-25T05:36:00.635063Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 2217.25 MiB, increment: 6.66 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "\n",
    "svm_meta_classifier = SVC(kernel='linear', probability=True)\n",
    "svm_meta_classifier.fit(train_meta_features, y_train)\n",
    "\n",
    "svm_final_predictions = svm_meta_classifier.predict(test_meta_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad340b68-d07e-473a-bbc4-138ef8e0271a",
   "metadata": {},
   "source": [
    "## EVALUATE MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93ba0c5-a053-45fb-8e97-b09c67959bc8",
   "metadata": {},
   "source": [
    "### LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d015915-5eb9-4a73-9ef6-5fc1bd4d0e8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T05:36:01.487874Z",
     "iopub.status.busy": "2024-09-25T05:36:01.487769Z",
     "iopub.status.idle": "2024-09-25T05:36:01.493621Z",
     "shell.execute_reply": "2024-09-25T05:36:01.493356Z",
     "shell.execute_reply.started": "2024-09-25T05:36:01.487864Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Precision: 0.8249747289163923\n",
      "Recall: 0.81974853899726\n",
      "Ensemble accuracy: 0.8192090395480226\n",
      "F1 Score: 0.821627771505307\n",
      "Confusion Matrix:\n",
      "[[367  90   3]\n",
      " [ 60 386  45]\n",
      " [  3  55 407]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "precision = precision_score(y_test, lr_final_predictions, average='macro')\n",
    "recall = recall_score(y_test, lr_final_predictions, average='macro')\n",
    "accuracy = accuracy_score(y_test, lr_final_predictions)\n",
    "f1 = f1_score(y_test, lr_final_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_test, lr_final_predictions)\n",
    "\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Ensemble accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8c650bc-c7b7-4f3d-b8c7-c415ed29f2f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T05:36:01.494171Z",
     "iopub.status.busy": "2024-09-25T05:36:01.494087Z",
     "iopub.status.idle": "2024-09-25T05:36:01.504548Z",
     "shell.execute_reply": "2024-09-25T05:36:01.504271Z",
     "shell.execute_reply.started": "2024-09-25T05:36:01.494164Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized thresholds for each class: [0.3432560170040141, 0.2952466603044054, 0.508370728847482]\n",
      "Logistic Regression\n",
      "Precision: 0.8250\n",
      "Recall: 0.8197\n",
      "Ensemble accuracy: 0.8192\n",
      "F1 Score: 0.821627771505307\n",
      "Confusion Matrix:\n",
      "[[367  90   3]\n",
      " [ 60 386  45]\n",
      " [  3  55 407]]\n"
     ]
    }
   ],
   "source": [
    "probabilities = lr_meta_classifier.predict_proba(test_meta_features)\n",
    "\n",
    "# Calculate precision-recall curve and find optimal thresholds for each class\n",
    "lr_thresh = []\n",
    "for i in range(probabilities.shape[1]):  # Iterate over each class\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test == i, probabilities[:, i])\n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "    optimal_idx = np.nanargmax(f1_scores)  # Handle cases where precision and recall are both zero\n",
    "    lr_thresh.append(thresholds[optimal_idx])\n",
    "\n",
    "# Apply the optimized thresholds to make adjusted predictions\n",
    "adjusted_predictions = np.array([np.argmax([probabilities[i, j] if probabilities[i, j] >= lr_thresh[j] else 0\n",
    "                                         for j in range(probabilities.shape[1])])\n",
    "                              for i in range(len(probabilities))])\n",
    "\n",
    "# Evaluate\n",
    "adjusted_precision = precision_score(y_test, adjusted_predictions, average='macro')\n",
    "adjusted_recall = recall_score(y_test, adjusted_predictions, average='macro')\n",
    "adjusted_accuracy = accuracy_score(y_test, adjusted_predictions)\n",
    "adjusted_f1 = f1_score(y_test, adjusted_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_test, adjusted_predictions)\n",
    "\n",
    "print(\"Optimized thresholds for each class:\", lr_thresh)\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Precision: {adjusted_precision:.4f}\")\n",
    "print(f\"Recall: {adjusted_recall:.4f}\")\n",
    "print(f\"Ensemble accuracy: {adjusted_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {adjusted_f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfc6b32b-5f2a-4017-8a2b-e393ee1f85b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T05:36:01.505135Z",
     "iopub.status.busy": "2024-09-25T05:36:01.505038Z",
     "iopub.status.idle": "2024-09-25T05:36:03.003035Z",
     "shell.execute_reply": "2024-09-25T05:36:03.001499Z",
     "shell.execute_reply.started": "2024-09-25T05:36:01.505108Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated cells count: 4\n"
     ]
    }
   ],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '3-2!B4:E4'  \n",
    "\n",
    "values = [[\n",
    "    f\"{adjusted_precision * 100:.2f}\",\n",
    "    f\"{adjusted_recall * 100:.2f}\",\n",
    "    f\"{adjusted_accuracy * 100:.2f}\",\n",
    "    f\"{adjusted_f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f311d02-936c-467e-ae14-e0c9cd0f0211",
   "metadata": {},
   "source": [
    "### NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3cde7aba-1d7b-4fbd-94f0-98b9e5b2756a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T05:36:03.004988Z",
     "iopub.status.busy": "2024-09-25T05:36:03.004727Z",
     "iopub.status.idle": "2024-09-25T05:36:03.020434Z",
     "shell.execute_reply": "2024-09-25T05:36:03.019692Z",
     "shell.execute_reply.started": "2024-09-25T05:36:03.004965Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes\n",
      "Precision: 0.8242133325879702\n",
      "Recall: 0.8182768879887848\n",
      "Ensemble accuracy: 0.8177966101694916\n",
      "F1 Score: 0.8204003786349573\n",
      "Confusion Matrix:\n",
      "[[367  90   3]\n",
      " [ 60 387  44]\n",
      " [  3  58 404]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "precision = precision_score(y_test, nb_final_predictions, average='macro')\n",
    "recall = recall_score(y_test, nb_final_predictions, average='macro')\n",
    "accuracy = accuracy_score(y_test, nb_final_predictions)\n",
    "f1 = f1_score(y_test, nb_final_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_test, nb_final_predictions)\n",
    "\n",
    "print(\"Naive Bayes\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Ensemble accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07991bda-71ea-4786-996b-61a3ae0132ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T05:36:03.021932Z",
     "iopub.status.busy": "2024-09-25T05:36:03.021538Z",
     "iopub.status.idle": "2024-09-25T05:36:03.039381Z",
     "shell.execute_reply": "2024-09-25T05:36:03.038902Z",
     "shell.execute_reply.started": "2024-09-25T05:36:03.021910Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized thresholds for each class: [0.02745962487858432, 0.18658077444627344, 0.46613090408909486]\n",
      "Naive Bayes\n",
      "Precision: 0.8242\n",
      "Recall: 0.8183\n",
      "Ensemble accuracy: 0.8178\n",
      "F1 Score: 0.8204003786349573\n",
      "Confusion Matrix:\n",
      "[[367  90   3]\n",
      " [ 60 387  44]\n",
      " [  3  58 404]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d8/nbkwtx_953q99tk0ckh0v0v40000gn/T/ipykernel_6868/3670015346.py:7: RuntimeWarning: invalid value encountered in divide\n",
      "  f1_scores = 2 * (precision * recall) / (precision + recall)\n"
     ]
    }
   ],
   "source": [
    "probabilities = nb_meta_classifier.predict_proba(test_meta_features)\n",
    "\n",
    "# Calculate precision-recall curve and find optimal thresholds for each class\n",
    "nb_thresh = []\n",
    "for i in range(probabilities.shape[1]):  # Iterate over each class\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test == i, probabilities[:, i])\n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "    optimal_idx = np.nanargmax(f1_scores)  # Handle cases where precision and recall are both zero\n",
    "    nb_thresh.append(thresholds[optimal_idx])\n",
    "\n",
    "# Apply the optimized thresholds to make adjusted predictions\n",
    "adjusted_predictions = np.array([np.argmax([probabilities[i, j] if probabilities[i, j] >= nb_thresh[j] else 0\n",
    "                                         for j in range(probabilities.shape[1])])\n",
    "                              for i in range(len(probabilities))])\n",
    "\n",
    "# Evaluate\n",
    "adjusted_precision = precision_score(y_test, adjusted_predictions, average='macro')\n",
    "adjusted_recall = recall_score(y_test, adjusted_predictions, average='macro')\n",
    "adjusted_accuracy = accuracy_score(y_test, adjusted_predictions)\n",
    "adjusted_f1 = f1_score(y_test, adjusted_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_test, adjusted_predictions)\n",
    "\n",
    "print(\"Optimized thresholds for each class:\", nb_thresh)\n",
    "print(\"Naive Bayes\")\n",
    "print(f\"Precision: {adjusted_precision:.4f}\")\n",
    "print(f\"Recall: {adjusted_recall:.4f}\")\n",
    "print(f\"Ensemble accuracy: {adjusted_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {adjusted_f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aecf64b8-5a1a-4cea-a077-2049e0459dd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T05:36:03.040036Z",
     "iopub.status.busy": "2024-09-25T05:36:03.039923Z",
     "iopub.status.idle": "2024-09-25T05:36:03.717164Z",
     "shell.execute_reply": "2024-09-25T05:36:03.716219Z",
     "shell.execute_reply.started": "2024-09-25T05:36:03.040027Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated cells count: 4\n"
     ]
    }
   ],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '3-2!B5:E5'  \n",
    "\n",
    "values = [[\n",
    "    f\"{adjusted_precision * 100:.2f}\",\n",
    "    f\"{adjusted_recall * 100:.2f}\",\n",
    "    f\"{adjusted_accuracy * 100:.2f}\",\n",
    "    f\"{adjusted_f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958d063b-7c6a-43d7-aaa2-0b93e3d56610",
   "metadata": {},
   "source": [
    "### DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c799950-2309-4a08-9778-351ab70a85db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T05:36:03.725546Z",
     "iopub.status.busy": "2024-09-25T05:36:03.725253Z",
     "iopub.status.idle": "2024-09-25T05:36:03.737725Z",
     "shell.execute_reply": "2024-09-25T05:36:03.737081Z",
     "shell.execute_reply.started": "2024-09-25T05:36:03.725526Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Precision: 0.8238599873485776\n",
      "Recall: 0.8206561808993232\n",
      "Ensemble accuracy: 0.8199152542372882\n",
      "F1 Score: 0.8219326133891497\n",
      "Confusion Matrix:\n",
      "[[372  83   5]\n",
      " [ 64 382  45]\n",
      " [  5  53 407]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "precision = precision_score(y_test, dt_final_predictions, average='macro')\n",
    "recall = recall_score(y_test, dt_final_predictions, average='macro')\n",
    "accuracy = accuracy_score(y_test, dt_final_predictions)\n",
    "f1 = f1_score(y_test, dt_final_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_test, dt_final_predictions)\n",
    "\n",
    "print(\"Decision Tree\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Ensemble accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a63b5fc-8c61-409f-86bf-470f00eb6d99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T05:36:03.739052Z",
     "iopub.status.busy": "2024-09-25T05:36:03.738756Z",
     "iopub.status.idle": "2024-09-25T05:36:03.754148Z",
     "shell.execute_reply": "2024-09-25T05:36:03.753849Z",
     "shell.execute_reply.started": "2024-09-25T05:36:03.739031Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized thresholds for each class: [0.36585365853658536, 0.40217391304347827, 0.6052631578947368]\n",
      "Decision Tree\n",
      "Precision: 0.8239\n",
      "Recall: 0.8207\n",
      "Ensemble accuracy: 0.8199\n",
      "F1 Score: 0.8219326133891497\n",
      "Confusion Matrix:\n",
      "[[372  83   5]\n",
      " [ 64 382  45]\n",
      " [  5  53 407]]\n"
     ]
    }
   ],
   "source": [
    "probabilities = dt_meta_classifier.predict_proba(test_meta_features)\n",
    "\n",
    "# Calculate precision-recall curve and find optimal thresholds for each class\n",
    "dt_thresh = []\n",
    "for i in range(probabilities.shape[1]):  # Iterate over each class\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test == i, probabilities[:, i])\n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "    optimal_idx = np.nanargmax(f1_scores)  # Handle cases where precision and recall are both zero\n",
    "    dt_thresh.append(thresholds[optimal_idx])\n",
    "\n",
    "# Apply the optimized thresholds to make adjusted predictions\n",
    "adjusted_predictions = np.array([np.argmax([probabilities[i, j] if probabilities[i, j] >= dt_thresh[j] else 0\n",
    "                                         for j in range(probabilities.shape[1])])\n",
    "                              for i in range(len(probabilities))])\n",
    "\n",
    "# Evaluate\n",
    "adjusted_precision = precision_score(y_test, adjusted_predictions, average='macro')\n",
    "adjusted_recall = recall_score(y_test, adjusted_predictions, average='macro')\n",
    "adjusted_accuracy = accuracy_score(y_test, adjusted_predictions)\n",
    "adjusted_f1 = f1_score(y_test, adjusted_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_test, adjusted_predictions)\n",
    "\n",
    "print(\"Optimized thresholds for each class:\", dt_thresh)\n",
    "print(\"Decision Tree\")\n",
    "print(f\"Precision: {adjusted_precision:.4f}\")\n",
    "print(f\"Recall: {adjusted_recall:.4f}\")\n",
    "print(f\"Ensemble accuracy: {adjusted_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {adjusted_f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9653e844-4196-4d63-9b61-4998f3dba2d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T05:36:03.754774Z",
     "iopub.status.busy": "2024-09-25T05:36:03.754650Z",
     "iopub.status.idle": "2024-09-25T05:36:04.172209Z",
     "shell.execute_reply": "2024-09-25T05:36:04.171084Z",
     "shell.execute_reply.started": "2024-09-25T05:36:03.754765Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated cells count: 4\n"
     ]
    }
   ],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '3-2!B6:E6'  \n",
    "\n",
    "values = [[\n",
    "    f\"{adjusted_precision * 100:.2f}\",\n",
    "    f\"{adjusted_recall * 100:.2f}\",\n",
    "    f\"{adjusted_accuracy * 100:.2f}\",\n",
    "    f\"{adjusted_f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24614471-4cf3-4349-b8bb-98715c2db8a9",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f5a4d67-5a7a-4f32-b9c4-6f5c7612a256",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T05:36:04.174645Z",
     "iopub.status.busy": "2024-09-25T05:36:04.174127Z",
     "iopub.status.idle": "2024-09-25T05:36:04.188303Z",
     "shell.execute_reply": "2024-09-25T05:36:04.187793Z",
     "shell.execute_reply.started": "2024-09-25T05:36:04.174609Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "Precision: 0.8132355596073367\n",
      "Recall: 0.8111206009241618\n",
      "Ensemble accuracy: 0.8100282485875706\n",
      "F1 Score: 0.8117958776276343\n",
      "Confusion Matrix:\n",
      "[[368  90   2]\n",
      " [ 60 368  63]\n",
      " [  4  50 411]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "precision = precision_score(y_test, svm_final_predictions, average='macro')\n",
    "recall = recall_score(y_test, svm_final_predictions, average='macro')\n",
    "accuracy = accuracy_score(y_test, svm_final_predictions)\n",
    "f1 = f1_score(y_test, svm_final_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_test, svm_final_predictions)\n",
    "\n",
    "print(\"SVM\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Ensemble accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f4bf24f-5e38-4acf-b0d1-c42ddb5a862f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T05:36:04.189487Z",
     "iopub.status.busy": "2024-09-25T05:36:04.189237Z",
     "iopub.status.idle": "2024-09-25T05:36:04.230482Z",
     "shell.execute_reply": "2024-09-25T05:36:04.230106Z",
     "shell.execute_reply.started": "2024-09-25T05:36:04.189472Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized thresholds for each class: [0.13166691310975756, 0.15977674906186304, 0.7928568250721233]\n",
      "Logistic Regression\n",
      "Precision: 0.7808\n",
      "Recall: 0.7775\n",
      "Ensemble accuracy: 0.7761\n",
      "F1 Score: 0.7787215854808972\n",
      "Confusion Matrix:\n",
      "[[356 102   2]\n",
      " [108 345  38]\n",
      " [ 21  46 398]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d8/nbkwtx_953q99tk0ckh0v0v40000gn/T/ipykernel_6868/2603681419.py:7: RuntimeWarning: invalid value encountered in divide\n",
      "  f1_scores = 2 * (precision * recall) / (precision + recall)\n"
     ]
    }
   ],
   "source": [
    "probabilities = svm_meta_classifier.predict_proba(test_meta_features)\n",
    "\n",
    "# Calculate precision-recall curve and find optimal thresholds for each class\n",
    "svm_thresh = []\n",
    "for i in range(probabilities.shape[1]):  # Iterate over each class\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test == i, probabilities[:, i])\n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "    optimal_idx = np.nanargmax(f1_scores)  # Handle cases where precision and recall are both zero\n",
    "    svm_thresh.append(thresholds[optimal_idx])\n",
    "\n",
    "# Apply the optimized thresholds to make adjusted predictions\n",
    "adjusted_predictions = np.array([np.argmax([probabilities[i, j] if probabilities[i, j] >= svm_thresh[j] else 0\n",
    "                                         for j in range(probabilities.shape[1])])\n",
    "                              for i in range(len(probabilities))])\n",
    "\n",
    "# Evaluate\n",
    "adjusted_precision = precision_score(y_test, adjusted_predictions, average='macro')\n",
    "adjusted_recall = recall_score(y_test, adjusted_predictions, average='macro')\n",
    "adjusted_accuracy = accuracy_score(y_test, adjusted_predictions)\n",
    "adjusted_f1 = f1_score(y_test, adjusted_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_test, adjusted_predictions)\n",
    "\n",
    "print(\"Optimized thresholds for each class:\", svm_thresh)\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Precision: {adjusted_precision:.4f}\")\n",
    "print(f\"Recall: {adjusted_recall:.4f}\")\n",
    "print(f\"Ensemble accuracy: {adjusted_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {adjusted_f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "92382252-0d77-45d8-bb20-8c5c7f2a983b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T05:36:04.231075Z",
     "iopub.status.busy": "2024-09-25T05:36:04.230984Z",
     "iopub.status.idle": "2024-09-25T05:36:04.637085Z",
     "shell.execute_reply": "2024-09-25T05:36:04.636294Z",
     "shell.execute_reply.started": "2024-09-25T05:36:04.231067Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated cells count: 4\n"
     ]
    }
   ],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '3-2!B7:E7'  \n",
    "\n",
    "values = [[\n",
    "    f\"{adjusted_precision * 100:.2f}\",\n",
    "    f\"{adjusted_recall * 100:.2f}\",\n",
    "    f\"{adjusted_accuracy * 100:.2f}\",\n",
    "    f\"{adjusted_f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0143f6-14c3-431a-b08b-7f182a0c7c96",
   "metadata": {},
   "source": [
    "## TEST DATA C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a7c1fca-bf56-43cf-8559-e8acfd5dc262",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T05:36:04.639487Z",
     "iopub.status.busy": "2024-09-25T05:36:04.638808Z",
     "iopub.status.idle": "2024-09-25T05:36:22.119476Z",
     "shell.execute_reply": "2024-09-25T05:36:22.119030Z",
     "shell.execute_reply.started": "2024-09-25T05:36:04.639452Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Load validation data\n",
    "validation_file_path = 'Corpus/FiReCS/FiReCS_data_c.csv'\n",
    "validation_df = pd.read_csv(validation_file_path)\n",
    "\n",
    "X_val = validation_df['review'].values \n",
    "y_val = validation_df['label'].values\n",
    "\n",
    "# Generate meta-features for data c dataset\n",
    "val_meta_features = get_predictions(model_info, X_val, y_val, device) \n",
    "\n",
    "# Predict using the logistic regression meta-classifier\n",
    "val_lr_predictions = lr_meta_classifier.predict(val_meta_features)\n",
    "\n",
    "# Predict using the naive bayes meta-classifier\n",
    "val_nb_predictions = nb_meta_classifier.predict(val_meta_features)\n",
    "\n",
    "# Predict using the decision tree meta-classifier\n",
    "val_dt_predictions = dt_meta_classifier.predict(val_meta_features)\n",
    "\n",
    "# Predict using the svm meta-classifier\n",
    "val_svm_predictions = svm_meta_classifier.predict(val_meta_features)\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0693ac-17b2-4645-be71-fe4c1f337e38",
   "metadata": {},
   "source": [
    "### LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5303f868-1507-4252-9f50-136aa337f630",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T05:36:22.119941Z",
     "iopub.status.busy": "2024-09-25T05:36:22.119864Z",
     "iopub.status.idle": "2024-09-25T05:36:22.125696Z",
     "shell.execute_reply": "2024-09-25T05:36:22.125421Z",
     "shell.execute_reply.started": "2024-09-25T05:36:22.119933Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on HS-Data C Dataset\n",
      "Precision: 0.8010453674482698\n",
      "Recall: 0.7969647881500844\n",
      "Accuracy: 0.7959961868446139\n",
      "F1 Score: 0.7985658616866728\n",
      "Confusion Matrix:\n",
      "[[268  71   2]\n",
      " [ 52 271  41]\n",
      " [  3  45 296]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the predictions\n",
    "precision = precision_score(y_val, val_lr_predictions, average='macro')\n",
    "recall = recall_score(y_val, val_lr_predictions, average='macro')\n",
    "accuracy = accuracy_score(y_val, val_lr_predictions)\n",
    "f1 = f1_score(y_val, val_lr_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_val, val_lr_predictions)\n",
    "\n",
    "print(\"Evaluation on HS-Data C Dataset\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d732e24d-540c-4934-a359-e7098db0eaaf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T05:36:22.126117Z",
     "iopub.status.busy": "2024-09-25T05:36:22.126055Z",
     "iopub.status.idle": "2024-09-25T05:36:22.134203Z",
     "shell.execute_reply": "2024-09-25T05:36:22.133955Z",
     "shell.execute_reply.started": "2024-09-25T05:36:22.126111Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results\n",
      "Precision: 0.8010\n",
      "Recall: 0.7970\n",
      "Accuracy: 0.7960\n",
      "F1 Score: 0.7986\n",
      "Confusion Matrix:\n",
      "[[268  71   2]\n",
      " [ 52 271  41]\n",
      " [  3  45 296]]\n"
     ]
    }
   ],
   "source": [
    "lr_validation_probabilities = lr_meta_classifier.predict_proba(val_meta_features)\n",
    "\n",
    "# Apply thresholds to the validation set probabilities to make final predictions\n",
    "lr_validation_predictions = np.array([np.argmax([lr_validation_probabilities[i, j] if lr_validation_probabilities[i, j] >= lr_thresh[j] else 0\n",
    "                                              for j in range(lr_validation_probabilities.shape[1])])\n",
    "                                   for i in range(len(lr_validation_probabilities))])\n",
    "\n",
    "# Evaluate threshold on validation set\n",
    "adjusted_precision = precision_score(y_val, lr_validation_predictions, average='macro')\n",
    "adjusted_recall = recall_score(y_val, lr_validation_predictions, average='macro')\n",
    "adjusted_accuracy = accuracy_score(y_val, lr_validation_predictions)\n",
    "adjusted_f1 = f1_score(y_val, lr_validation_predictions, average='macro')\n",
    "adjusted_conf_matrix = confusion_matrix(y_val, lr_validation_predictions)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Validation Results\")\n",
    "print(f\"Precision: {adjusted_precision:.4f}\")\n",
    "print(f\"Recall: {adjusted_recall:.4f}\")\n",
    "print(f\"Accuracy: {adjusted_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {adjusted_f1:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(adjusted_conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "35d847f4-0bc4-4f4f-a1ff-22d5d990820f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T05:36:22.134912Z",
     "iopub.status.busy": "2024-09-25T05:36:22.134663Z",
     "iopub.status.idle": "2024-09-25T05:36:22.661941Z",
     "shell.execute_reply": "2024-09-25T05:36:22.660394Z",
     "shell.execute_reply.started": "2024-09-25T05:36:22.134905Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated cells count: 4\n"
     ]
    }
   ],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '3-2!F4:I4'  \n",
    "\n",
    "values = [[\n",
    "    f\"{adjusted_precision * 100:.2f}\",\n",
    "    f\"{adjusted_recall * 100:.2f}\",\n",
    "    f\"{adjusted_accuracy * 100:.2f}\",\n",
    "    f\"{adjusted_f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d20e88-5a01-4b56-ad36-37c984d10277",
   "metadata": {},
   "source": [
    "#### Save CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ca78187-3e76-4798-b348-64b200b29eb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T05:36:22.664157Z",
     "iopub.status.busy": "2024-09-25T05:36:22.663678Z",
     "iopub.status.idle": "2024-09-25T05:36:22.919987Z",
     "shell.execute_reply": "2024-09-25T05:36:22.919746Z",
     "shell.execute_reply.started": "2024-09-25T05:36:22.664127Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-ce6066f521214c478b232490add04926.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-ce6066f521214c478b232490add04926.vega-embed details,\n",
       "  #altair-viz-ce6066f521214c478b232490add04926.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-ce6066f521214c478b232490add04926\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-ce6066f521214c478b232490add04926\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-ce6066f521214c478b232490add04926\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"rect\"}, \"encoding\": {\"color\": {\"field\": \"Count\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"True\", \"type\": \"ordinal\"}, {\"field\": \"Predicted\", \"type\": \"ordinal\"}, {\"field\": \"Count\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Predicted\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}, \"y\": {\"field\": \"True\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}}, \"title\": \"OF_Using_FIRE 3STK-2 LR\"}, {\"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"middle\", \"fontSize\": 12}, \"encoding\": {\"color\": {\"condition\": {\"test\": \"(datum.Count > 148.0)\", \"value\": \"white\"}, \"value\": \"black\"}, \"text\": {\"field\": \"Count\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"True\", \"type\": \"ordinal\"}, {\"field\": \"Predicted\", \"type\": \"ordinal\"}, {\"field\": \"Count\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Predicted\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}, \"y\": {\"field\": \"True\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}}, \"title\": \"OF_Using_FIRE 3STK-2 LR\"}], \"data\": {\"name\": \"data-cfe6c728a20647e48abe439d2f507937\"}, \"height\": 300, \"width\": 400, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-cfe6c728a20647e48abe439d2f507937\": [{\"True\": \"Negative\", \"Predicted\": \"Negative\", \"Count\": 268}, {\"True\": \"Neutral\", \"Predicted\": \"Negative\", \"Count\": 52}, {\"True\": \"Positive\", \"Predicted\": \"Negative\", \"Count\": 3}, {\"True\": \"Negative\", \"Predicted\": \"Neutral\", \"Count\": 71}, {\"True\": \"Neutral\", \"Predicted\": \"Neutral\", \"Count\": 271}, {\"True\": \"Positive\", \"Predicted\": \"Neutral\", \"Count\": 45}, {\"True\": \"Negative\", \"Predicted\": \"Positive\", \"Count\": 2}, {\"True\": \"Neutral\", \"Predicted\": \"Positive\", \"Count\": 41}, {\"True\": \"Positive\", \"Predicted\": \"Positive\", \"Count\": 296}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import altair as alt\n",
    "import altair_saver\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_val, lr_validation_predictions)\n",
    "\n",
    "# Define class names\n",
    "class_names = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "# Convert confusion matrix to DataFrame\n",
    "cm_df = pd.DataFrame(cm, index=class_names, columns=class_names).reset_index().melt(id_vars='index')\n",
    "cm_df.columns = ['True', 'Predicted', 'Count']\n",
    "\n",
    "# Ensure the order of categories\n",
    "cm_df['True'] = pd.Categorical(cm_df['True'], categories=class_names, ordered=True)\n",
    "cm_df['Predicted'] = pd.Categorical(cm_df['Predicted'], categories=class_names, ordered=True)\n",
    "\n",
    "# Create the Altair plot\n",
    "heatmap = alt.Chart(cm_df).mark_rect().encode(\n",
    "    x=alt.X('Predicted:O', sort=class_names),\n",
    "    y=alt.Y('True:O', sort=class_names),\n",
    "    color='Count:Q',\n",
    "    tooltip=['True', 'Predicted', 'Count']\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=300,\n",
    "    title='OF_Using_FIRE 3STK-2 LR'\n",
    ")\n",
    "\n",
    "# Add text labels\n",
    "text = heatmap.mark_text(\n",
    "    align='center',\n",
    "    baseline='middle',\n",
    "    fontSize=12\n",
    ").encode(\n",
    "    text='Count:Q',\n",
    "    color=alt.condition(\n",
    "        alt.datum.Count > cm.max() / 2,\n",
    "        alt.value('white'),\n",
    "        alt.value('black')\n",
    "    )\n",
    ")\n",
    "\n",
    "# Combine heatmap and text\n",
    "final_chart = heatmap + text\n",
    "\n",
    "# Display the plot\n",
    "final_chart.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4018e7ba-2de6-44d9-9a6f-bf13ccb33108",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T05:36:22.920490Z",
     "iopub.status.busy": "2024-09-25T05:36:22.920422Z",
     "iopub.status.idle": "2024-09-25T05:36:23.360086Z",
     "shell.execute_reply": "2024-09-25T05:36:23.359756Z",
     "shell.execute_reply.started": "2024-09-25T05:36:22.920484Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to Results/Ensemble Model Results/On FireCS dataset/OF Using FIRE ENSEMBLE/Stacking/OF_Using_FIRE 3STK-2 LR.png\n"
     ]
    }
   ],
   "source": [
    "# Specify the folder path\n",
    "folder_path = os.path.expanduser('Results/Ensemble Model Results/On FireCS dataset/OF Using FIRE ENSEMBLE/Stacking/')\n",
    "\n",
    "# Save the plot using vl-convert\n",
    "file_path_png = os.path.join(folder_path, 'OF_Using_FIRE 3STK-2 LR.png')\n",
    "final_chart.save(file_path_png)\n",
    "\n",
    "print(f\"Plot saved to {file_path_png}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e3bc0f-597f-47e3-ba99-5d9cafd1aea3",
   "metadata": {},
   "source": [
    "### NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0af5051f-834f-4646-afef-37bfdfdc43d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T05:36:23.360707Z",
     "iopub.status.busy": "2024-09-25T05:36:23.360606Z",
     "iopub.status.idle": "2024-09-25T05:36:23.366176Z",
     "shell.execute_reply": "2024-09-25T05:36:23.365948Z",
     "shell.execute_reply.started": "2024-09-25T05:36:23.360700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on HS-Data C Dataset\n",
      "Precision: 0.7995943402487794\n",
      "Recall: 0.7950268036539604\n",
      "Accuracy: 0.7940896091515729\n",
      "F1 Score: 0.796817518536978\n",
      "Confusion Matrix:\n",
      "[[268  71   2]\n",
      " [ 52 271  41]\n",
      " [  3  47 294]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the predictions\n",
    "precision = precision_score(y_val, val_nb_predictions, average='macro')\n",
    "recall = recall_score(y_val, val_nb_predictions, average='macro')\n",
    "accuracy = accuracy_score(y_val, val_nb_predictions)\n",
    "f1 = f1_score(y_val, val_nb_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_val, val_nb_predictions)\n",
    "\n",
    "print(\"Evaluation on HS-Data C Dataset\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d1acd42b-ca2c-40be-b90e-e7fb7f6eeb2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T05:36:23.366642Z",
     "iopub.status.busy": "2024-09-25T05:36:23.366580Z",
     "iopub.status.idle": "2024-09-25T05:36:23.375674Z",
     "shell.execute_reply": "2024-09-25T05:36:23.375389Z",
     "shell.execute_reply.started": "2024-09-25T05:36:23.366636Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results\n",
      "Precision: 0.7996\n",
      "Recall: 0.7950\n",
      "Accuracy: 0.7941\n",
      "F1 Score: 0.7968\n",
      "Confusion Matrix:\n",
      "[[268  71   2]\n",
      " [ 52 271  41]\n",
      " [  3  47 294]]\n"
     ]
    }
   ],
   "source": [
    "nb_validation_probabilities = nb_meta_classifier.predict_proba(val_meta_features)\n",
    "\n",
    "# Apply thresholds to the validation set probabilities to make final predictions\n",
    "nb_validation_predictions = np.array([np.argmax([nb_validation_probabilities[i, j] if nb_validation_probabilities[i, j] >= nb_thresh[j] else 0\n",
    "                                              for j in range(nb_validation_probabilities.shape[1])])\n",
    "                                   for i in range(len(nb_validation_probabilities))])\n",
    "\n",
    "# Evaluate threshold on validation set\n",
    "adjusted_precision = precision_score(y_val, nb_validation_predictions, average='macro')\n",
    "adjusted_recall = recall_score(y_val, nb_validation_predictions, average='macro')\n",
    "adjusted_accuracy = accuracy_score(y_val, nb_validation_predictions)\n",
    "adjusted_f1 = f1_score(y_val, nb_validation_predictions, average='macro')\n",
    "adjusted_conf_matrix = confusion_matrix(y_val, nb_validation_predictions)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Validation Results\")\n",
    "print(f\"Precision: {adjusted_precision:.4f}\")\n",
    "print(f\"Recall: {adjusted_recall:.4f}\")\n",
    "print(f\"Accuracy: {adjusted_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {adjusted_f1:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(adjusted_conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fe5b7918-e4a2-4fd5-bfc3-74bb308a085b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T05:36:23.376551Z",
     "iopub.status.busy": "2024-09-25T05:36:23.376298Z",
     "iopub.status.idle": "2024-09-25T05:36:23.891281Z",
     "shell.execute_reply": "2024-09-25T05:36:23.890052Z",
     "shell.execute_reply.started": "2024-09-25T05:36:23.376536Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated cells count: 4\n"
     ]
    }
   ],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '3-2!F5:I5'  \n",
    "\n",
    "values = [[\n",
    "    f\"{adjusted_precision * 100:.2f}\",\n",
    "    f\"{adjusted_recall * 100:.2f}\",\n",
    "    f\"{adjusted_accuracy * 100:.2f}\",\n",
    "    f\"{adjusted_f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65529983-86a3-4c32-b155-c08fcdf20b31",
   "metadata": {},
   "source": [
    "#### Save CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea993771-7e1b-4a65-8e32-29912f2564d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T05:36:23.893420Z",
     "iopub.status.busy": "2024-09-25T05:36:23.893105Z",
     "iopub.status.idle": "2024-09-25T05:36:23.946255Z",
     "shell.execute_reply": "2024-09-25T05:36:23.945809Z",
     "shell.execute_reply.started": "2024-09-25T05:36:23.893392Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-96b46e51d19a40d4ab339c95da9743cc.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-96b46e51d19a40d4ab339c95da9743cc.vega-embed details,\n",
       "  #altair-viz-96b46e51d19a40d4ab339c95da9743cc.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-96b46e51d19a40d4ab339c95da9743cc\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-96b46e51d19a40d4ab339c95da9743cc\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-96b46e51d19a40d4ab339c95da9743cc\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"rect\"}, \"encoding\": {\"color\": {\"field\": \"Count\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"True\", \"type\": \"ordinal\"}, {\"field\": \"Predicted\", \"type\": \"ordinal\"}, {\"field\": \"Count\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Predicted\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}, \"y\": {\"field\": \"True\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}}, \"title\": \"OF_Using_FIRE 3STK-2 NB\"}, {\"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"middle\", \"fontSize\": 12}, \"encoding\": {\"color\": {\"condition\": {\"test\": \"(datum.Count > 147.0)\", \"value\": \"white\"}, \"value\": \"black\"}, \"text\": {\"field\": \"Count\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"True\", \"type\": \"ordinal\"}, {\"field\": \"Predicted\", \"type\": \"ordinal\"}, {\"field\": \"Count\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Predicted\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}, \"y\": {\"field\": \"True\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}}, \"title\": \"OF_Using_FIRE 3STK-2 NB\"}], \"data\": {\"name\": \"data-8c118a5445c19946fede7ab97b946eff\"}, \"height\": 300, \"width\": 400, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-8c118a5445c19946fede7ab97b946eff\": [{\"True\": \"Negative\", \"Predicted\": \"Negative\", \"Count\": 268}, {\"True\": \"Neutral\", \"Predicted\": \"Negative\", \"Count\": 52}, {\"True\": \"Positive\", \"Predicted\": \"Negative\", \"Count\": 3}, {\"True\": \"Negative\", \"Predicted\": \"Neutral\", \"Count\": 71}, {\"True\": \"Neutral\", \"Predicted\": \"Neutral\", \"Count\": 271}, {\"True\": \"Positive\", \"Predicted\": \"Neutral\", \"Count\": 47}, {\"True\": \"Negative\", \"Predicted\": \"Positive\", \"Count\": 2}, {\"True\": \"Neutral\", \"Predicted\": \"Positive\", \"Count\": 41}, {\"True\": \"Positive\", \"Predicted\": \"Positive\", \"Count\": 294}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import altair as alt\n",
    "import altair_saver\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_val, nb_validation_predictions)\n",
    "\n",
    "# Define class names\n",
    "class_names = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "# Convert confusion matrix to DataFrame\n",
    "cm_df = pd.DataFrame(cm, index=class_names, columns=class_names).reset_index().melt(id_vars='index')\n",
    "cm_df.columns = ['True', 'Predicted', 'Count']\n",
    "\n",
    "# Ensure the order of categories\n",
    "cm_df['True'] = pd.Categorical(cm_df['True'], categories=class_names, ordered=True)\n",
    "cm_df['Predicted'] = pd.Categorical(cm_df['Predicted'], categories=class_names, ordered=True)\n",
    "\n",
    "# Create the Altair plot\n",
    "heatmap = alt.Chart(cm_df).mark_rect().encode(\n",
    "    x=alt.X('Predicted:O', sort=class_names),\n",
    "    y=alt.Y('True:O', sort=class_names),\n",
    "    color='Count:Q',\n",
    "    tooltip=['True', 'Predicted', 'Count']\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=300,\n",
    "    title='OF_Using_FIRE 3STK-2 NB'\n",
    ")\n",
    "\n",
    "# Add text labels\n",
    "text = heatmap.mark_text(\n",
    "    align='center',\n",
    "    baseline='middle',\n",
    "    fontSize=12\n",
    ").encode(\n",
    "    text='Count:Q',\n",
    "    color=alt.condition(\n",
    "        alt.datum.Count > cm.max() / 2,\n",
    "        alt.value('white'),\n",
    "        alt.value('black')\n",
    "    )\n",
    ")\n",
    "\n",
    "# Combine heatmap and text\n",
    "final_chart = heatmap + text\n",
    "\n",
    "# Display the plot\n",
    "final_chart.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "031b9ce6-7d92-4735-a298-e8f7812ebae0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T05:36:23.947164Z",
     "iopub.status.busy": "2024-09-25T05:36:23.946991Z",
     "iopub.status.idle": "2024-09-25T05:36:23.998467Z",
     "shell.execute_reply": "2024-09-25T05:36:23.997926Z",
     "shell.execute_reply.started": "2024-09-25T05:36:23.947153Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to Results/Ensemble Model Results/On FireCS dataset/OF Using FIRE ENSEMBLE/Stacking/OF_Using_FIRE 3STK-2 NB.png\n"
     ]
    }
   ],
   "source": [
    "# Specify the folder path\n",
    "folder_path = os.path.expanduser('Results/Ensemble Model Results/On FireCS dataset/OF Using FIRE ENSEMBLE/Stacking/')\n",
    "\n",
    "# Save the plot using vl-convert\n",
    "file_path_png = os.path.join(folder_path, 'OF_Using_FIRE 3STK-2 NB.png')\n",
    "final_chart.save(file_path_png)\n",
    "\n",
    "print(f\"Plot saved to {file_path_png}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba2269b-62c4-43d2-8394-9aa3c1a27678",
   "metadata": {},
   "source": [
    "### DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0448f107-62d6-4f1a-8b04-4378b79f3d3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T05:36:23.999415Z",
     "iopub.status.busy": "2024-09-25T05:36:23.999224Z",
     "iopub.status.idle": "2024-09-25T05:36:24.005545Z",
     "shell.execute_reply": "2024-09-25T05:36:24.005169Z",
     "shell.execute_reply.started": "2024-09-25T05:36:23.999405Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on HS-Data C Dataset\n",
      "Precision: 0.8012940884186944\n",
      "Recall: 0.79904335474478\n",
      "Accuracy: 0.797902764537655\n",
      "F1 Score: 0.7999796531300278\n",
      "Confusion Matrix:\n",
      "[[272  65   4]\n",
      " [ 52 269  43]\n",
      " [  4  44 296]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the predictions\n",
    "precision = precision_score(y_val, val_dt_predictions, average='macro')\n",
    "recall = recall_score(y_val, val_dt_predictions, average='macro')\n",
    "accuracy = accuracy_score(y_val, val_dt_predictions)\n",
    "f1 = f1_score(y_val, val_dt_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_val, val_dt_predictions)\n",
    "\n",
    "print(\"Evaluation on HS-Data C Dataset\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9a0f105d-eb8f-4450-9d41-d90c97cf028c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T05:36:24.006224Z",
     "iopub.status.busy": "2024-09-25T05:36:24.006126Z",
     "iopub.status.idle": "2024-09-25T05:36:24.015793Z",
     "shell.execute_reply": "2024-09-25T05:36:24.015377Z",
     "shell.execute_reply.started": "2024-09-25T05:36:24.006212Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results\n",
      "Precision: 0.8013\n",
      "Recall: 0.7990\n",
      "Accuracy: 0.7979\n",
      "F1 Score: 0.8000\n",
      "Confusion Matrix:\n",
      "[[272  65   4]\n",
      " [ 52 269  43]\n",
      " [  4  44 296]]\n"
     ]
    }
   ],
   "source": [
    "dt_validation_probabilities = dt_meta_classifier.predict_proba(val_meta_features)\n",
    "\n",
    "# Apply thresholds to the validation set probabilities to make final predictions\n",
    "dt_validation_predictions = np.array([np.argmax([dt_validation_probabilities[i, j] if dt_validation_probabilities[i, j] >= dt_thresh[j] else 0\n",
    "                                              for j in range(dt_validation_probabilities.shape[1])])\n",
    "                                   for i in range(len(dt_validation_probabilities))])\n",
    "\n",
    "# Evaluate threshold on validation set\n",
    "adjusted_precision = precision_score(y_val, dt_validation_predictions, average='macro')\n",
    "adjusted_recall = recall_score(y_val, dt_validation_predictions, average='macro')\n",
    "adjusted_accuracy = accuracy_score(y_val, dt_validation_predictions)\n",
    "adjusted_f1 = f1_score(y_val, dt_validation_predictions, average='macro')\n",
    "adjusted_conf_matrix = confusion_matrix(y_val, dt_validation_predictions)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Validation Results\")\n",
    "print(f\"Precision: {adjusted_precision:.4f}\")\n",
    "print(f\"Recall: {adjusted_recall:.4f}\")\n",
    "print(f\"Accuracy: {adjusted_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {adjusted_f1:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(adjusted_conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dec85bf2-3044-4247-90ec-703089be962b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T05:36:24.016675Z",
     "iopub.status.busy": "2024-09-25T05:36:24.016434Z",
     "iopub.status.idle": "2024-09-25T05:36:24.414931Z",
     "shell.execute_reply": "2024-09-25T05:36:24.414021Z",
     "shell.execute_reply.started": "2024-09-25T05:36:24.016666Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated cells count: 4\n"
     ]
    }
   ],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '3-2!F6:I6'  \n",
    "\n",
    "values = [[\n",
    "    f\"{adjusted_precision * 100:.2f}\",\n",
    "    f\"{adjusted_recall * 100:.2f}\",\n",
    "    f\"{adjusted_accuracy * 100:.2f}\",\n",
    "    f\"{adjusted_f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8589d71-c489-4214-9c56-4a3a7ed69506",
   "metadata": {},
   "source": [
    "#### Save CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bb07bbd3-2021-4e16-8b59-3908f095b7cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T05:36:24.416720Z",
     "iopub.status.busy": "2024-09-25T05:36:24.416413Z",
     "iopub.status.idle": "2024-09-25T05:36:24.461941Z",
     "shell.execute_reply": "2024-09-25T05:36:24.461614Z",
     "shell.execute_reply.started": "2024-09-25T05:36:24.416696Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-615a67f19ba94ef5bae61725cff78c0d.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-615a67f19ba94ef5bae61725cff78c0d.vega-embed details,\n",
       "  #altair-viz-615a67f19ba94ef5bae61725cff78c0d.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-615a67f19ba94ef5bae61725cff78c0d\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-615a67f19ba94ef5bae61725cff78c0d\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-615a67f19ba94ef5bae61725cff78c0d\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"rect\"}, \"encoding\": {\"color\": {\"field\": \"Count\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"True\", \"type\": \"ordinal\"}, {\"field\": \"Predicted\", \"type\": \"ordinal\"}, {\"field\": \"Count\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Predicted\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}, \"y\": {\"field\": \"True\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}}, \"title\": \"OF_Using_FIRE 3STK-2 DT\"}, {\"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"middle\", \"fontSize\": 12}, \"encoding\": {\"color\": {\"condition\": {\"test\": \"(datum.Count > 148.0)\", \"value\": \"white\"}, \"value\": \"black\"}, \"text\": {\"field\": \"Count\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"True\", \"type\": \"ordinal\"}, {\"field\": \"Predicted\", \"type\": \"ordinal\"}, {\"field\": \"Count\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Predicted\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}, \"y\": {\"field\": \"True\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}}, \"title\": \"OF_Using_FIRE 3STK-2 DT\"}], \"data\": {\"name\": \"data-042d758cfea69071a645439c12dce590\"}, \"height\": 300, \"width\": 400, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-042d758cfea69071a645439c12dce590\": [{\"True\": \"Negative\", \"Predicted\": \"Negative\", \"Count\": 272}, {\"True\": \"Neutral\", \"Predicted\": \"Negative\", \"Count\": 52}, {\"True\": \"Positive\", \"Predicted\": \"Negative\", \"Count\": 4}, {\"True\": \"Negative\", \"Predicted\": \"Neutral\", \"Count\": 65}, {\"True\": \"Neutral\", \"Predicted\": \"Neutral\", \"Count\": 269}, {\"True\": \"Positive\", \"Predicted\": \"Neutral\", \"Count\": 44}, {\"True\": \"Negative\", \"Predicted\": \"Positive\", \"Count\": 4}, {\"True\": \"Neutral\", \"Predicted\": \"Positive\", \"Count\": 43}, {\"True\": \"Positive\", \"Predicted\": \"Positive\", \"Count\": 296}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import altair as alt\n",
    "import altair_saver\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_val, dt_validation_predictions)\n",
    "\n",
    "# Define class names\n",
    "class_names = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "# Convert confusion matrix to DataFrame\n",
    "cm_df = pd.DataFrame(cm, index=class_names, columns=class_names).reset_index().melt(id_vars='index')\n",
    "cm_df.columns = ['True', 'Predicted', 'Count']\n",
    "\n",
    "# Ensure the order of categories\n",
    "cm_df['True'] = pd.Categorical(cm_df['True'], categories=class_names, ordered=True)\n",
    "cm_df['Predicted'] = pd.Categorical(cm_df['Predicted'], categories=class_names, ordered=True)\n",
    "\n",
    "# Create the Altair plot\n",
    "heatmap = alt.Chart(cm_df).mark_rect().encode(\n",
    "    x=alt.X('Predicted:O', sort=class_names),\n",
    "    y=alt.Y('True:O', sort=class_names),\n",
    "    color='Count:Q',\n",
    "    tooltip=['True', 'Predicted', 'Count']\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=300,\n",
    "    title='OF_Using_FIRE 3STK-2 DT'\n",
    ")\n",
    "\n",
    "# Add text labels\n",
    "text = heatmap.mark_text(\n",
    "    align='center',\n",
    "    baseline='middle',\n",
    "    fontSize=12\n",
    ").encode(\n",
    "    text='Count:Q',\n",
    "    color=alt.condition(\n",
    "        alt.datum.Count > cm.max() / 2,\n",
    "        alt.value('white'),\n",
    "        alt.value('black')\n",
    "    )\n",
    ")\n",
    "\n",
    "# Combine heatmap and text\n",
    "final_chart = heatmap + text\n",
    "\n",
    "# Display the plot\n",
    "final_chart.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5445e621-6288-4a87-9e75-bf4511b2d9a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T05:36:24.462610Z",
     "iopub.status.busy": "2024-09-25T05:36:24.462506Z",
     "iopub.status.idle": "2024-09-25T05:36:24.505948Z",
     "shell.execute_reply": "2024-09-25T05:36:24.505607Z",
     "shell.execute_reply.started": "2024-09-25T05:36:24.462599Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to Results/Ensemble Model Results/On FireCS dataset/OF Using FIRE ENSEMBLE/Stacking/OF_Using_FIRE 3STK-2 DT.png\n"
     ]
    }
   ],
   "source": [
    "# Specify the folder path\n",
    "folder_path = os.path.expanduser('Results/Ensemble Model Results/On FireCS dataset/OF Using FIRE ENSEMBLE/Stacking/')\n",
    "\n",
    "# Save the plot using vl-convert\n",
    "file_path_png = os.path.join(folder_path, 'OF_Using_FIRE 3STK-2 DT.png')\n",
    "final_chart.save(file_path_png)\n",
    "\n",
    "print(f\"Plot saved to {file_path_png}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6165ef-d0ff-4230-9fdb-3c6a774d728f",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "660f90df-3de4-41b1-9fc6-4285133ec0a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T05:36:24.506556Z",
     "iopub.status.busy": "2024-09-25T05:36:24.506451Z",
     "iopub.status.idle": "2024-09-25T05:36:24.512420Z",
     "shell.execute_reply": "2024-09-25T05:36:24.512117Z",
     "shell.execute_reply.started": "2024-09-25T05:36:24.506547Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on HS-Data C Dataset\n",
      "Precision: 0.7890957957880627\n",
      "Recall: 0.789095719234504\n",
      "Accuracy: 0.7874165872259294\n",
      "F1 Score: 0.7887117689073387\n",
      "Confusion Matrix:\n",
      "[[268  71   2]\n",
      " [ 52 255  57]\n",
      " [  3  38 303]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the predictions\n",
    "precision = precision_score(y_val, val_svm_predictions, average='macro')\n",
    "recall = recall_score(y_val, val_svm_predictions, average='macro')\n",
    "accuracy = accuracy_score(y_val, val_svm_predictions)\n",
    "f1 = f1_score(y_val, val_svm_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_val, val_svm_predictions)\n",
    "\n",
    "print(\"Evaluation on HS-Data C Dataset\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ad2fba87-04de-46b7-bc1d-1fbf7d1bb263",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T05:36:24.513053Z",
     "iopub.status.busy": "2024-09-25T05:36:24.512975Z",
     "iopub.status.idle": "2024-09-25T05:36:24.531949Z",
     "shell.execute_reply": "2024-09-25T05:36:24.531595Z",
     "shell.execute_reply.started": "2024-09-25T05:36:24.513045Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results\n",
      "Precision: 0.7740\n",
      "Recall: 0.7718\n",
      "Accuracy: 0.7703\n",
      "F1 Score: 0.7726\n",
      "Confusion Matrix:\n",
      "[[264  76   1]\n",
      " [ 77 252  35]\n",
      " [ 16  36 292]]\n"
     ]
    }
   ],
   "source": [
    "svm_validation_probabilities = svm_meta_classifier.predict_proba(val_meta_features)\n",
    "\n",
    "# Apply thresholds to the validation set probabilities to make final predictions\n",
    "svm_validation_predictions = np.array([np.argmax([svm_validation_probabilities[i, j] if svm_validation_probabilities[i, j] >= svm_thresh[j] else 0\n",
    "                                              for j in range(svm_validation_probabilities.shape[1])])\n",
    "                                   for i in range(len(svm_validation_probabilities))])\n",
    "\n",
    "# Evaluate threshold on validation set\n",
    "adjusted_precision = precision_score(y_val, svm_validation_predictions, average='macro')\n",
    "adjusted_recall = recall_score(y_val, svm_validation_predictions, average='macro')\n",
    "adjusted_accuracy = accuracy_score(y_val, svm_validation_predictions)\n",
    "adjusted_f1 = f1_score(y_val, svm_validation_predictions, average='macro')\n",
    "adjusted_conf_matrix = confusion_matrix(y_val, svm_validation_predictions)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Validation Results\")\n",
    "print(f\"Precision: {adjusted_precision:.4f}\")\n",
    "print(f\"Recall: {adjusted_recall:.4f}\")\n",
    "print(f\"Accuracy: {adjusted_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {adjusted_f1:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(adjusted_conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7644868d-4140-415e-be20-4db4bfbf21b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T05:36:24.532462Z",
     "iopub.status.busy": "2024-09-25T05:36:24.532386Z",
     "iopub.status.idle": "2024-09-25T05:36:24.915469Z",
     "shell.execute_reply": "2024-09-25T05:36:24.914236Z",
     "shell.execute_reply.started": "2024-09-25T05:36:24.532452Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated cells count: 4\n"
     ]
    }
   ],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '3-2!F7:I7'  \n",
    "\n",
    "values = [[\n",
    "    f\"{adjusted_precision * 100:.2f}\",\n",
    "    f\"{adjusted_recall * 100:.2f}\",\n",
    "    f\"{adjusted_accuracy * 100:.2f}\",\n",
    "    f\"{adjusted_f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682be1a4-7bf8-4e44-9da2-2b7f48eac91c",
   "metadata": {},
   "source": [
    "#### Save CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "939272d5-856b-49da-99a2-4a25d818d2ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T05:36:24.919810Z",
     "iopub.status.busy": "2024-09-25T05:36:24.918504Z",
     "iopub.status.idle": "2024-09-25T05:36:24.975920Z",
     "shell.execute_reply": "2024-09-25T05:36:24.975558Z",
     "shell.execute_reply.started": "2024-09-25T05:36:24.919767Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-4917c3cfb35c4a97a162e12d3d3312df.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-4917c3cfb35c4a97a162e12d3d3312df.vega-embed details,\n",
       "  #altair-viz-4917c3cfb35c4a97a162e12d3d3312df.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-4917c3cfb35c4a97a162e12d3d3312df\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-4917c3cfb35c4a97a162e12d3d3312df\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-4917c3cfb35c4a97a162e12d3d3312df\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"rect\"}, \"encoding\": {\"color\": {\"field\": \"Count\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"True\", \"type\": \"ordinal\"}, {\"field\": \"Predicted\", \"type\": \"ordinal\"}, {\"field\": \"Count\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Predicted\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}, \"y\": {\"field\": \"True\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}}, \"title\": \"OF_Using_FIRE 3STK-2 SVM\"}, {\"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"middle\", \"fontSize\": 12}, \"encoding\": {\"color\": {\"condition\": {\"test\": \"(datum.Count > 146.0)\", \"value\": \"white\"}, \"value\": \"black\"}, \"text\": {\"field\": \"Count\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"True\", \"type\": \"ordinal\"}, {\"field\": \"Predicted\", \"type\": \"ordinal\"}, {\"field\": \"Count\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Predicted\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}, \"y\": {\"field\": \"True\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}}, \"title\": \"OF_Using_FIRE 3STK-2 SVM\"}], \"data\": {\"name\": \"data-66e2b4fd974070bffcb3cbad2b506c7f\"}, \"height\": 300, \"width\": 400, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-66e2b4fd974070bffcb3cbad2b506c7f\": [{\"True\": \"Negative\", \"Predicted\": \"Negative\", \"Count\": 264}, {\"True\": \"Neutral\", \"Predicted\": \"Negative\", \"Count\": 77}, {\"True\": \"Positive\", \"Predicted\": \"Negative\", \"Count\": 16}, {\"True\": \"Negative\", \"Predicted\": \"Neutral\", \"Count\": 76}, {\"True\": \"Neutral\", \"Predicted\": \"Neutral\", \"Count\": 252}, {\"True\": \"Positive\", \"Predicted\": \"Neutral\", \"Count\": 36}, {\"True\": \"Negative\", \"Predicted\": \"Positive\", \"Count\": 1}, {\"True\": \"Neutral\", \"Predicted\": \"Positive\", \"Count\": 35}, {\"True\": \"Positive\", \"Predicted\": \"Positive\", \"Count\": 292}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import altair as alt\n",
    "import altair_saver\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_val, svm_validation_predictions)\n",
    "\n",
    "# Define class names\n",
    "class_names = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "# Convert confusion matrix to DataFrame\n",
    "cm_df = pd.DataFrame(cm, index=class_names, columns=class_names).reset_index().melt(id_vars='index')\n",
    "cm_df.columns = ['True', 'Predicted', 'Count']\n",
    "\n",
    "# Ensure the order of categories\n",
    "cm_df['True'] = pd.Categorical(cm_df['True'], categories=class_names, ordered=True)\n",
    "cm_df['Predicted'] = pd.Categorical(cm_df['Predicted'], categories=class_names, ordered=True)\n",
    "\n",
    "# Create the Altair plot\n",
    "heatmap = alt.Chart(cm_df).mark_rect().encode(\n",
    "    x=alt.X('Predicted:O', sort=class_names),\n",
    "    y=alt.Y('True:O', sort=class_names),\n",
    "    color='Count:Q',\n",
    "    tooltip=['True', 'Predicted', 'Count']\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=300,\n",
    "    title='OF_Using_FIRE 3STK-2 SVM'\n",
    ")\n",
    "\n",
    "# Add text labels\n",
    "text = heatmap.mark_text(\n",
    "    align='center',\n",
    "    baseline='middle',\n",
    "    fontSize=12\n",
    ").encode(\n",
    "    text='Count:Q',\n",
    "    color=alt.condition(\n",
    "        alt.datum.Count > cm.max() / 2,\n",
    "        alt.value('white'),\n",
    "        alt.value('black')\n",
    "    )\n",
    ")\n",
    "\n",
    "# Combine heatmap and text\n",
    "final_chart = heatmap + text\n",
    "\n",
    "# Display the plot\n",
    "final_chart.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4ab1dbec-94d8-4f9c-b5e8-843b853a71cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T05:36:24.976689Z",
     "iopub.status.busy": "2024-09-25T05:36:24.976544Z",
     "iopub.status.idle": "2024-09-25T05:36:25.020965Z",
     "shell.execute_reply": "2024-09-25T05:36:25.020579Z",
     "shell.execute_reply.started": "2024-09-25T05:36:24.976677Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to Results/Ensemble Model Results/On FireCS dataset/OF Using FIRE ENSEMBLE/Stacking/OF_Using_FIRE 3STK-2 SVM.png\n"
     ]
    }
   ],
   "source": [
    "# Specify the folder path\n",
    "folder_path = os.path.expanduser('Results/Ensemble Model Results/On FireCS dataset/OF Using FIRE ENSEMBLE/Stacking/')\n",
    "\n",
    "# Save the plot using vl-convert\n",
    "file_path_png = os.path.join(folder_path, 'OF_Using_FIRE 3STK-2 SVM.png')\n",
    "final_chart.save(file_path_png)\n",
    "\n",
    "print(f\"Plot saved to {file_path_png}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a298f212-36ec-4e75-ad74-d7b272d094a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80391c9f-64d7-4e98-b9f0-6ee41cb035f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
