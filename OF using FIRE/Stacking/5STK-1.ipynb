{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dc06b17-fcee-4505-bd74-d98376ce3ed9",
   "metadata": {},
   "source": [
    "# Train Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "437dabfe-d445-404d-bcff-a7c9c6928f9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:52:59.417446Z",
     "iopub.status.busy": "2024-09-25T07:52:59.417372Z",
     "iopub.status.idle": "2024-09-25T07:52:59.969538Z",
     "shell.execute_reply": "2024-09-25T07:52:59.969237Z",
     "shell.execute_reply.started": "2024-09-25T07:52:59.417439Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.backends.mps.is_available():\n",
    "        # Currently, there's no separate manual seed function for MPS like torch.cuda.manual_seed_all()\n",
    "        pass \n",
    "    else:\n",
    "        print(\"MPS device not available. Using CPU.\")\n",
    "        \n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c6a724-b17e-46f6-aee6-90ef2f7877a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T15:08:53.465538Z",
     "iopub.status.busy": "2024-08-13T15:08:53.465321Z",
     "iopub.status.idle": "2024-08-13T15:08:53.469076Z",
     "shell.execute_reply": "2024-08-13T15:08:53.468592Z",
     "shell.execute_reply.started": "2024-08-13T15:08:53.465526Z"
    }
   },
   "source": [
    "Best F1 score BERT model on HS_C dataset are used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3823c3e6-976a-4eb9-a651-2cfeaa1a3cc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:52:59.970031Z",
     "iopub.status.busy": "2024-09-25T07:52:59.969919Z",
     "iopub.status.idle": "2024-09-25T07:53:00.090855Z",
     "shell.execute_reply": "2024-09-25T07:53:00.090459Z",
     "shell.execute_reply.started": "2024-09-25T07:52:59.970024Z"
    }
   },
   "outputs": [],
   "source": [
    "# This automates data tabulation onto google sheets \n",
    "\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "import os\n",
    "\n",
    "# new directory path\n",
    "new_directory = '/Users/levan/ATENEO MASTERAL/Thesis'\n",
    "\n",
    "# Change the current working directory\n",
    "os.chdir(new_directory)\n",
    "\n",
    "# Use creds to create a client to interact with the Google Drive API\n",
    "scope = ['https://spreadsheets.google.com/feeds','https://www.googleapis.com/auth/drive']\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_name('thesis-432315-12daec8d1ff6.json', scope)\n",
    "\n",
    "service = build('sheets', 'v4', credentials=creds)\n",
    "\n",
    "client = gspread.authorize(creds)\n",
    "\n",
    "spreadsheet_id = '13Fk5oXX9B_mdHmNpMKQMy29y9iiHWrgQCa4hUTiQKD0' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d70bdb-0504-41ef-913d-e4b7f778f561",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7b193db-3f30-4e5f-a38b-c254bf1e1976",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:53:00.091374Z",
     "iopub.status.busy": "2024-09-25T07:53:00.091290Z",
     "iopub.status.idle": "2024-09-25T07:53:01.254076Z",
     "shell.execute_reply": "2024-09-25T07:53:01.253800Z",
     "shell.execute_reply.started": "2024-09-25T07:53:00.091367Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AutoConfig\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_recall_curve, f1_score, confusion_matrix, precision_score, recall_score, accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "# new directory path\n",
    "new_directory = '/Users/levan/ATENEO MASTERAL/Thesis/Development'\n",
    "\n",
    "# Change the current working directory\n",
    "os.chdir(new_directory)\n",
    "\n",
    "#Load Data\n",
    "df = pd.read_csv('Corpus/FiReCS/FiReCS_data_b.csv')\n",
    "X = df['review'].values\n",
    "y = df['label'].values\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a307e67b-00c3-47aa-8f83-34bc62c93f83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-11T10:08:58.783500Z",
     "iopub.status.busy": "2024-04-11T10:08:58.782872Z",
     "iopub.status.idle": "2024-04-11T10:08:58.788089Z",
     "shell.execute_reply": "2024-04-11T10:08:58.787147Z",
     "shell.execute_reply.started": "2024-04-11T10:08:58.783465Z"
    }
   },
   "source": [
    "## Load Models and Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e666f7e-9db0-4666-a112-2af127307162",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:53:01.254655Z",
     "iopub.status.busy": "2024-09-25T07:53:01.254576Z",
     "iopub.status.idle": "2024-09-25T07:53:05.535423Z",
     "shell.execute_reply": "2024-09-25T07:53:05.535083Z",
     "shell.execute_reply.started": "2024-09-25T07:53:01.254648Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_model_and_tokenizer(model_path, tokenizer_path, base_model):\n",
    "    # Load the tokenizer from the local directory\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "    \n",
    "    # Load the configuration from the base model, then update configuration if needed\n",
    "    config = AutoConfig.from_pretrained(base_model, num_labels=3)\n",
    "\n",
    "    # Initialize the model with the configuration\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_path, config=config)\n",
    "\n",
    "    # Ensure the model is in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    return model, tokenizer\n",
    "\n",
    "model_info = {\n",
    "    \n",
    "    'BERT cased': {\n",
    "        'model_path': 'BERT models/1 FiReCS/fire_bert-base-cased-finetuned',\n",
    "        'tokenizer_path': 'BERT models/1 FiReCS/fire_bert-base-cased-finetuned',\n",
    "        'base_model': 'google-bert/bert-base-cased'\n",
    "    },\n",
    "\n",
    "    'DistilBERT uncased': {\n",
    "        'model_path': 'BERT models/1 FiReCS/fire_distilbert-base-uncased-finetuned',\n",
    "        'tokenizer_path': 'BERT models/1 FiReCS/fire_distilbert-base-uncased-finetuned',\n",
    "        'base_model': 'distilbert/distilbert-base-uncased'\n",
    "    },\n",
    "\n",
    "    'DeBERTa': {\n",
    "        'model_path': 'BERT models/1 FiReCS/fire_DeBERTa-finetuned',\n",
    "        'tokenizer_path': 'BERT models/1 FiReCS/fire_DeBERTa-finetuned',\n",
    "        'base_model': 'microsoft/deberta-v3-base'\n",
    "    },\n",
    "    \n",
    "    'BERT uncased': {\n",
    "        'model_path': 'BERT models/1 FiReCS/fire_bert-base-uncased-finetuned',\n",
    "        'tokenizer_path': 'BERT models/1 FiReCS/fire_bert-base-uncased-finetuned',\n",
    "        'base_model': 'google-bert/bert-base-uncased'\n",
    "    },\n",
    "\n",
    "    'HateBERT': {\n",
    "        'model_path': 'BERT models/1 FiReCS/fire_HateBERT-finetuned',\n",
    "        'tokenizer_path': 'BERT models/1 FiReCS/fire_HateBERT-finetuned',\n",
    "        'base_model': 'GroNLP/hateBERT'\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "models_and_tokenizers = {name: load_model_and_tokenizer(info['model_path'], \n",
    "                                                        info['tokenizer_path'], \n",
    "                                                        info['base_model']) \n",
    "                         for name, info in model_info.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a9b906-a837-4de8-b8a2-05aa44074c5c",
   "metadata": {},
   "source": [
    "## Apply Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05f7b2f9-3bc4-4d6d-8595-8971899238c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:53:05.535895Z",
     "iopub.status.busy": "2024-09-25T07:53:05.535823Z",
     "iopub.status.idle": "2024-09-25T07:53:05.538735Z",
     "shell.execute_reply": "2024-09-25T07:53:05.538529Z",
     "shell.execute_reply.started": "2024-09-25T07:53:05.535888Z"
    }
   },
   "outputs": [],
   "source": [
    "class MultiModelTextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, labels, models_and_tokenizers, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.models_and_tokenizers = models_and_tokenizers\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.texts[index])\n",
    "        label = self.labels[index]\n",
    "\n",
    "        model_inputs = {}\n",
    "        for name, (model, tokenizer) in self.models_and_tokenizers.items():\n",
    "            encoding = tokenizer.encode_plus(\n",
    "                text,\n",
    "                add_special_tokens=True,\n",
    "                max_length=self.max_len,\n",
    "                return_token_type_ids=False,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                return_attention_mask=True,\n",
    "                return_tensors='pt',\n",
    "            )\n",
    "            model_inputs[name] = {\n",
    "                'input_ids': encoding['input_ids'].squeeze(0),  # Remove batch dimension\n",
    "                'attention_mask': encoding['attention_mask'].squeeze(0)  # Remove batch dimension\n",
    "            }\n",
    "        return {'model_inputs': model_inputs, 'label': torch.tensor(label, dtype=torch.long)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d574483-f790-48ba-a7d0-07cc8f2973d4",
   "metadata": {},
   "source": [
    "## BERT Training for Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e6167c5-79fd-4536-815c-237ec599453a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:53:05.540174Z",
     "iopub.status.busy": "2024-09-25T07:53:05.540090Z",
     "iopub.status.idle": "2024-09-25T07:53:05.543347Z",
     "shell.execute_reply": "2024-09-25T07:53:05.543123Z",
     "shell.execute_reply.started": "2024-09-25T07:53:05.540168Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_base_learner(model, data_loader, optimizer, device):\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    correct_predictions = 0\n",
    "    losses = []\n",
    "\n",
    "    for batch in data_loader:\n",
    "        # Accessing inputs for the current model\n",
    "        inputs = batch['model_inputs']\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        for model_name, model_inputs in inputs.items():\n",
    "            # Forward pass\n",
    "            outputs = model(input_ids=model_inputs['input_ids'].squeeze(1).to(device),\n",
    "                attention_mask=model_inputs['attention_mask'].squeeze(1).to(device),\n",
    "                labels=labels)\n",
    "\n",
    "            loss = outputs.loss\n",
    "            preds = outputs.logits.argmax(dim=1)\n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    return correct_predictions.float() / len(data_loader.dataset), np.mean(losses).astype(np.float32)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def eval_model(model, data_loader, device):\n",
    "    model = model.eval()\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for d in data_loader:\n",
    "            input_ids = d[\"input_ids\"].to(device)\n",
    "            attention_mask = d[\"attention_mask\"].to(device)\n",
    "            labels = d[\"label\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            preds = outputs.logits.argmax(dim=1)\n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "\n",
    "    return correct_predictions.double() / len(data_loader.dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b36fee-48a1-4eda-bf0b-c59982cbba14",
   "metadata": {},
   "source": [
    "## Train Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99eb6be0-fb6e-441b-bfaa-853e75a01983",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:53:05.544466Z",
     "iopub.status.busy": "2024-09-25T07:53:05.544410Z",
     "iopub.status.idle": "2024-09-25T07:53:05.552342Z",
     "shell.execute_reply": "2024-09-25T07:53:05.552069Z",
     "shell.execute_reply.started": "2024-09-25T07:53:05.544461Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, confusion_matrix\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "\n",
    "def train_stacking_classifier(models_and_tokenizers, X_train, y_train, device, max_len=128):\n",
    "    n_splits = 4\n",
    "    skf = StratifiedKFold(n_splits=n_splits)\n",
    "    base_learners_predictions_train = np.zeros((len(X_train), len(models_and_tokenizers)))\n",
    "    fold_idx = 0\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_train, y_train):\n",
    "        fold_idx += 1\n",
    "        print(f\"Training fold {fold_idx}/{n_splits}...\")\n",
    "        train_texts, val_texts = X_train[train_idx], X_train[val_idx]\n",
    "        train_labels, val_labels = y_train[train_idx], y_train[val_idx]\n",
    "        \n",
    "        model_idx = 0\n",
    "        for name, info in model_info.items():\n",
    "            # Reload the model and tokenizer to reset weights\n",
    "            model, tokenizer = load_model_and_tokenizer(info['model_path'], info['tokenizer_path'], info['base_model'])\n",
    "            model.to(device)\n",
    "            \n",
    "            train_dataset = MultiModelTextDataset(train_texts, train_labels, {name: (model, tokenizer)}, max_len)\n",
    "            val_dataset = MultiModelTextDataset(val_texts, val_labels, {name: (model, tokenizer)}, max_len)\n",
    "            train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "            \n",
    "            optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "            train_base_learner(model, train_loader, optimizer, device)\n",
    "            \n",
    "            val_preds = []\n",
    "            model.eval()\n",
    "            for batch in val_loader:\n",
    "                inputs = batch['model_inputs'][name]\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(input_ids=inputs['input_ids'].to(device), attention_mask=inputs['attention_mask'].to(device))\n",
    "                val_preds.extend(outputs.logits.argmax(dim=1).cpu().numpy())\n",
    "            \n",
    "            base_learners_predictions_train[val_idx, model_idx] = np.array(val_preds)\n",
    "            model_idx += 1\n",
    "\n",
    "    return base_learners_predictions_train, y_train\n",
    "    \n",
    "\n",
    "def get_predictions(model_info, X, y, device, max_len=128):\n",
    "    predictions = np.zeros((len(X), len(model_info)))\n",
    "    model_idx = 0\n",
    "    for name, info in model_info.items():\n",
    "        # Reload the model and tokenizer\n",
    "        model, tokenizer = load_model_and_tokenizer(info['model_path'], info['tokenizer_path'], info['base_model'])\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        \n",
    "        dataset = MultiModelTextDataset(X, y, {name: (model, tokenizer)}, max_len)\n",
    "        loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
    "        \n",
    "        preds = []\n",
    "        for batch in loader:\n",
    "            inputs = batch['model_inputs'][name]\n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_ids=inputs['input_ids'].to(device), attention_mask=inputs['attention_mask'].to(device))\n",
    "            preds.extend(outputs.logits.argmax(dim=1).cpu().numpy())\n",
    "        \n",
    "        predictions[:, model_idx] = np.array(preds)\n",
    "        model_idx += 1\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58472c03-8cb9-4a28-b8f3-fd5227c0e620",
   "metadata": {},
   "source": [
    "## Perform Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da0e67bd-3f57-4bf1-aa4e-1537a9132002",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:53:05.552955Z",
     "iopub.status.busy": "2024-09-25T07:53:05.552798Z",
     "iopub.status.idle": "2024-09-25T07:53:05.556938Z",
     "shell.execute_reply": "2024-09-25T07:53:05.556569Z",
     "shell.execute_reply.started": "2024-09-25T07:53:05.552946Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36436c2d-846d-46ab-ae3c-b36c5bdda6a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:53:05.557589Z",
     "iopub.status.busy": "2024-09-25T07:53:05.557498Z",
     "iopub.status.idle": "2024-09-25T08:07:50.568724Z",
     "shell.execute_reply": "2024-09-25T08:07:50.568387Z",
     "shell.execute_reply.started": "2024-09-25T07:53:05.557583Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/transformers/optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 2/4...\n",
      "Training fold 3/4...\n",
      "Training fold 4/4...\n",
      "peak memory: 3615.78 MiB, increment: 870.11 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# Train stacking classifier (using 4-fold cross validation for each BERT model) on Train Set and retrieve training meta-features\n",
    "train_meta_features, _ = train_stacking_classifier(model_info, X_train, y_train, device)\n",
    "\n",
    "# Generate predictions for the test set to be used as test meta-features\n",
    "test_meta_features = get_predictions(model_info, X_test, y_test, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d42e0b-1855-4774-8f83-599a6158e526",
   "metadata": {},
   "source": [
    "### Train LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "265a5311-c2a4-48a0-9f21-d803350fb89f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:07:50.569300Z",
     "iopub.status.busy": "2024-09-25T08:07:50.569215Z",
     "iopub.status.idle": "2024-09-25T08:07:51.441039Z",
     "shell.execute_reply": "2024-09-25T08:07:51.440696Z",
     "shell.execute_reply.started": "2024-09-25T08:07:50.569293Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 2275.27 MiB, increment: 1.48 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "\n",
    "lr_meta_classifier = LogisticRegression()\n",
    "lr_meta_classifier.fit(train_meta_features, y_train)\n",
    "\n",
    "lr_final_predictions = lr_meta_classifier.predict(test_meta_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ea06bb-fab4-4f49-99e4-19680ec1b870",
   "metadata": {},
   "source": [
    "### Train NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "244b0f68-e401-4d18-913f-a3a153dd8104",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:07:51.441692Z",
     "iopub.status.busy": "2024-09-25T08:07:51.441605Z",
     "iopub.status.idle": "2024-09-25T08:07:52.870611Z",
     "shell.execute_reply": "2024-09-25T08:07:52.870266Z",
     "shell.execute_reply.started": "2024-09-25T08:07:51.441683Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 2272.72 MiB, increment: -2.56 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "\n",
    "nb_meta_classifier = GaussianNB()\n",
    "nb_meta_classifier.fit(train_meta_features, y_train)\n",
    "\n",
    "nb_final_predictions = nb_meta_classifier.predict(test_meta_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e50604f-9bef-4db4-bf92-89f9d2874e89",
   "metadata": {},
   "source": [
    "### Train DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3990ca03-b860-4b65-97e7-47f551754ab7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:07:52.871448Z",
     "iopub.status.busy": "2024-09-25T08:07:52.871243Z",
     "iopub.status.idle": "2024-09-25T08:07:54.261404Z",
     "shell.execute_reply": "2024-09-25T08:07:54.261058Z",
     "shell.execute_reply.started": "2024-09-25T08:07:52.871434Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 2273.20 MiB, increment: 0.48 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "\n",
    "dt_meta_classifier = DecisionTreeClassifier(max_depth=None)\n",
    "dt_meta_classifier.fit(train_meta_features, y_train)\n",
    "\n",
    "dt_final_predictions = dt_meta_classifier.predict(test_meta_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986bd8f0-b569-4eaf-8e13-a51529e871e6",
   "metadata": {},
   "source": [
    "### Train SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "460a4087-b343-4249-b794-db90baabf11c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:07:54.262167Z",
     "iopub.status.busy": "2024-09-25T08:07:54.262076Z",
     "iopub.status.idle": "2024-09-25T08:07:55.176202Z",
     "shell.execute_reply": "2024-09-25T08:07:55.175883Z",
     "shell.execute_reply.started": "2024-09-25T08:07:54.262158Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 2285.27 MiB, increment: 12.05 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "\n",
    "svm_meta_classifier = SVC(kernel='linear', probability=True)\n",
    "svm_meta_classifier.fit(train_meta_features, y_train)\n",
    "\n",
    "svm_final_predictions = svm_meta_classifier.predict(test_meta_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad340b68-d07e-473a-bbc4-138ef8e0271a",
   "metadata": {},
   "source": [
    "## EVALUATE MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93ba0c5-a053-45fb-8e97-b09c67959bc8",
   "metadata": {},
   "source": [
    "### LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d015915-5eb9-4a73-9ef6-5fc1bd4d0e8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:07:55.176889Z",
     "iopub.status.busy": "2024-09-25T08:07:55.176800Z",
     "iopub.status.idle": "2024-09-25T08:07:55.182368Z",
     "shell.execute_reply": "2024-09-25T08:07:55.182157Z",
     "shell.execute_reply.started": "2024-09-25T08:07:55.176882Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Precision: 0.8258353687117865\n",
      "Recall: 0.8164927713967512\n",
      "Ensemble accuracy: 0.8163841807909604\n",
      "F1 Score: 0.8194753569361172\n",
      "Confusion Matrix:\n",
      "[[361  98   1]\n",
      " [ 54 395  42]\n",
      " [  4  61 400]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "precision = precision_score(y_test, lr_final_predictions, average='macro')\n",
    "recall = recall_score(y_test, lr_final_predictions, average='macro')\n",
    "accuracy = accuracy_score(y_test, lr_final_predictions)\n",
    "f1 = f1_score(y_test, lr_final_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_test, lr_final_predictions)\n",
    "\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Ensemble accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8c650bc-c7b7-4f3d-b8c7-c415ed29f2f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:07:55.182859Z",
     "iopub.status.busy": "2024-09-25T08:07:55.182780Z",
     "iopub.status.idle": "2024-09-25T08:07:55.192019Z",
     "shell.execute_reply": "2024-09-25T08:07:55.191771Z",
     "shell.execute_reply.started": "2024-09-25T08:07:55.182853Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized thresholds for each class: [0.2481917654786743, 0.5657888727783995, 0.44509210224323986]\n",
      "Logistic Regression\n",
      "Precision: 0.8320\n",
      "Recall: 0.8310\n",
      "Ensemble accuracy: 0.8298\n",
      "F1 Score: 0.8314325021317727\n",
      "Confusion Matrix:\n",
      "[[388  70   2]\n",
      " [ 62 378  51]\n",
      " [  4  52 409]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d8/nbkwtx_953q99tk0ckh0v0v40000gn/T/ipykernel_1614/181558703.py:7: RuntimeWarning: invalid value encountered in divide\n",
      "  f1_scores = 2 * (precision * recall) / (precision + recall)\n"
     ]
    }
   ],
   "source": [
    "probabilities = lr_meta_classifier.predict_proba(test_meta_features)\n",
    "\n",
    "# Calculate precision-recall curve and find optimal thresholds for each class\n",
    "lr_thresh = []\n",
    "for i in range(probabilities.shape[1]):  # Iterate over each class\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test == i, probabilities[:, i])\n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "    optimal_idx = np.nanargmax(f1_scores)  # Handle cases where precision and recall are both zero\n",
    "    lr_thresh.append(thresholds[optimal_idx])\n",
    "\n",
    "# Apply the optimized thresholds to make adjusted predictions\n",
    "adjusted_predictions = np.array([np.argmax([probabilities[i, j] if probabilities[i, j] >= lr_thresh[j] else 0\n",
    "                                         for j in range(probabilities.shape[1])])\n",
    "                              for i in range(len(probabilities))])\n",
    "\n",
    "# Evaluate\n",
    "adjusted_precision = precision_score(y_test, adjusted_predictions, average='macro')\n",
    "adjusted_recall = recall_score(y_test, adjusted_predictions, average='macro')\n",
    "adjusted_accuracy = accuracy_score(y_test, adjusted_predictions)\n",
    "adjusted_f1 = f1_score(y_test, adjusted_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_test, adjusted_predictions)\n",
    "\n",
    "print(\"Optimized thresholds for each class:\", lr_thresh)\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Precision: {adjusted_precision:.4f}\")\n",
    "print(f\"Recall: {adjusted_recall:.4f}\")\n",
    "print(f\"Ensemble accuracy: {adjusted_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {adjusted_f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfc6b32b-5f2a-4017-8a2b-e393ee1f85b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:07:55.192588Z",
     "iopub.status.busy": "2024-09-25T08:07:55.192499Z",
     "iopub.status.idle": "2024-09-25T08:07:56.344494Z",
     "shell.execute_reply": "2024-09-25T08:07:56.342511Z",
     "shell.execute_reply.started": "2024-09-25T08:07:55.192582Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated cells count: 4\n"
     ]
    }
   ],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '5-1!B4:E4'  \n",
    "\n",
    "values = [[\n",
    "    f\"{adjusted_precision * 100:.2f}\",\n",
    "    f\"{adjusted_recall * 100:.2f}\",\n",
    "    f\"{adjusted_accuracy * 100:.2f}\",\n",
    "    f\"{adjusted_f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f311d02-936c-467e-ae14-e0c9cd0f0211",
   "metadata": {},
   "source": [
    "### NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3cde7aba-1d7b-4fbd-94f0-98b9e5b2756a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:07:56.346302Z",
     "iopub.status.busy": "2024-09-25T08:07:56.345941Z",
     "iopub.status.idle": "2024-09-25T08:07:56.361514Z",
     "shell.execute_reply": "2024-09-25T08:07:56.360943Z",
     "shell.execute_reply.started": "2024-09-25T08:07:56.346266Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes\n",
      "Precision: 0.8299551086436332\n",
      "Recall: 0.819224901269445\n",
      "Ensemble accuracy: 0.8192090395480226\n",
      "F1 Score: 0.8226335233471197\n",
      "Confusion Matrix:\n",
      "[[368  91   1]\n",
      " [ 55 400  36]\n",
      " [  4  69 392]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "precision = precision_score(y_test, nb_final_predictions, average='macro')\n",
    "recall = recall_score(y_test, nb_final_predictions, average='macro')\n",
    "accuracy = accuracy_score(y_test, nb_final_predictions)\n",
    "f1 = f1_score(y_test, nb_final_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_test, nb_final_predictions)\n",
    "\n",
    "print(\"Naive Bayes\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Ensemble accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07991bda-71ea-4786-996b-61a3ae0132ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:07:56.362831Z",
     "iopub.status.busy": "2024-09-25T08:07:56.362617Z",
     "iopub.status.idle": "2024-09-25T08:07:56.380664Z",
     "shell.execute_reply": "2024-09-25T08:07:56.380289Z",
     "shell.execute_reply.started": "2024-09-25T08:07:56.362814Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized thresholds for each class: [0.004411088088945314, 0.5638814267913974, 0.15201185872705947]\n",
      "Naive Bayes\n",
      "Precision: 0.8300\n",
      "Recall: 0.8192\n",
      "Ensemble accuracy: 0.8192\n",
      "F1 Score: 0.8226335233471197\n",
      "Confusion Matrix:\n",
      "[[368  91   1]\n",
      " [ 55 400  36]\n",
      " [  4  69 392]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d8/nbkwtx_953q99tk0ckh0v0v40000gn/T/ipykernel_1614/3670015346.py:7: RuntimeWarning: invalid value encountered in divide\n",
      "  f1_scores = 2 * (precision * recall) / (precision + recall)\n"
     ]
    }
   ],
   "source": [
    "probabilities = nb_meta_classifier.predict_proba(test_meta_features)\n",
    "\n",
    "# Calculate precision-recall curve and find optimal thresholds for each class\n",
    "nb_thresh = []\n",
    "for i in range(probabilities.shape[1]):  # Iterate over each class\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test == i, probabilities[:, i])\n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "    optimal_idx = np.nanargmax(f1_scores)  # Handle cases where precision and recall are both zero\n",
    "    nb_thresh.append(thresholds[optimal_idx])\n",
    "\n",
    "# Apply the optimized thresholds to make adjusted predictions\n",
    "adjusted_predictions = np.array([np.argmax([probabilities[i, j] if probabilities[i, j] >= nb_thresh[j] else 0\n",
    "                                         for j in range(probabilities.shape[1])])\n",
    "                              for i in range(len(probabilities))])\n",
    "\n",
    "# Evaluate\n",
    "adjusted_precision = precision_score(y_test, adjusted_predictions, average='macro')\n",
    "adjusted_recall = recall_score(y_test, adjusted_predictions, average='macro')\n",
    "adjusted_accuracy = accuracy_score(y_test, adjusted_predictions)\n",
    "adjusted_f1 = f1_score(y_test, adjusted_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_test, adjusted_predictions)\n",
    "\n",
    "print(\"Optimized thresholds for each class:\", nb_thresh)\n",
    "print(\"Naive Bayes\")\n",
    "print(f\"Precision: {adjusted_precision:.4f}\")\n",
    "print(f\"Recall: {adjusted_recall:.4f}\")\n",
    "print(f\"Ensemble accuracy: {adjusted_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {adjusted_f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aecf64b8-5a1a-4cea-a077-2049e0459dd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:07:56.381843Z",
     "iopub.status.busy": "2024-09-25T08:07:56.381582Z",
     "iopub.status.idle": "2024-09-25T08:07:56.819027Z",
     "shell.execute_reply": "2024-09-25T08:07:56.817767Z",
     "shell.execute_reply.started": "2024-09-25T08:07:56.381831Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated cells count: 4\n"
     ]
    }
   ],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '5-1!B5:E5'  \n",
    "\n",
    "values = [[\n",
    "    f\"{adjusted_precision * 100:.2f}\",\n",
    "    f\"{adjusted_recall * 100:.2f}\",\n",
    "    f\"{adjusted_accuracy * 100:.2f}\",\n",
    "    f\"{adjusted_f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958d063b-7c6a-43d7-aaa2-0b93e3d56610",
   "metadata": {},
   "source": [
    "### DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c799950-2309-4a08-9778-351ab70a85db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:07:56.829413Z",
     "iopub.status.busy": "2024-09-25T08:07:56.828922Z",
     "iopub.status.idle": "2024-09-25T08:07:56.844696Z",
     "shell.execute_reply": "2024-09-25T08:07:56.844291Z",
     "shell.execute_reply.started": "2024-09-25T08:07:56.829385Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Precision: 0.8112158347716609\n",
      "Recall: 0.8084693883704404\n",
      "Ensemble accuracy: 0.8072033898305084\n",
      "F1 Score: 0.8094163742042273\n",
      "Confusion Matrix:\n",
      "[[386  71   3]\n",
      " [ 83 366  42]\n",
      " [  8  66 391]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "precision = precision_score(y_test, dt_final_predictions, average='macro')\n",
    "recall = recall_score(y_test, dt_final_predictions, average='macro')\n",
    "accuracy = accuracy_score(y_test, dt_final_predictions)\n",
    "f1 = f1_score(y_test, dt_final_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_test, dt_final_predictions)\n",
    "\n",
    "print(\"Decision Tree\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Ensemble accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a63b5fc-8c61-409f-86bf-470f00eb6d99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:07:56.845916Z",
     "iopub.status.busy": "2024-09-25T08:07:56.845482Z",
     "iopub.status.idle": "2024-09-25T08:07:56.859989Z",
     "shell.execute_reply": "2024-09-25T08:07:56.859666Z",
     "shell.execute_reply.started": "2024-09-25T08:07:56.845896Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized thresholds for each class: [0.42857142857142855, 0.5, 0.5714285714285714]\n",
      "Decision Tree\n",
      "Precision: 0.8089\n",
      "Recall: 0.8064\n",
      "Ensemble accuracy: 0.8051\n",
      "F1 Score: 0.8072205624508474\n",
      "Confusion Matrix:\n",
      "[[386  71   3]\n",
      " [ 86 363  42]\n",
      " [  9  65 391]]\n"
     ]
    }
   ],
   "source": [
    "probabilities = dt_meta_classifier.predict_proba(test_meta_features)\n",
    "\n",
    "# Calculate precision-recall curve and find optimal thresholds for each class\n",
    "dt_thresh = []\n",
    "for i in range(probabilities.shape[1]):  # Iterate over each class\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test == i, probabilities[:, i])\n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "    optimal_idx = np.nanargmax(f1_scores)  # Handle cases where precision and recall are both zero\n",
    "    dt_thresh.append(thresholds[optimal_idx])\n",
    "\n",
    "# Apply the optimized thresholds to make adjusted predictions\n",
    "adjusted_predictions = np.array([np.argmax([probabilities[i, j] if probabilities[i, j] >= dt_thresh[j] else 0\n",
    "                                         for j in range(probabilities.shape[1])])\n",
    "                              for i in range(len(probabilities))])\n",
    "\n",
    "# Evaluate\n",
    "adjusted_precision = precision_score(y_test, adjusted_predictions, average='macro')\n",
    "adjusted_recall = recall_score(y_test, adjusted_predictions, average='macro')\n",
    "adjusted_accuracy = accuracy_score(y_test, adjusted_predictions)\n",
    "adjusted_f1 = f1_score(y_test, adjusted_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_test, adjusted_predictions)\n",
    "\n",
    "print(\"Optimized thresholds for each class:\", dt_thresh)\n",
    "print(\"Decision Tree\")\n",
    "print(f\"Precision: {adjusted_precision:.4f}\")\n",
    "print(f\"Recall: {adjusted_recall:.4f}\")\n",
    "print(f\"Ensemble accuracy: {adjusted_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {adjusted_f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9653e844-4196-4d63-9b61-4998f3dba2d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:07:56.860674Z",
     "iopub.status.busy": "2024-09-25T08:07:56.860577Z",
     "iopub.status.idle": "2024-09-25T08:07:57.301123Z",
     "shell.execute_reply": "2024-09-25T08:07:57.299279Z",
     "shell.execute_reply.started": "2024-09-25T08:07:56.860666Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated cells count: 4\n"
     ]
    }
   ],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '5-1!B6:E6'  \n",
    "\n",
    "values = [[\n",
    "    f\"{adjusted_precision * 100:.2f}\",\n",
    "    f\"{adjusted_recall * 100:.2f}\",\n",
    "    f\"{adjusted_accuracy * 100:.2f}\",\n",
    "    f\"{adjusted_f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24614471-4cf3-4349-b8bb-98715c2db8a9",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f5a4d67-5a7a-4f32-b9c4-6f5c7612a256",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:07:57.302983Z",
     "iopub.status.busy": "2024-09-25T08:07:57.302695Z",
     "iopub.status.idle": "2024-09-25T08:07:57.318613Z",
     "shell.execute_reply": "2024-09-25T08:07:57.317966Z",
     "shell.execute_reply.started": "2024-09-25T08:07:57.302958Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "Precision: 0.8227973533537941\n",
      "Recall: 0.8154105042391534\n",
      "Ensemble accuracy: 0.8149717514124294\n",
      "F1 Score: 0.8180534022394488\n",
      "Confusion Matrix:\n",
      "[[372  86   2]\n",
      " [ 64 388  39]\n",
      " [  4  67 394]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "precision = precision_score(y_test, svm_final_predictions, average='macro')\n",
    "recall = recall_score(y_test, svm_final_predictions, average='macro')\n",
    "accuracy = accuracy_score(y_test, svm_final_predictions)\n",
    "f1 = f1_score(y_test, svm_final_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_test, svm_final_predictions)\n",
    "\n",
    "print(\"SVM\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Ensemble accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f4bf24f-5e38-4acf-b0d1-c42ddb5a862f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:07:57.320072Z",
     "iopub.status.busy": "2024-09-25T08:07:57.319552Z",
     "iopub.status.idle": "2024-09-25T08:07:57.361971Z",
     "shell.execute_reply": "2024-09-25T08:07:57.361605Z",
     "shell.execute_reply.started": "2024-09-25T08:07:57.320044Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized thresholds for each class: [0.1553717984698633, 0.19843826924503977, 0.5128764454085163]\n",
      "SVM\n",
      "Precision: 0.8190\n",
      "Recall: 0.8167\n",
      "Ensemble accuracy: 0.8157\n",
      "F1 Score: 0.8175811817225763\n",
      "Confusion Matrix:\n",
      "[[372  85   3]\n",
      " [ 64 374  53]\n",
      " [  4  52 409]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d8/nbkwtx_953q99tk0ckh0v0v40000gn/T/ipykernel_1614/2287312597.py:7: RuntimeWarning: invalid value encountered in divide\n",
      "  f1_scores = 2 * (precision * recall) / (precision + recall)\n"
     ]
    }
   ],
   "source": [
    "probabilities = svm_meta_classifier.predict_proba(test_meta_features)\n",
    "\n",
    "# Calculate precision-recall curve and find optimal thresholds for each class\n",
    "svm_thresh = []\n",
    "for i in range(probabilities.shape[1]):  # Iterate over each class\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test == i, probabilities[:, i])\n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "    optimal_idx = np.nanargmax(f1_scores)  # Handle cases where precision and recall are both zero\n",
    "    svm_thresh.append(thresholds[optimal_idx])\n",
    "\n",
    "# Apply the optimized thresholds to make adjusted predictions\n",
    "adjusted_predictions = np.array([np.argmax([probabilities[i, j] if probabilities[i, j] >= svm_thresh[j] else 0\n",
    "                                         for j in range(probabilities.shape[1])])\n",
    "                              for i in range(len(probabilities))])\n",
    "\n",
    "# Evaluate\n",
    "adjusted_precision = precision_score(y_test, adjusted_predictions, average='macro')\n",
    "adjusted_recall = recall_score(y_test, adjusted_predictions, average='macro')\n",
    "adjusted_accuracy = accuracy_score(y_test, adjusted_predictions)\n",
    "adjusted_f1 = f1_score(y_test, adjusted_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_test, adjusted_predictions)\n",
    "\n",
    "print(\"Optimized thresholds for each class:\", svm_thresh)\n",
    "print(\"SVM\")\n",
    "print(f\"Precision: {adjusted_precision:.4f}\")\n",
    "print(f\"Recall: {adjusted_recall:.4f}\")\n",
    "print(f\"Ensemble accuracy: {adjusted_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {adjusted_f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "92382252-0d77-45d8-bb20-8c5c7f2a983b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:07:57.362630Z",
     "iopub.status.busy": "2024-09-25T08:07:57.362525Z",
     "iopub.status.idle": "2024-09-25T08:07:57.792759Z",
     "shell.execute_reply": "2024-09-25T08:07:57.790713Z",
     "shell.execute_reply.started": "2024-09-25T08:07:57.362622Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated cells count: 4\n"
     ]
    }
   ],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '5-1!B7:E7'  \n",
    "\n",
    "values = [[\n",
    "    f\"{adjusted_precision * 100:.2f}\",\n",
    "    f\"{adjusted_recall * 100:.2f}\",\n",
    "    f\"{adjusted_accuracy * 100:.2f}\",\n",
    "    f\"{adjusted_f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0143f6-14c3-431a-b08b-7f182a0c7c96",
   "metadata": {},
   "source": [
    "## TEST DATA C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a7c1fca-bf56-43cf-8559-e8acfd5dc262",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:07:57.794913Z",
     "iopub.status.busy": "2024-09-25T08:07:57.794255Z",
     "iopub.status.idle": "2024-09-25T08:08:26.842718Z",
     "shell.execute_reply": "2024-09-25T08:08:26.842346Z",
     "shell.execute_reply.started": "2024-09-25T08:07:57.794888Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Load validation data\n",
    "validation_file_path = 'Corpus/FiReCS/FiReCS_data_c.csv'\n",
    "validation_df = pd.read_csv(validation_file_path)\n",
    "\n",
    "X_val = validation_df['review'].values \n",
    "y_val = validation_df['label'].values\n",
    "\n",
    "# Generate meta-features for data c dataset\n",
    "val_meta_features = get_predictions(model_info, X_val, y_val, device) \n",
    "\n",
    "# Predict using the logistic regression meta-classifier\n",
    "val_lr_predictions = lr_meta_classifier.predict(val_meta_features)\n",
    "\n",
    "# Predict using the naive bayes meta-classifier\n",
    "val_nb_predictions = nb_meta_classifier.predict(val_meta_features)\n",
    "\n",
    "# Predict using the decision tree meta-classifier\n",
    "val_dt_predictions = dt_meta_classifier.predict(val_meta_features)\n",
    "\n",
    "# Predict using the svm meta-classifier\n",
    "val_svm_predictions = svm_meta_classifier.predict(val_meta_features)\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0693ac-17b2-4645-be71-fe4c1f337e38",
   "metadata": {},
   "source": [
    "### LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5303f868-1507-4252-9f50-136aa337f630",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:08:26.843201Z",
     "iopub.status.busy": "2024-09-25T08:08:26.843122Z",
     "iopub.status.idle": "2024-09-25T08:08:26.848305Z",
     "shell.execute_reply": "2024-09-25T08:08:26.848074Z",
     "shell.execute_reply.started": "2024-09-25T08:08:26.843194Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on HS-Data C Dataset\n",
      "Precision: 0.8216431194372372\n",
      "Recall: 0.8133162473935167\n",
      "Accuracy: 0.8131553860819828\n",
      "F1 Score: 0.8158528678883554\n",
      "Confusion Matrix:\n",
      "[[265  72   4]\n",
      " [ 38 291  35]\n",
      " [  3  44 297]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the predictions\n",
    "precision = precision_score(y_val, val_lr_predictions, average='macro')\n",
    "recall = recall_score(y_val, val_lr_predictions, average='macro')\n",
    "accuracy = accuracy_score(y_val, val_lr_predictions)\n",
    "f1 = f1_score(y_val, val_lr_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_val, val_lr_predictions)\n",
    "\n",
    "print(\"Evaluation on HS-Data C Dataset\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d732e24d-540c-4934-a359-e7098db0eaaf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:08:26.848736Z",
     "iopub.status.busy": "2024-09-25T08:08:26.848661Z",
     "iopub.status.idle": "2024-09-25T08:08:26.857065Z",
     "shell.execute_reply": "2024-09-25T08:08:26.856809Z",
     "shell.execute_reply.started": "2024-09-25T08:08:26.848729Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results\n",
      "Precision: 0.8122\n",
      "Recall: 0.8116\n",
      "Accuracy: 0.8103\n",
      "F1 Score: 0.8117\n",
      "Confusion Matrix:\n",
      "[[277  58   6]\n",
      " [ 47 271  46]\n",
      " [  3  39 302]]\n"
     ]
    }
   ],
   "source": [
    "lr_validation_probabilities = lr_meta_classifier.predict_proba(val_meta_features)\n",
    "\n",
    "# Apply thresholds to the validation set probabilities to make final predictions\n",
    "lr_validation_predictions = np.array([np.argmax([lr_validation_probabilities[i, j] if lr_validation_probabilities[i, j] >= lr_thresh[j] else 0\n",
    "                                              for j in range(lr_validation_probabilities.shape[1])])\n",
    "                                   for i in range(len(lr_validation_probabilities))])\n",
    "\n",
    "# Evaluate threshold on validation set\n",
    "adjusted_precision = precision_score(y_val, lr_validation_predictions, average='macro')\n",
    "adjusted_recall = recall_score(y_val, lr_validation_predictions, average='macro')\n",
    "adjusted_accuracy = accuracy_score(y_val, lr_validation_predictions)\n",
    "adjusted_f1 = f1_score(y_val, lr_validation_predictions, average='macro')\n",
    "adjusted_conf_matrix = confusion_matrix(y_val, lr_validation_predictions)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Validation Results\")\n",
    "print(f\"Precision: {adjusted_precision:.4f}\")\n",
    "print(f\"Recall: {adjusted_recall:.4f}\")\n",
    "print(f\"Accuracy: {adjusted_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {adjusted_f1:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(adjusted_conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "35d847f4-0bc4-4f4f-a1ff-22d5d990820f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:08:26.857631Z",
     "iopub.status.busy": "2024-09-25T08:08:26.857523Z",
     "iopub.status.idle": "2024-09-25T08:08:27.324956Z",
     "shell.execute_reply": "2024-09-25T08:08:27.322863Z",
     "shell.execute_reply.started": "2024-09-25T08:08:26.857625Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated cells count: 4\n"
     ]
    }
   ],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '5-1!F4:I4'  \n",
    "\n",
    "values = [[\n",
    "    f\"{adjusted_precision * 100:.2f}\",\n",
    "    f\"{adjusted_recall * 100:.2f}\",\n",
    "    f\"{adjusted_accuracy * 100:.2f}\",\n",
    "    f\"{adjusted_f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d20e88-5a01-4b56-ad36-37c984d10277",
   "metadata": {},
   "source": [
    "#### Save CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ca78187-3e76-4798-b348-64b200b29eb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:08:27.326866Z",
     "iopub.status.busy": "2024-09-25T08:08:27.326466Z",
     "iopub.status.idle": "2024-09-25T08:08:27.551925Z",
     "shell.execute_reply": "2024-09-25T08:08:27.551709Z",
     "shell.execute_reply.started": "2024-09-25T08:08:27.326838Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-40e798745e464695a268bc1245fb0889.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-40e798745e464695a268bc1245fb0889.vega-embed details,\n",
       "  #altair-viz-40e798745e464695a268bc1245fb0889.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-40e798745e464695a268bc1245fb0889\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-40e798745e464695a268bc1245fb0889\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-40e798745e464695a268bc1245fb0889\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"rect\"}, \"encoding\": {\"color\": {\"field\": \"Count\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"True\", \"type\": \"ordinal\"}, {\"field\": \"Predicted\", \"type\": \"ordinal\"}, {\"field\": \"Count\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Predicted\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}, \"y\": {\"field\": \"True\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}}, \"title\": \"OF_Using_FIRE 5STK-1 LR\"}, {\"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"middle\", \"fontSize\": 12}, \"encoding\": {\"color\": {\"condition\": {\"test\": \"(datum.Count > 151.0)\", \"value\": \"white\"}, \"value\": \"black\"}, \"text\": {\"field\": \"Count\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"True\", \"type\": \"ordinal\"}, {\"field\": \"Predicted\", \"type\": \"ordinal\"}, {\"field\": \"Count\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Predicted\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}, \"y\": {\"field\": \"True\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}}, \"title\": \"OF_Using_FIRE 5STK-1 LR\"}], \"data\": {\"name\": \"data-6bb300ede76a2976ced5ebb78fcca0e7\"}, \"height\": 300, \"width\": 400, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-6bb300ede76a2976ced5ebb78fcca0e7\": [{\"True\": \"Negative\", \"Predicted\": \"Negative\", \"Count\": 277}, {\"True\": \"Neutral\", \"Predicted\": \"Negative\", \"Count\": 47}, {\"True\": \"Positive\", \"Predicted\": \"Negative\", \"Count\": 3}, {\"True\": \"Negative\", \"Predicted\": \"Neutral\", \"Count\": 58}, {\"True\": \"Neutral\", \"Predicted\": \"Neutral\", \"Count\": 271}, {\"True\": \"Positive\", \"Predicted\": \"Neutral\", \"Count\": 39}, {\"True\": \"Negative\", \"Predicted\": \"Positive\", \"Count\": 6}, {\"True\": \"Neutral\", \"Predicted\": \"Positive\", \"Count\": 46}, {\"True\": \"Positive\", \"Predicted\": \"Positive\", \"Count\": 302}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import altair as alt\n",
    "import altair_saver\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_val, lr_validation_predictions)\n",
    "\n",
    "# Define class names\n",
    "class_names = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "# Convert confusion matrix to DataFrame\n",
    "cm_df = pd.DataFrame(cm, index=class_names, columns=class_names).reset_index().melt(id_vars='index')\n",
    "cm_df.columns = ['True', 'Predicted', 'Count']\n",
    "\n",
    "# Ensure the order of categories\n",
    "cm_df['True'] = pd.Categorical(cm_df['True'], categories=class_names, ordered=True)\n",
    "cm_df['Predicted'] = pd.Categorical(cm_df['Predicted'], categories=class_names, ordered=True)\n",
    "\n",
    "# Create the Altair plot\n",
    "heatmap = alt.Chart(cm_df).mark_rect().encode(\n",
    "    x=alt.X('Predicted:O', sort=class_names),\n",
    "    y=alt.Y('True:O', sort=class_names),\n",
    "    color='Count:Q',\n",
    "    tooltip=['True', 'Predicted', 'Count']\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=300,\n",
    "    title='OF_Using_FIRE 5STK-1 LR'\n",
    ")\n",
    "\n",
    "# Add text labels\n",
    "text = heatmap.mark_text(\n",
    "    align='center',\n",
    "    baseline='middle',\n",
    "    fontSize=12\n",
    ").encode(\n",
    "    text='Count:Q',\n",
    "    color=alt.condition(\n",
    "        alt.datum.Count > cm.max() / 2,\n",
    "        alt.value('white'),\n",
    "        alt.value('black')\n",
    "    )\n",
    ")\n",
    "\n",
    "# Combine heatmap and text\n",
    "final_chart = heatmap + text\n",
    "\n",
    "# Display the plot\n",
    "final_chart.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4018e7ba-2de6-44d9-9a6f-bf13ccb33108",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:08:27.552431Z",
     "iopub.status.busy": "2024-09-25T08:08:27.552348Z",
     "iopub.status.idle": "2024-09-25T08:08:27.948687Z",
     "shell.execute_reply": "2024-09-25T08:08:27.948390Z",
     "shell.execute_reply.started": "2024-09-25T08:08:27.552423Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to Results/Ensemble Model Results/On FireCS dataset/OF Using FIRE ENSEMBLE/Stacking/OF_Using_FIRE 5STK-1 LR.png\n"
     ]
    }
   ],
   "source": [
    "# Specify the folder path\n",
    "folder_path = os.path.expanduser('Results/Ensemble Model Results/On FireCS dataset/OF Using FIRE ENSEMBLE/Stacking/')\n",
    "\n",
    "# Save the plot using vl-convert\n",
    "file_path_png = os.path.join(folder_path, 'OF_Using_FIRE 5STK-1 LR.png')\n",
    "final_chart.save(file_path_png)\n",
    "\n",
    "print(f\"Plot saved to {file_path_png}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e3bc0f-597f-47e3-ba99-5d9cafd1aea3",
   "metadata": {},
   "source": [
    "### NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0af5051f-834f-4646-afef-37bfdfdc43d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:08:27.949139Z",
     "iopub.status.busy": "2024-09-25T08:08:27.949055Z",
     "iopub.status.idle": "2024-09-25T08:08:27.954088Z",
     "shell.execute_reply": "2024-09-25T08:08:27.953871Z",
     "shell.execute_reply.started": "2024-09-25T08:08:27.949133Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on HS-Data C Dataset\n",
      "Precision: 0.8213692175758435\n",
      "Recall: 0.8112717802327705\n",
      "Accuracy: 0.8112488083889419\n",
      "F1 Score: 0.814408282888504\n",
      "Confusion Matrix:\n",
      "[[265  73   3]\n",
      " [ 41 293  30]\n",
      " [  3  48 293]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the predictions\n",
    "precision = precision_score(y_val, val_nb_predictions, average='macro')\n",
    "recall = recall_score(y_val, val_nb_predictions, average='macro')\n",
    "accuracy = accuracy_score(y_val, val_nb_predictions)\n",
    "f1 = f1_score(y_val, val_nb_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_val, val_nb_predictions)\n",
    "\n",
    "print(\"Evaluation on HS-Data C Dataset\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d1acd42b-ca2c-40be-b90e-e7fb7f6eeb2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:08:27.954622Z",
     "iopub.status.busy": "2024-09-25T08:08:27.954505Z",
     "iopub.status.idle": "2024-09-25T08:08:27.963457Z",
     "shell.execute_reply": "2024-09-25T08:08:27.963220Z",
     "shell.execute_reply.started": "2024-09-25T08:08:27.954616Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results\n",
      "Precision: 0.8214\n",
      "Recall: 0.8113\n",
      "Accuracy: 0.8112\n",
      "F1 Score: 0.8144\n",
      "Confusion Matrix:\n",
      "[[265  73   3]\n",
      " [ 41 293  30]\n",
      " [  3  48 293]]\n"
     ]
    }
   ],
   "source": [
    "nb_validation_probabilities = nb_meta_classifier.predict_proba(val_meta_features)\n",
    "\n",
    "# Apply thresholds to the validation set probabilities to make final predictions\n",
    "nb_validation_predictions = np.array([np.argmax([nb_validation_probabilities[i, j] if nb_validation_probabilities[i, j] >= nb_thresh[j] else 0\n",
    "                                              for j in range(nb_validation_probabilities.shape[1])])\n",
    "                                   for i in range(len(nb_validation_probabilities))])\n",
    "\n",
    "# Evaluate threshold on validation set\n",
    "adjusted_precision = precision_score(y_val, nb_validation_predictions, average='macro')\n",
    "adjusted_recall = recall_score(y_val, nb_validation_predictions, average='macro')\n",
    "adjusted_accuracy = accuracy_score(y_val, nb_validation_predictions)\n",
    "adjusted_f1 = f1_score(y_val, nb_validation_predictions, average='macro')\n",
    "adjusted_conf_matrix = confusion_matrix(y_val, nb_validation_predictions)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Validation Results\")\n",
    "print(f\"Precision: {adjusted_precision:.4f}\")\n",
    "print(f\"Recall: {adjusted_recall:.4f}\")\n",
    "print(f\"Accuracy: {adjusted_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {adjusted_f1:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(adjusted_conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fe5b7918-e4a2-4fd5-bfc3-74bb308a085b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:08:27.963967Z",
     "iopub.status.busy": "2024-09-25T08:08:27.963879Z",
     "iopub.status.idle": "2024-09-25T08:08:28.425137Z",
     "shell.execute_reply": "2024-09-25T08:08:28.422111Z",
     "shell.execute_reply.started": "2024-09-25T08:08:27.963960Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated cells count: 4\n"
     ]
    }
   ],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '5-1!F5:I5'  \n",
    "\n",
    "values = [[\n",
    "    f\"{adjusted_precision * 100:.2f}\",\n",
    "    f\"{adjusted_recall * 100:.2f}\",\n",
    "    f\"{adjusted_accuracy * 100:.2f}\",\n",
    "    f\"{adjusted_f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65529983-86a3-4c32-b155-c08fcdf20b31",
   "metadata": {},
   "source": [
    "#### Save CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea993771-7e1b-4a65-8e32-29912f2564d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:08:28.429018Z",
     "iopub.status.busy": "2024-09-25T08:08:28.428435Z",
     "iopub.status.idle": "2024-09-25T08:08:28.477302Z",
     "shell.execute_reply": "2024-09-25T08:08:28.476941Z",
     "shell.execute_reply.started": "2024-09-25T08:08:28.428986Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-f1724720d0cc45e5a15e14f4ee2e77d4.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-f1724720d0cc45e5a15e14f4ee2e77d4.vega-embed details,\n",
       "  #altair-viz-f1724720d0cc45e5a15e14f4ee2e77d4.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-f1724720d0cc45e5a15e14f4ee2e77d4\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-f1724720d0cc45e5a15e14f4ee2e77d4\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-f1724720d0cc45e5a15e14f4ee2e77d4\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"rect\"}, \"encoding\": {\"color\": {\"field\": \"Count\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"True\", \"type\": \"ordinal\"}, {\"field\": \"Predicted\", \"type\": \"ordinal\"}, {\"field\": \"Count\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Predicted\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}, \"y\": {\"field\": \"True\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}}, \"title\": \"OF_Using_FIRE 5STK-1 NB\"}, {\"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"middle\", \"fontSize\": 12}, \"encoding\": {\"color\": {\"condition\": {\"test\": \"(datum.Count > 146.5)\", \"value\": \"white\"}, \"value\": \"black\"}, \"text\": {\"field\": \"Count\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"True\", \"type\": \"ordinal\"}, {\"field\": \"Predicted\", \"type\": \"ordinal\"}, {\"field\": \"Count\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Predicted\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}, \"y\": {\"field\": \"True\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}}, \"title\": \"OF_Using_FIRE 5STK-1 NB\"}], \"data\": {\"name\": \"data-c066b527e06b84bd61265323615895d1\"}, \"height\": 300, \"width\": 400, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-c066b527e06b84bd61265323615895d1\": [{\"True\": \"Negative\", \"Predicted\": \"Negative\", \"Count\": 265}, {\"True\": \"Neutral\", \"Predicted\": \"Negative\", \"Count\": 41}, {\"True\": \"Positive\", \"Predicted\": \"Negative\", \"Count\": 3}, {\"True\": \"Negative\", \"Predicted\": \"Neutral\", \"Count\": 73}, {\"True\": \"Neutral\", \"Predicted\": \"Neutral\", \"Count\": 293}, {\"True\": \"Positive\", \"Predicted\": \"Neutral\", \"Count\": 48}, {\"True\": \"Negative\", \"Predicted\": \"Positive\", \"Count\": 3}, {\"True\": \"Neutral\", \"Predicted\": \"Positive\", \"Count\": 30}, {\"True\": \"Positive\", \"Predicted\": \"Positive\", \"Count\": 293}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import altair as alt\n",
    "import altair_saver\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_val, nb_validation_predictions)\n",
    "\n",
    "# Define class names\n",
    "class_names = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "# Convert confusion matrix to DataFrame\n",
    "cm_df = pd.DataFrame(cm, index=class_names, columns=class_names).reset_index().melt(id_vars='index')\n",
    "cm_df.columns = ['True', 'Predicted', 'Count']\n",
    "\n",
    "# Ensure the order of categories\n",
    "cm_df['True'] = pd.Categorical(cm_df['True'], categories=class_names, ordered=True)\n",
    "cm_df['Predicted'] = pd.Categorical(cm_df['Predicted'], categories=class_names, ordered=True)\n",
    "\n",
    "# Create the Altair plot\n",
    "heatmap = alt.Chart(cm_df).mark_rect().encode(\n",
    "    x=alt.X('Predicted:O', sort=class_names),\n",
    "    y=alt.Y('True:O', sort=class_names),\n",
    "    color='Count:Q',\n",
    "    tooltip=['True', 'Predicted', 'Count']\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=300,\n",
    "    title='OF_Using_FIRE 5STK-1 NB'\n",
    ")\n",
    "\n",
    "# Add text labels\n",
    "text = heatmap.mark_text(\n",
    "    align='center',\n",
    "    baseline='middle',\n",
    "    fontSize=12\n",
    ").encode(\n",
    "    text='Count:Q',\n",
    "    color=alt.condition(\n",
    "        alt.datum.Count > cm.max() / 2,\n",
    "        alt.value('white'),\n",
    "        alt.value('black')\n",
    "    )\n",
    ")\n",
    "\n",
    "# Combine heatmap and text\n",
    "final_chart = heatmap + text\n",
    "\n",
    "# Display the plot\n",
    "final_chart.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "031b9ce6-7d92-4735-a298-e8f7812ebae0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:08:28.478001Z",
     "iopub.status.busy": "2024-09-25T08:08:28.477889Z",
     "iopub.status.idle": "2024-09-25T08:08:28.523247Z",
     "shell.execute_reply": "2024-09-25T08:08:28.522913Z",
     "shell.execute_reply.started": "2024-09-25T08:08:28.477992Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to Results/Ensemble Model Results/On FireCS dataset/OF Using FIRE ENSEMBLE/Stacking/OF_Using_FIRE 5STK-1 NB.png\n"
     ]
    }
   ],
   "source": [
    "# Specify the folder path\n",
    "folder_path = os.path.expanduser('Results/Ensemble Model Results/On FireCS dataset/OF Using FIRE ENSEMBLE/Stacking/')\n",
    "\n",
    "# Save the plot using vl-convert\n",
    "file_path_png = os.path.join(folder_path, 'OF_Using_FIRE 5STK-1 NB.png')\n",
    "final_chart.save(file_path_png)\n",
    "\n",
    "print(f\"Plot saved to {file_path_png}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba2269b-62c4-43d2-8394-9aa3c1a27678",
   "metadata": {},
   "source": [
    "### DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0448f107-62d6-4f1a-8b04-4378b79f3d3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:08:28.524189Z",
     "iopub.status.busy": "2024-09-25T08:08:28.523887Z",
     "iopub.status.idle": "2024-09-25T08:08:28.529772Z",
     "shell.execute_reply": "2024-09-25T08:08:28.529490Z",
     "shell.execute_reply.started": "2024-09-25T08:08:28.524170Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on HS-Data C Dataset\n",
      "Precision: 0.8094056302645259\n",
      "Recall: 0.8044037108178143\n",
      "Accuracy: 0.8036224976167778\n",
      "F1 Score: 0.8063653037224756\n",
      "Confusion Matrix:\n",
      "[[275  63   3]\n",
      " [ 53 278  33]\n",
      " [  5  49 290]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the predictions\n",
    "precision = precision_score(y_val, val_dt_predictions, average='macro')\n",
    "recall = recall_score(y_val, val_dt_predictions, average='macro')\n",
    "accuracy = accuracy_score(y_val, val_dt_predictions)\n",
    "f1 = f1_score(y_val, val_dt_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_val, val_dt_predictions)\n",
    "\n",
    "print(\"Evaluation on HS-Data C Dataset\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9a0f105d-eb8f-4450-9d41-d90c97cf028c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:08:28.530483Z",
     "iopub.status.busy": "2024-09-25T08:08:28.530328Z",
     "iopub.status.idle": "2024-09-25T08:08:28.539256Z",
     "shell.execute_reply": "2024-09-25T08:08:28.539012Z",
     "shell.execute_reply.started": "2024-09-25T08:08:28.530475Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results\n",
      "Precision: 0.8038\n",
      "Recall: 0.7998\n",
      "Accuracy: 0.7989\n",
      "F1 Score: 0.8014\n",
      "Confusion Matrix:\n",
      "[[276  62   3]\n",
      " [ 57 274  33]\n",
      " [  9  47 288]]\n"
     ]
    }
   ],
   "source": [
    "dt_validation_probabilities = dt_meta_classifier.predict_proba(val_meta_features)\n",
    "\n",
    "# Apply thresholds to the validation set probabilities to make final predictions\n",
    "dt_validation_predictions = np.array([np.argmax([dt_validation_probabilities[i, j] if dt_validation_probabilities[i, j] >= dt_thresh[j] else 0\n",
    "                                              for j in range(dt_validation_probabilities.shape[1])])\n",
    "                                   for i in range(len(dt_validation_probabilities))])\n",
    "\n",
    "# Evaluate threshold on validation set\n",
    "adjusted_precision = precision_score(y_val, dt_validation_predictions, average='macro')\n",
    "adjusted_recall = recall_score(y_val, dt_validation_predictions, average='macro')\n",
    "adjusted_accuracy = accuracy_score(y_val, dt_validation_predictions)\n",
    "adjusted_f1 = f1_score(y_val, dt_validation_predictions, average='macro')\n",
    "adjusted_conf_matrix = confusion_matrix(y_val, dt_validation_predictions)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Validation Results\")\n",
    "print(f\"Precision: {adjusted_precision:.4f}\")\n",
    "print(f\"Recall: {adjusted_recall:.4f}\")\n",
    "print(f\"Accuracy: {adjusted_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {adjusted_f1:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(adjusted_conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dec85bf2-3044-4247-90ec-703089be962b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:08:28.539670Z",
     "iopub.status.busy": "2024-09-25T08:08:28.539589Z",
     "iopub.status.idle": "2024-09-25T08:08:28.980421Z",
     "shell.execute_reply": "2024-09-25T08:08:28.979562Z",
     "shell.execute_reply.started": "2024-09-25T08:08:28.539663Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated cells count: 4\n"
     ]
    }
   ],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '5-1!F6:I6'  \n",
    "\n",
    "values = [[\n",
    "    f\"{adjusted_precision * 100:.2f}\",\n",
    "    f\"{adjusted_recall * 100:.2f}\",\n",
    "    f\"{adjusted_accuracy * 100:.2f}\",\n",
    "    f\"{adjusted_f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8589d71-c489-4214-9c56-4a3a7ed69506",
   "metadata": {},
   "source": [
    "#### Save CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bb07bbd3-2021-4e16-8b59-3908f095b7cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:08:28.982545Z",
     "iopub.status.busy": "2024-09-25T08:08:28.982040Z",
     "iopub.status.idle": "2024-09-25T08:08:29.033474Z",
     "shell.execute_reply": "2024-09-25T08:08:29.033147Z",
     "shell.execute_reply.started": "2024-09-25T08:08:28.982513Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-fb08cdd747374e6a9a70f7c7873ec677.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-fb08cdd747374e6a9a70f7c7873ec677.vega-embed details,\n",
       "  #altair-viz-fb08cdd747374e6a9a70f7c7873ec677.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-fb08cdd747374e6a9a70f7c7873ec677\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-fb08cdd747374e6a9a70f7c7873ec677\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-fb08cdd747374e6a9a70f7c7873ec677\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"rect\"}, \"encoding\": {\"color\": {\"field\": \"Count\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"True\", \"type\": \"ordinal\"}, {\"field\": \"Predicted\", \"type\": \"ordinal\"}, {\"field\": \"Count\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Predicted\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}, \"y\": {\"field\": \"True\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}}, \"title\": \"OF_Using_FIRE 5STK-1 DT\"}, {\"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"middle\", \"fontSize\": 12}, \"encoding\": {\"color\": {\"condition\": {\"test\": \"(datum.Count > 144.0)\", \"value\": \"white\"}, \"value\": \"black\"}, \"text\": {\"field\": \"Count\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"True\", \"type\": \"ordinal\"}, {\"field\": \"Predicted\", \"type\": \"ordinal\"}, {\"field\": \"Count\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Predicted\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}, \"y\": {\"field\": \"True\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}}, \"title\": \"OF_Using_FIRE 5STK-1 DT\"}], \"data\": {\"name\": \"data-f1e125a0979eed26967229cf1a88414f\"}, \"height\": 300, \"width\": 400, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-f1e125a0979eed26967229cf1a88414f\": [{\"True\": \"Negative\", \"Predicted\": \"Negative\", \"Count\": 276}, {\"True\": \"Neutral\", \"Predicted\": \"Negative\", \"Count\": 57}, {\"True\": \"Positive\", \"Predicted\": \"Negative\", \"Count\": 9}, {\"True\": \"Negative\", \"Predicted\": \"Neutral\", \"Count\": 62}, {\"True\": \"Neutral\", \"Predicted\": \"Neutral\", \"Count\": 274}, {\"True\": \"Positive\", \"Predicted\": \"Neutral\", \"Count\": 47}, {\"True\": \"Negative\", \"Predicted\": \"Positive\", \"Count\": 3}, {\"True\": \"Neutral\", \"Predicted\": \"Positive\", \"Count\": 33}, {\"True\": \"Positive\", \"Predicted\": \"Positive\", \"Count\": 288}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import altair as alt\n",
    "import altair_saver\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_val, dt_validation_predictions)\n",
    "\n",
    "# Define class names\n",
    "class_names = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "# Convert confusion matrix to DataFrame\n",
    "cm_df = pd.DataFrame(cm, index=class_names, columns=class_names).reset_index().melt(id_vars='index')\n",
    "cm_df.columns = ['True', 'Predicted', 'Count']\n",
    "\n",
    "# Ensure the order of categories\n",
    "cm_df['True'] = pd.Categorical(cm_df['True'], categories=class_names, ordered=True)\n",
    "cm_df['Predicted'] = pd.Categorical(cm_df['Predicted'], categories=class_names, ordered=True)\n",
    "\n",
    "# Create the Altair plot\n",
    "heatmap = alt.Chart(cm_df).mark_rect().encode(\n",
    "    x=alt.X('Predicted:O', sort=class_names),\n",
    "    y=alt.Y('True:O', sort=class_names),\n",
    "    color='Count:Q',\n",
    "    tooltip=['True', 'Predicted', 'Count']\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=300,\n",
    "    title='OF_Using_FIRE 5STK-1 DT'\n",
    ")\n",
    "\n",
    "# Add text labels\n",
    "text = heatmap.mark_text(\n",
    "    align='center',\n",
    "    baseline='middle',\n",
    "    fontSize=12\n",
    ").encode(\n",
    "    text='Count:Q',\n",
    "    color=alt.condition(\n",
    "        alt.datum.Count > cm.max() / 2,\n",
    "        alt.value('white'),\n",
    "        alt.value('black')\n",
    "    )\n",
    ")\n",
    "\n",
    "# Combine heatmap and text\n",
    "final_chart = heatmap + text\n",
    "\n",
    "# Display the plot\n",
    "final_chart.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5445e621-6288-4a87-9e75-bf4511b2d9a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:08:29.034179Z",
     "iopub.status.busy": "2024-09-25T08:08:29.034075Z",
     "iopub.status.idle": "2024-09-25T08:08:29.080506Z",
     "shell.execute_reply": "2024-09-25T08:08:29.080177Z",
     "shell.execute_reply.started": "2024-09-25T08:08:29.034171Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to Results/Ensemble Model Results/On FireCS dataset/OF Using FIRE ENSEMBLE/Stacking/OF_Using_FIRE 5STK-1 DT.png\n"
     ]
    }
   ],
   "source": [
    "# Specify the folder path\n",
    "folder_path = os.path.expanduser('Results/Ensemble Model Results/On FireCS dataset/OF Using FIRE ENSEMBLE/Stacking/')\n",
    "\n",
    "# Save the plot using vl-convert\n",
    "file_path_png = os.path.join(folder_path, 'OF_Using_FIRE 5STK-1 DT.png')\n",
    "final_chart.save(file_path_png)\n",
    "\n",
    "print(f\"Plot saved to {file_path_png}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6165ef-d0ff-4230-9fdb-3c6a774d728f",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "660f90df-3de4-41b1-9fc6-4285133ec0a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:08:29.081112Z",
     "iopub.status.busy": "2024-09-25T08:08:29.081032Z",
     "iopub.status.idle": "2024-09-25T08:08:29.087127Z",
     "shell.execute_reply": "2024-09-25T08:08:29.086849Z",
     "shell.execute_reply.started": "2024-09-25T08:08:29.081104Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on HS-Data C Dataset\n",
      "Precision: 0.7985484561441809\n",
      "Recall: 0.7865954375706815\n",
      "Accuracy: 0.786463298379409\n",
      "F1 Score: 0.7903843485374753\n",
      "Confusion Matrix:\n",
      "[[257  81   3]\n",
      " [ 49 282  33]\n",
      " [  2  56 286]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the predictions\n",
    "precision = precision_score(y_val, val_svm_predictions, average='macro')\n",
    "recall = recall_score(y_val, val_svm_predictions, average='macro')\n",
    "accuracy = accuracy_score(y_val, val_svm_predictions)\n",
    "f1 = f1_score(y_val, val_svm_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_val, val_svm_predictions)\n",
    "\n",
    "print(\"Evaluation on HS-Data C Dataset\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ad2fba87-04de-46b7-bc1d-1fbf7d1bb263",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:08:29.087729Z",
     "iopub.status.busy": "2024-09-25T08:08:29.087602Z",
     "iopub.status.idle": "2024-09-25T08:08:29.108070Z",
     "shell.execute_reply": "2024-09-25T08:08:29.107732Z",
     "shell.execute_reply.started": "2024-09-25T08:08:29.087722Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results\n",
      "Precision: 0.7903\n",
      "Recall: 0.7864\n",
      "Accuracy: 0.7855\n",
      "F1 Score: 0.7873\n",
      "Confusion Matrix:\n",
      "[[256  77   8]\n",
      " [ 48 267  49]\n",
      " [  2  41 301]]\n"
     ]
    }
   ],
   "source": [
    "svm_validation_probabilities = svm_meta_classifier.predict_proba(val_meta_features)\n",
    "\n",
    "# Apply thresholds to the validation set probabilities to make final predictions\n",
    "svm_validation_predictions = np.array([np.argmax([svm_validation_probabilities[i, j] if svm_validation_probabilities[i, j] >= svm_thresh[j] else 0\n",
    "                                              for j in range(svm_validation_probabilities.shape[1])])\n",
    "                                   for i in range(len(svm_validation_probabilities))])\n",
    "\n",
    "# Evaluate threshold on validation set\n",
    "adjusted_precision = precision_score(y_val, svm_validation_predictions, average='macro')\n",
    "adjusted_recall = recall_score(y_val, svm_validation_predictions, average='macro')\n",
    "adjusted_accuracy = accuracy_score(y_val, svm_validation_predictions)\n",
    "adjusted_f1 = f1_score(y_val, svm_validation_predictions, average='macro')\n",
    "adjusted_conf_matrix = confusion_matrix(y_val, svm_validation_predictions)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Validation Results\")\n",
    "print(f\"Precision: {adjusted_precision:.4f}\")\n",
    "print(f\"Recall: {adjusted_recall:.4f}\")\n",
    "print(f\"Accuracy: {adjusted_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {adjusted_f1:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(adjusted_conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7644868d-4140-415e-be20-4db4bfbf21b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:08:29.108802Z",
     "iopub.status.busy": "2024-09-25T08:08:29.108711Z",
     "iopub.status.idle": "2024-09-25T08:08:29.469553Z",
     "shell.execute_reply": "2024-09-25T08:08:29.467868Z",
     "shell.execute_reply.started": "2024-09-25T08:08:29.108793Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated cells count: 4\n"
     ]
    }
   ],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '5-1!F7:I7'  \n",
    "\n",
    "values = [[\n",
    "    f\"{adjusted_precision * 100:.2f}\",\n",
    "    f\"{adjusted_recall * 100:.2f}\",\n",
    "    f\"{adjusted_accuracy * 100:.2f}\",\n",
    "    f\"{adjusted_f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682be1a4-7bf8-4e44-9da2-2b7f48eac91c",
   "metadata": {},
   "source": [
    "#### Save CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "939272d5-856b-49da-99a2-4a25d818d2ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:08:29.472394Z",
     "iopub.status.busy": "2024-09-25T08:08:29.471856Z",
     "iopub.status.idle": "2024-09-25T08:08:29.523076Z",
     "shell.execute_reply": "2024-09-25T08:08:29.522731Z",
     "shell.execute_reply.started": "2024-09-25T08:08:29.472354Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-3398afd7a3a1457685a8d05072cf19d5.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-3398afd7a3a1457685a8d05072cf19d5.vega-embed details,\n",
       "  #altair-viz-3398afd7a3a1457685a8d05072cf19d5.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-3398afd7a3a1457685a8d05072cf19d5\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-3398afd7a3a1457685a8d05072cf19d5\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-3398afd7a3a1457685a8d05072cf19d5\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"rect\"}, \"encoding\": {\"color\": {\"field\": \"Count\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"True\", \"type\": \"ordinal\"}, {\"field\": \"Predicted\", \"type\": \"ordinal\"}, {\"field\": \"Count\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Predicted\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}, \"y\": {\"field\": \"True\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}}, \"title\": \"OF_Using_FIRE 5STK-1 SVM\"}, {\"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"middle\", \"fontSize\": 12}, \"encoding\": {\"color\": {\"condition\": {\"test\": \"(datum.Count > 150.5)\", \"value\": \"white\"}, \"value\": \"black\"}, \"text\": {\"field\": \"Count\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"True\", \"type\": \"ordinal\"}, {\"field\": \"Predicted\", \"type\": \"ordinal\"}, {\"field\": \"Count\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Predicted\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}, \"y\": {\"field\": \"True\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}}, \"title\": \"OF_Using_FIRE 5STK-1 SVM\"}], \"data\": {\"name\": \"data-f9804bc01cc0c5dc31c8818df4de814c\"}, \"height\": 300, \"width\": 400, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-f9804bc01cc0c5dc31c8818df4de814c\": [{\"True\": \"Negative\", \"Predicted\": \"Negative\", \"Count\": 256}, {\"True\": \"Neutral\", \"Predicted\": \"Negative\", \"Count\": 48}, {\"True\": \"Positive\", \"Predicted\": \"Negative\", \"Count\": 2}, {\"True\": \"Negative\", \"Predicted\": \"Neutral\", \"Count\": 77}, {\"True\": \"Neutral\", \"Predicted\": \"Neutral\", \"Count\": 267}, {\"True\": \"Positive\", \"Predicted\": \"Neutral\", \"Count\": 41}, {\"True\": \"Negative\", \"Predicted\": \"Positive\", \"Count\": 8}, {\"True\": \"Neutral\", \"Predicted\": \"Positive\", \"Count\": 49}, {\"True\": \"Positive\", \"Predicted\": \"Positive\", \"Count\": 301}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import altair as alt\n",
    "import altair_saver\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_val, svm_validation_predictions)\n",
    "\n",
    "# Define class names\n",
    "class_names = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "# Convert confusion matrix to DataFrame\n",
    "cm_df = pd.DataFrame(cm, index=class_names, columns=class_names).reset_index().melt(id_vars='index')\n",
    "cm_df.columns = ['True', 'Predicted', 'Count']\n",
    "\n",
    "# Ensure the order of categories\n",
    "cm_df['True'] = pd.Categorical(cm_df['True'], categories=class_names, ordered=True)\n",
    "cm_df['Predicted'] = pd.Categorical(cm_df['Predicted'], categories=class_names, ordered=True)\n",
    "\n",
    "# Create the Altair plot\n",
    "heatmap = alt.Chart(cm_df).mark_rect().encode(\n",
    "    x=alt.X('Predicted:O', sort=class_names),\n",
    "    y=alt.Y('True:O', sort=class_names),\n",
    "    color='Count:Q',\n",
    "    tooltip=['True', 'Predicted', 'Count']\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=300,\n",
    "    title='OF_Using_FIRE 5STK-1 SVM'\n",
    ")\n",
    "\n",
    "# Add text labels\n",
    "text = heatmap.mark_text(\n",
    "    align='center',\n",
    "    baseline='middle',\n",
    "    fontSize=12\n",
    ").encode(\n",
    "    text='Count:Q',\n",
    "    color=alt.condition(\n",
    "        alt.datum.Count > cm.max() / 2,\n",
    "        alt.value('white'),\n",
    "        alt.value('black')\n",
    "    )\n",
    ")\n",
    "\n",
    "# Combine heatmap and text\n",
    "final_chart = heatmap + text\n",
    "\n",
    "# Display the plot\n",
    "final_chart.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4ab1dbec-94d8-4f9c-b5e8-843b853a71cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:08:29.523673Z",
     "iopub.status.busy": "2024-09-25T08:08:29.523584Z",
     "iopub.status.idle": "2024-09-25T08:08:29.569674Z",
     "shell.execute_reply": "2024-09-25T08:08:29.569371Z",
     "shell.execute_reply.started": "2024-09-25T08:08:29.523664Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to Results/Ensemble Model Results/On FireCS dataset/OF Using FIRE ENSEMBLE/Stacking/OF_Using_FIRE 5STK-1 SVM.png\n"
     ]
    }
   ],
   "source": [
    "# Specify the folder path\n",
    "folder_path = os.path.expanduser('Results/Ensemble Model Results/On FireCS dataset/OF Using FIRE ENSEMBLE/Stacking/')\n",
    "\n",
    "# Save the plot using vl-convert\n",
    "file_path_png = os.path.join(folder_path, 'OF_Using_FIRE 5STK-1 SVM.png')\n",
    "final_chart.save(file_path_png)\n",
    "\n",
    "print(f\"Plot saved to {file_path_png}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a298f212-36ec-4e75-ad74-d7b272d094a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80391c9f-64d7-4e98-b9f0-6ee41cb035f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
