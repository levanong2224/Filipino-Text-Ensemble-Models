{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dc06b17-fcee-4505-bd74-d98376ce3ed9",
   "metadata": {},
   "source": [
    "# Train Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45d553e9-1bf6-4f1e-be88-d6e10a44849e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:12:06.198238Z",
     "iopub.status.busy": "2024-09-25T08:12:06.198175Z",
     "iopub.status.idle": "2024-09-25T08:12:06.722747Z",
     "shell.execute_reply": "2024-09-25T08:12:06.722398Z",
     "shell.execute_reply.started": "2024-09-25T08:12:06.198231Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.backends.mps.is_available():\n",
    "        # Currently, there's no separate manual seed function for MPS like torch.cuda.manual_seed_all()\n",
    "        pass \n",
    "    else:\n",
    "        print(\"MPS device not available. Using CPU.\")\n",
    "        \n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c6a724-b17e-46f6-aee6-90ef2f7877a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T15:08:53.465538Z",
     "iopub.status.busy": "2024-08-13T15:08:53.465321Z",
     "iopub.status.idle": "2024-08-13T15:08:53.469076Z",
     "shell.execute_reply": "2024-08-13T15:08:53.468592Z",
     "shell.execute_reply.started": "2024-08-13T15:08:53.465526Z"
    }
   },
   "source": [
    "Best F1 score BERT model on HS_C dataset are used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3823c3e6-976a-4eb9-a651-2cfeaa1a3cc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:12:06.723290Z",
     "iopub.status.busy": "2024-09-25T08:12:06.723189Z",
     "iopub.status.idle": "2024-09-25T08:12:06.848232Z",
     "shell.execute_reply": "2024-09-25T08:12:06.847812Z",
     "shell.execute_reply.started": "2024-09-25T08:12:06.723283Z"
    }
   },
   "outputs": [],
   "source": [
    "# This automates data tabulation onto google sheets \n",
    "\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "import os\n",
    "\n",
    "# new directory path\n",
    "new_directory = '/Users/levan/ATENEO MASTERAL/Thesis'\n",
    "\n",
    "# Change the current working directory\n",
    "os.chdir(new_directory)\n",
    "\n",
    "# Use creds to create a client to interact with the Google Drive API\n",
    "scope = ['https://spreadsheets.google.com/feeds','https://www.googleapis.com/auth/drive']\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_name('thesis-432315-12daec8d1ff6.json', scope)\n",
    "\n",
    "service = build('sheets', 'v4', credentials=creds)\n",
    "\n",
    "client = gspread.authorize(creds)\n",
    "\n",
    "spreadsheet_id = '13Fk5oXX9B_mdHmNpMKQMy29y9iiHWrgQCa4hUTiQKD0' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d70bdb-0504-41ef-913d-e4b7f778f561",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7b193db-3f30-4e5f-a38b-c254bf1e1976",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:12:06.848739Z",
     "iopub.status.busy": "2024-09-25T08:12:06.848648Z",
     "iopub.status.idle": "2024-09-25T08:12:08.026287Z",
     "shell.execute_reply": "2024-09-25T08:12:08.025974Z",
     "shell.execute_reply.started": "2024-09-25T08:12:06.848731Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AutoConfig\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_recall_curve, f1_score, confusion_matrix, precision_score, recall_score, accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "# new directory path\n",
    "new_directory = '/Users/levan/ATENEO MASTERAL/Thesis/Development'\n",
    "\n",
    "# Change the current working directory\n",
    "os.chdir(new_directory)\n",
    "\n",
    "#Load Data\n",
    "df = pd.read_csv('Corpus/FiReCS/FiReCS_data_b.csv')\n",
    "X = df['review'].values\n",
    "y = df['label'].values\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a307e67b-00c3-47aa-8f83-34bc62c93f83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-11T10:08:58.783500Z",
     "iopub.status.busy": "2024-04-11T10:08:58.782872Z",
     "iopub.status.idle": "2024-04-11T10:08:58.788089Z",
     "shell.execute_reply": "2024-04-11T10:08:58.787147Z",
     "shell.execute_reply.started": "2024-04-11T10:08:58.783465Z"
    }
   },
   "source": [
    "## Load Models and Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e666f7e-9db0-4666-a112-2af127307162",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:12:08.026840Z",
     "iopub.status.busy": "2024-09-25T08:12:08.026762Z",
     "iopub.status.idle": "2024-09-25T08:12:12.419722Z",
     "shell.execute_reply": "2024-09-25T08:12:12.419345Z",
     "shell.execute_reply.started": "2024-09-25T08:12:08.026833Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_model_and_tokenizer(model_path, tokenizer_path, base_model):\n",
    "    # Load the tokenizer from the local directory\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "    \n",
    "    # Load the configuration from the base model, then update configuration if needed\n",
    "    config = AutoConfig.from_pretrained(base_model, num_labels=3)\n",
    "\n",
    "    # Initialize the model with the configuration\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_path, config=config)\n",
    "\n",
    "    # Ensure the model is in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    return model, tokenizer\n",
    "\n",
    "model_info = {\n",
    "    \n",
    "    'DistilBERT cased': {\n",
    "        'model_path': 'BERT models/1 FiReCS/fire_distilbert-base-cased-finetuned',\n",
    "        'tokenizer_path': 'BERT models/1 FiReCS/fire_distilbert-base-cased-finetuned',\n",
    "        'base_model': 'distilbert/distilbert-base-cased'\n",
    "    },\n",
    "\n",
    "    'DeBERTa': {\n",
    "        'model_path': 'BERT models/1 FiReCS/fire_DeBERTa-finetuned',\n",
    "        'tokenizer_path': 'BERT models/1 FiReCS/fire_DeBERTa-finetuned',\n",
    "        'base_model': 'microsoft/deberta-v3-base'\n",
    "    },\n",
    "\n",
    "    'HateBERT': {\n",
    "        'model_path': 'BERT models/1 FiReCS/fire_HateBERT-finetuned',\n",
    "        'tokenizer_path': 'BERT models/1 FiReCS/fire_HateBERT-finetuned',\n",
    "        'base_model': 'GroNLP/hateBERT'\n",
    "    },\n",
    "\n",
    "    'BERT cased': {\n",
    "        'model_path': 'BERT models/1 FiReCS/fire_bert-base-cased-finetuned',\n",
    "        'tokenizer_path': 'BERT models/1 FiReCS/fire_bert-base-cased-finetuned',\n",
    "        'base_model': 'google-bert/bert-base-cased'\n",
    "    },\n",
    "\n",
    "    'Roberta Tag cased': {\n",
    "        'model_path': 'BERT models/1 FiReCS/fire_Tag-Roberta-finetuned',\n",
    "        'tokenizer_path': 'BERT models/1 FiReCS/fire_Tag-Roberta-finetuned',\n",
    "        'base_model': 'jcblaise/roberta-tagalog-base'\n",
    "    },\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "models_and_tokenizers = {name: load_model_and_tokenizer(info['model_path'], \n",
    "                                                        info['tokenizer_path'], \n",
    "                                                        info['base_model']) \n",
    "                         for name, info in model_info.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a9b906-a837-4de8-b8a2-05aa44074c5c",
   "metadata": {},
   "source": [
    "## Apply Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05f7b2f9-3bc4-4d6d-8595-8971899238c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:12:12.420293Z",
     "iopub.status.busy": "2024-09-25T08:12:12.420222Z",
     "iopub.status.idle": "2024-09-25T08:12:12.423067Z",
     "shell.execute_reply": "2024-09-25T08:12:12.422829Z",
     "shell.execute_reply.started": "2024-09-25T08:12:12.420286Z"
    }
   },
   "outputs": [],
   "source": [
    "class MultiModelTextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, labels, models_and_tokenizers, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.models_and_tokenizers = models_and_tokenizers\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.texts[index])\n",
    "        label = self.labels[index]\n",
    "\n",
    "        model_inputs = {}\n",
    "        for name, (model, tokenizer) in self.models_and_tokenizers.items():\n",
    "            encoding = tokenizer.encode_plus(\n",
    "                text,\n",
    "                add_special_tokens=True,\n",
    "                max_length=self.max_len,\n",
    "                return_token_type_ids=False,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                return_attention_mask=True,\n",
    "                return_tensors='pt',\n",
    "            )\n",
    "            model_inputs[name] = {\n",
    "                'input_ids': encoding['input_ids'].squeeze(0),  # Remove batch dimension\n",
    "                'attention_mask': encoding['attention_mask'].squeeze(0)  # Remove batch dimension\n",
    "            }\n",
    "        return {'model_inputs': model_inputs, 'label': torch.tensor(label, dtype=torch.long)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d574483-f790-48ba-a7d0-07cc8f2973d4",
   "metadata": {},
   "source": [
    "## BERT Training for Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e6167c5-79fd-4536-815c-237ec599453a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:12:12.424552Z",
     "iopub.status.busy": "2024-09-25T08:12:12.424481Z",
     "iopub.status.idle": "2024-09-25T08:12:12.549918Z",
     "shell.execute_reply": "2024-09-25T08:12:12.549614Z",
     "shell.execute_reply.started": "2024-09-25T08:12:12.424546Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_base_learner(model, data_loader, optimizer, device):\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    correct_predictions = 0\n",
    "    losses = []\n",
    "\n",
    "    for batch in data_loader:\n",
    "        # Accessing inputs for the current model\n",
    "        inputs = batch['model_inputs']\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        for model_name, model_inputs in inputs.items():\n",
    "            # Forward pass\n",
    "            outputs = model(input_ids=model_inputs['input_ids'].squeeze(1).to(device),\n",
    "                attention_mask=model_inputs['attention_mask'].squeeze(1).to(device),\n",
    "                labels=labels)\n",
    "\n",
    "            loss = outputs.loss\n",
    "            preds = outputs.logits.argmax(dim=1)\n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    return correct_predictions.float() / len(data_loader.dataset), np.mean(losses).astype(np.float32)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def eval_model(model, data_loader, device):\n",
    "    model = model.eval()\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for d in data_loader:\n",
    "            input_ids = d[\"input_ids\"].to(device)\n",
    "            attention_mask = d[\"attention_mask\"].to(device)\n",
    "            labels = d[\"label\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            preds = outputs.logits.argmax(dim=1)\n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "\n",
    "    return correct_predictions.double() / len(data_loader.dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b36fee-48a1-4eda-bf0b-c59982cbba14",
   "metadata": {},
   "source": [
    "## Train Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99eb6be0-fb6e-441b-bfaa-853e75a01983",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:12:12.550473Z",
     "iopub.status.busy": "2024-09-25T08:12:12.550393Z",
     "iopub.status.idle": "2024-09-25T08:12:12.558912Z",
     "shell.execute_reply": "2024-09-25T08:12:12.558648Z",
     "shell.execute_reply.started": "2024-09-25T08:12:12.550465Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, confusion_matrix\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "\n",
    "def train_stacking_classifier(models_and_tokenizers, X_train, y_train, device, max_len=128):\n",
    "    n_splits = 4\n",
    "    skf = StratifiedKFold(n_splits=n_splits)\n",
    "    base_learners_predictions_train = np.zeros((len(X_train), len(models_and_tokenizers)))\n",
    "    fold_idx = 0\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_train, y_train):\n",
    "        fold_idx += 1\n",
    "        print(f\"Training fold {fold_idx}/{n_splits}...\")\n",
    "        train_texts, val_texts = X_train[train_idx], X_train[val_idx]\n",
    "        train_labels, val_labels = y_train[train_idx], y_train[val_idx]\n",
    "        \n",
    "        model_idx = 0\n",
    "        for name, info in model_info.items():\n",
    "            # Reload the model and tokenizer to reset weights\n",
    "            model, tokenizer = load_model_and_tokenizer(info['model_path'], info['tokenizer_path'], info['base_model'])\n",
    "            model.to(device)\n",
    "            \n",
    "            train_dataset = MultiModelTextDataset(train_texts, train_labels, {name: (model, tokenizer)}, max_len)\n",
    "            val_dataset = MultiModelTextDataset(val_texts, val_labels, {name: (model, tokenizer)}, max_len)\n",
    "            train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "            \n",
    "            optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "            train_base_learner(model, train_loader, optimizer, device)\n",
    "            \n",
    "            val_preds = []\n",
    "            model.eval()\n",
    "            for batch in val_loader:\n",
    "                inputs = batch['model_inputs'][name]\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(input_ids=inputs['input_ids'].to(device), attention_mask=inputs['attention_mask'].to(device))\n",
    "                val_preds.extend(outputs.logits.argmax(dim=1).cpu().numpy())\n",
    "            \n",
    "            base_learners_predictions_train[val_idx, model_idx] = np.array(val_preds)\n",
    "            model_idx += 1\n",
    "\n",
    "    return base_learners_predictions_train, y_train\n",
    "    \n",
    "\n",
    "def get_predictions(model_info, X, y, device, max_len=128):\n",
    "    predictions = np.zeros((len(X), len(model_info)))\n",
    "    model_idx = 0\n",
    "    for name, info in model_info.items():\n",
    "        # Reload the model and tokenizer\n",
    "        model, tokenizer = load_model_and_tokenizer(info['model_path'], info['tokenizer_path'], info['base_model'])\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        \n",
    "        dataset = MultiModelTextDataset(X, y, {name: (model, tokenizer)}, max_len)\n",
    "        loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
    "        \n",
    "        preds = []\n",
    "        for batch in loader:\n",
    "            inputs = batch['model_inputs'][name]\n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_ids=inputs['input_ids'].to(device), attention_mask=inputs['attention_mask'].to(device))\n",
    "            preds.extend(outputs.logits.argmax(dim=1).cpu().numpy())\n",
    "        \n",
    "        predictions[:, model_idx] = np.array(preds)\n",
    "        model_idx += 1\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58472c03-8cb9-4a28-b8f3-fd5227c0e620",
   "metadata": {},
   "source": [
    "## Perform Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da0e67bd-3f57-4bf1-aa4e-1537a9132002",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:12:12.559521Z",
     "iopub.status.busy": "2024-09-25T08:12:12.559379Z",
     "iopub.status.idle": "2024-09-25T08:12:12.562575Z",
     "shell.execute_reply": "2024-09-25T08:12:12.562346Z",
     "shell.execute_reply.started": "2024-09-25T08:12:12.559514Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36436c2d-846d-46ab-ae3c-b36c5bdda6a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:12:12.563103Z",
     "iopub.status.busy": "2024-09-25T08:12:12.563005Z",
     "iopub.status.idle": "2024-09-25T08:27:03.375073Z",
     "shell.execute_reply": "2024-09-25T08:27:03.374771Z",
     "shell.execute_reply.started": "2024-09-25T08:12:12.563096Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/transformers/optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 2/4...\n",
      "Training fold 3/4...\n",
      "Training fold 4/4...\n",
      "peak memory: 4230.38 MiB, increment: 2666.41 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# Train stacking classifier (using 4-fold cross validation for each BERT model) on Train Set and retrieve training meta-features\n",
    "train_meta_features, _ = train_stacking_classifier(model_info, X_train, y_train, device)\n",
    "\n",
    "# Generate predictions for the test set to be used as test meta-features\n",
    "test_meta_features = get_predictions(model_info, X_test, y_test, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d42e0b-1855-4774-8f83-599a6158e526",
   "metadata": {},
   "source": [
    "### Train LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "265a5311-c2a4-48a0-9f21-d803350fb89f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:27:03.375653Z",
     "iopub.status.busy": "2024-09-25T08:27:03.375565Z",
     "iopub.status.idle": "2024-09-25T08:27:04.269128Z",
     "shell.execute_reply": "2024-09-25T08:27:04.268817Z",
     "shell.execute_reply.started": "2024-09-25T08:27:03.375645Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1648.47 MiB, increment: 1.17 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "\n",
    "lr_meta_classifier = LogisticRegression()\n",
    "lr_meta_classifier.fit(train_meta_features, y_train)\n",
    "\n",
    "lr_final_predictions = lr_meta_classifier.predict(test_meta_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ea06bb-fab4-4f49-99e4-19680ec1b870",
   "metadata": {},
   "source": [
    "### Train NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "244b0f68-e401-4d18-913f-a3a153dd8104",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:27:04.269870Z",
     "iopub.status.busy": "2024-09-25T08:27:04.269773Z",
     "iopub.status.idle": "2024-09-25T08:27:05.529211Z",
     "shell.execute_reply": "2024-09-25T08:27:05.528885Z",
     "shell.execute_reply.started": "2024-09-25T08:27:04.269861Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1647.66 MiB, increment: -0.86 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "\n",
    "nb_meta_classifier = GaussianNB()\n",
    "nb_meta_classifier.fit(train_meta_features, y_train)\n",
    "\n",
    "nb_final_predictions = nb_meta_classifier.predict(test_meta_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e50604f-9bef-4db4-bf92-89f9d2874e89",
   "metadata": {},
   "source": [
    "### Train DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3990ca03-b860-4b65-97e7-47f551754ab7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:27:05.529969Z",
     "iopub.status.busy": "2024-09-25T08:27:05.529870Z",
     "iopub.status.idle": "2024-09-25T08:27:06.583812Z",
     "shell.execute_reply": "2024-09-25T08:27:06.583457Z",
     "shell.execute_reply.started": "2024-09-25T08:27:05.529959Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1648.00 MiB, increment: 0.33 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "\n",
    "dt_meta_classifier = DecisionTreeClassifier(max_depth=None)\n",
    "dt_meta_classifier.fit(train_meta_features, y_train)\n",
    "\n",
    "dt_final_predictions = dt_meta_classifier.predict(test_meta_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986bd8f0-b569-4eaf-8e13-a51529e871e6",
   "metadata": {},
   "source": [
    "### Train SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "460a4087-b343-4249-b794-db90baabf11c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:27:06.584442Z",
     "iopub.status.busy": "2024-09-25T08:27:06.584354Z",
     "iopub.status.idle": "2024-09-25T08:27:07.482105Z",
     "shell.execute_reply": "2024-09-25T08:27:07.481781Z",
     "shell.execute_reply.started": "2024-09-25T08:27:06.584433Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1665.45 MiB, increment: 17.41 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "\n",
    "svm_meta_classifier = SVC(kernel='linear', probability=True)\n",
    "svm_meta_classifier.fit(train_meta_features, y_train)\n",
    "\n",
    "svm_final_predictions = svm_meta_classifier.predict(test_meta_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad340b68-d07e-473a-bbc4-138ef8e0271a",
   "metadata": {},
   "source": [
    "## EVALUATE MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93ba0c5-a053-45fb-8e97-b09c67959bc8",
   "metadata": {},
   "source": [
    "### LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d015915-5eb9-4a73-9ef6-5fc1bd4d0e8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:27:07.482704Z",
     "iopub.status.busy": "2024-09-25T08:27:07.482623Z",
     "iopub.status.idle": "2024-09-25T08:27:07.488228Z",
     "shell.execute_reply": "2024-09-25T08:27:07.487980Z",
     "shell.execute_reply.started": "2024-09-25T08:27:07.482696Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Precision: 0.8271115793590674\n",
      "Recall: 0.8172563680930268\n",
      "Ensemble accuracy: 0.817090395480226\n",
      "F1 Score: 0.8205069176547813\n",
      "Confusion Matrix:\n",
      "[[367  93   0]\n",
      " [ 57 395  39]\n",
      " [  3  67 395]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "precision = precision_score(y_test, lr_final_predictions, average='macro')\n",
    "recall = recall_score(y_test, lr_final_predictions, average='macro')\n",
    "accuracy = accuracy_score(y_test, lr_final_predictions)\n",
    "f1 = f1_score(y_test, lr_final_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_test, lr_final_predictions)\n",
    "\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Ensemble accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8c650bc-c7b7-4f3d-b8c7-c415ed29f2f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:27:07.488849Z",
     "iopub.status.busy": "2024-09-25T08:27:07.488721Z",
     "iopub.status.idle": "2024-09-25T08:27:07.499652Z",
     "shell.execute_reply": "2024-09-25T08:27:07.499415Z",
     "shell.execute_reply.started": "2024-09-25T08:27:07.488840Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized thresholds for each class: [0.28579904979740306, 0.3677756267213559, 0.3394659127981]\n",
      "Logistic Regression\n",
      "Precision: 0.8271\n",
      "Recall: 0.8173\n",
      "Ensemble accuracy: 0.8171\n",
      "F1 Score: 0.8205069176547813\n",
      "Confusion Matrix:\n",
      "[[367  93   0]\n",
      " [ 57 395  39]\n",
      " [  3  67 395]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d8/nbkwtx_953q99tk0ckh0v0v40000gn/T/ipykernel_1899/181558703.py:7: RuntimeWarning: invalid value encountered in divide\n",
      "  f1_scores = 2 * (precision * recall) / (precision + recall)\n"
     ]
    }
   ],
   "source": [
    "probabilities = lr_meta_classifier.predict_proba(test_meta_features)\n",
    "\n",
    "# Calculate precision-recall curve and find optimal thresholds for each class\n",
    "lr_thresh = []\n",
    "for i in range(probabilities.shape[1]):  # Iterate over each class\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test == i, probabilities[:, i])\n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "    optimal_idx = np.nanargmax(f1_scores)  # Handle cases where precision and recall are both zero\n",
    "    lr_thresh.append(thresholds[optimal_idx])\n",
    "\n",
    "# Apply the optimized thresholds to make adjusted predictions\n",
    "adjusted_predictions = np.array([np.argmax([probabilities[i, j] if probabilities[i, j] >= lr_thresh[j] else 0\n",
    "                                         for j in range(probabilities.shape[1])])\n",
    "                              for i in range(len(probabilities))])\n",
    "\n",
    "# Evaluate\n",
    "adjusted_precision = precision_score(y_test, adjusted_predictions, average='macro')\n",
    "adjusted_recall = recall_score(y_test, adjusted_predictions, average='macro')\n",
    "adjusted_accuracy = accuracy_score(y_test, adjusted_predictions)\n",
    "adjusted_f1 = f1_score(y_test, adjusted_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_test, adjusted_predictions)\n",
    "\n",
    "print(\"Optimized thresholds for each class:\", lr_thresh)\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Precision: {adjusted_precision:.4f}\")\n",
    "print(f\"Recall: {adjusted_recall:.4f}\")\n",
    "print(f\"Ensemble accuracy: {adjusted_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {adjusted_f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfc6b32b-5f2a-4017-8a2b-e393ee1f85b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:27:07.500166Z",
     "iopub.status.busy": "2024-09-25T08:27:07.500090Z",
     "iopub.status.idle": "2024-09-25T08:27:08.608626Z",
     "shell.execute_reply": "2024-09-25T08:27:08.607614Z",
     "shell.execute_reply.started": "2024-09-25T08:27:07.500158Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated cells count: 4\n"
     ]
    }
   ],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '5-2!B4:E4'  \n",
    "\n",
    "values = [[\n",
    "    f\"{adjusted_precision * 100:.2f}\",\n",
    "    f\"{adjusted_recall * 100:.2f}\",\n",
    "    f\"{adjusted_accuracy * 100:.2f}\",\n",
    "    f\"{adjusted_f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f311d02-936c-467e-ae14-e0c9cd0f0211",
   "metadata": {},
   "source": [
    "### NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3cde7aba-1d7b-4fbd-94f0-98b9e5b2756a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:27:08.610508Z",
     "iopub.status.busy": "2024-09-25T08:27:08.610087Z",
     "iopub.status.idle": "2024-09-25T08:27:08.627090Z",
     "shell.execute_reply": "2024-09-25T08:27:08.626472Z",
     "shell.execute_reply.started": "2024-09-25T08:27:08.610476Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes\n",
      "Precision: 0.828311335126109\n",
      "Recall: 0.8179508383250068\n",
      "Ensemble accuracy: 0.8177966101694916\n",
      "F1 Score: 0.8213461382593062\n",
      "Confusion Matrix:\n",
      "[[369  91   0]\n",
      " [ 57 396  38]\n",
      " [  2  70 393]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "precision = precision_score(y_test, nb_final_predictions, average='macro')\n",
    "recall = recall_score(y_test, nb_final_predictions, average='macro')\n",
    "accuracy = accuracy_score(y_test, nb_final_predictions)\n",
    "f1 = f1_score(y_test, nb_final_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_test, nb_final_predictions)\n",
    "\n",
    "print(\"Naive Bayes\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Ensemble accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07991bda-71ea-4786-996b-61a3ae0132ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:27:08.628811Z",
     "iopub.status.busy": "2024-09-25T08:27:08.628454Z",
     "iopub.status.idle": "2024-09-25T08:27:08.650856Z",
     "shell.execute_reply": "2024-09-25T08:27:08.650301Z",
     "shell.execute_reply.started": "2024-09-25T08:27:08.628791Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized thresholds for each class: [0.14637159067115513, 0.02341814035151381, 0.009616430879749402]\n",
      "Naive Bayes\n",
      "Precision: 0.8283\n",
      "Recall: 0.8180\n",
      "Ensemble accuracy: 0.8178\n",
      "F1 Score: 0.8213461382593062\n",
      "Confusion Matrix:\n",
      "[[369  91   0]\n",
      " [ 57 396  38]\n",
      " [  2  70 393]]\n"
     ]
    }
   ],
   "source": [
    "probabilities = nb_meta_classifier.predict_proba(test_meta_features)\n",
    "\n",
    "# Calculate precision-recall curve and find optimal thresholds for each class\n",
    "nb_thresh = []\n",
    "for i in range(probabilities.shape[1]):  # Iterate over each class\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test == i, probabilities[:, i])\n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "    optimal_idx = np.nanargmax(f1_scores)  # Handle cases where precision and recall are both zero\n",
    "    nb_thresh.append(thresholds[optimal_idx])\n",
    "\n",
    "# Apply the optimized thresholds to make adjusted predictions\n",
    "adjusted_predictions = np.array([np.argmax([probabilities[i, j] if probabilities[i, j] >= nb_thresh[j] else 0\n",
    "                                         for j in range(probabilities.shape[1])])\n",
    "                              for i in range(len(probabilities))])\n",
    "\n",
    "# Evaluate\n",
    "adjusted_precision = precision_score(y_test, adjusted_predictions, average='macro')\n",
    "adjusted_recall = recall_score(y_test, adjusted_predictions, average='macro')\n",
    "adjusted_accuracy = accuracy_score(y_test, adjusted_predictions)\n",
    "adjusted_f1 = f1_score(y_test, adjusted_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_test, adjusted_predictions)\n",
    "\n",
    "print(\"Optimized thresholds for each class:\", nb_thresh)\n",
    "print(\"Naive Bayes\")\n",
    "print(f\"Precision: {adjusted_precision:.4f}\")\n",
    "print(f\"Recall: {adjusted_recall:.4f}\")\n",
    "print(f\"Ensemble accuracy: {adjusted_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {adjusted_f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aecf64b8-5a1a-4cea-a077-2049e0459dd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:27:08.651970Z",
     "iopub.status.busy": "2024-09-25T08:27:08.651768Z",
     "iopub.status.idle": "2024-09-25T08:27:09.148837Z",
     "shell.execute_reply": "2024-09-25T08:27:09.147738Z",
     "shell.execute_reply.started": "2024-09-25T08:27:08.651951Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated cells count: 4\n"
     ]
    }
   ],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '5-2!B5:E5'  \n",
    "\n",
    "values = [[\n",
    "    f\"{adjusted_precision * 100:.2f}\",\n",
    "    f\"{adjusted_recall * 100:.2f}\",\n",
    "    f\"{adjusted_accuracy * 100:.2f}\",\n",
    "    f\"{adjusted_f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958d063b-7c6a-43d7-aaa2-0b93e3d56610",
   "metadata": {},
   "source": [
    "### DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c799950-2309-4a08-9778-351ab70a85db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:27:09.151201Z",
     "iopub.status.busy": "2024-09-25T08:27:09.150943Z",
     "iopub.status.idle": "2024-09-25T08:27:09.170559Z",
     "shell.execute_reply": "2024-09-25T08:27:09.169844Z",
     "shell.execute_reply.started": "2024-09-25T08:27:09.151179Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Precision: 0.8169772678589154\n",
      "Recall: 0.8083179639621969\n",
      "Ensemble accuracy: 0.807909604519774\n",
      "F1 Score: 0.811215552420388\n",
      "Confusion Matrix:\n",
      "[[372  84   4]\n",
      " [ 78 386  27]\n",
      " [  9  70 386]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "precision = precision_score(y_test, dt_final_predictions, average='macro')\n",
    "recall = recall_score(y_test, dt_final_predictions, average='macro')\n",
    "accuracy = accuracy_score(y_test, dt_final_predictions)\n",
    "f1 = f1_score(y_test, dt_final_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_test, dt_final_predictions)\n",
    "\n",
    "print(\"Decision Tree\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Ensemble accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a63b5fc-8c61-409f-86bf-470f00eb6d99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:27:09.178262Z",
     "iopub.status.busy": "2024-09-25T08:27:09.178032Z",
     "iopub.status.idle": "2024-09-25T08:27:09.192201Z",
     "shell.execute_reply": "2024-09-25T08:27:09.191623Z",
     "shell.execute_reply.started": "2024-09-25T08:27:09.178247Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized thresholds for each class: [0.3333333333333333, 0.3333333333333333, 0.5]\n",
      "Decision Tree\n",
      "Precision: 0.8170\n",
      "Recall: 0.8083\n",
      "Ensemble accuracy: 0.8079\n",
      "F1 Score: 0.811215552420388\n",
      "Confusion Matrix:\n",
      "[[372  84   4]\n",
      " [ 78 386  27]\n",
      " [  9  70 386]]\n"
     ]
    }
   ],
   "source": [
    "probabilities = dt_meta_classifier.predict_proba(test_meta_features)\n",
    "\n",
    "# Calculate precision-recall curve and find optimal thresholds for each class\n",
    "dt_thresh = []\n",
    "for i in range(probabilities.shape[1]):  # Iterate over each class\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test == i, probabilities[:, i])\n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "    optimal_idx = np.nanargmax(f1_scores)  # Handle cases where precision and recall are both zero\n",
    "    dt_thresh.append(thresholds[optimal_idx])\n",
    "\n",
    "# Apply the optimized thresholds to make adjusted predictions\n",
    "adjusted_predictions = np.array([np.argmax([probabilities[i, j] if probabilities[i, j] >= dt_thresh[j] else 0\n",
    "                                         for j in range(probabilities.shape[1])])\n",
    "                              for i in range(len(probabilities))])\n",
    "\n",
    "# Evaluate\n",
    "adjusted_precision = precision_score(y_test, adjusted_predictions, average='macro')\n",
    "adjusted_recall = recall_score(y_test, adjusted_predictions, average='macro')\n",
    "adjusted_accuracy = accuracy_score(y_test, adjusted_predictions)\n",
    "adjusted_f1 = f1_score(y_test, adjusted_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_test, adjusted_predictions)\n",
    "\n",
    "print(\"Optimized thresholds for each class:\", dt_thresh)\n",
    "print(\"Decision Tree\")\n",
    "print(f\"Precision: {adjusted_precision:.4f}\")\n",
    "print(f\"Recall: {adjusted_recall:.4f}\")\n",
    "print(f\"Ensemble accuracy: {adjusted_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {adjusted_f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9653e844-4196-4d63-9b61-4998f3dba2d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:27:09.193246Z",
     "iopub.status.busy": "2024-09-25T08:27:09.193032Z",
     "iopub.status.idle": "2024-09-25T08:27:09.642338Z",
     "shell.execute_reply": "2024-09-25T08:27:09.641449Z",
     "shell.execute_reply.started": "2024-09-25T08:27:09.193228Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated cells count: 4\n"
     ]
    }
   ],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '5-2!B6:E6'  \n",
    "\n",
    "values = [[\n",
    "    f\"{adjusted_precision * 100:.2f}\",\n",
    "    f\"{adjusted_recall * 100:.2f}\",\n",
    "    f\"{adjusted_accuracy * 100:.2f}\",\n",
    "    f\"{adjusted_f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24614471-4cf3-4349-b8bb-98715c2db8a9",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f5a4d67-5a7a-4f32-b9c4-6f5c7612a256",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:27:09.644099Z",
     "iopub.status.busy": "2024-09-25T08:27:09.643762Z",
     "iopub.status.idle": "2024-09-25T08:27:09.666713Z",
     "shell.execute_reply": "2024-09-25T08:27:09.665629Z",
     "shell.execute_reply.started": "2024-09-25T08:27:09.644038Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "Precision: 0.8271576527515689\n",
      "Recall: 0.8178807120977978\n",
      "Ensemble accuracy: 0.8177966101694916\n",
      "F1 Score: 0.8208550256126821\n",
      "Confusion Matrix:\n",
      "[[360  99   1]\n",
      " [ 57 396  38]\n",
      " [  4  59 402]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "precision = precision_score(y_test, svm_final_predictions, average='macro')\n",
    "recall = recall_score(y_test, svm_final_predictions, average='macro')\n",
    "accuracy = accuracy_score(y_test, svm_final_predictions)\n",
    "f1 = f1_score(y_test, svm_final_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_test, svm_final_predictions)\n",
    "\n",
    "print(\"SVM\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Ensemble accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f4bf24f-5e38-4acf-b0d1-c42ddb5a862f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:27:09.668007Z",
     "iopub.status.busy": "2024-09-25T08:27:09.667749Z",
     "iopub.status.idle": "2024-09-25T08:27:09.708338Z",
     "shell.execute_reply": "2024-09-25T08:27:09.707987Z",
     "shell.execute_reply.started": "2024-09-25T08:27:09.667983Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized thresholds for each class: [0.34212878796608037, 0.32218079817056494, 0.5466438991986236]\n",
      "SVM\n",
      "Precision: 0.8268\n",
      "Recall: 0.8195\n",
      "Ensemble accuracy: 0.8192\n",
      "F1 Score: 0.8218569128271175\n",
      "Confusion Matrix:\n",
      "[[360  99   1]\n",
      " [ 57 392  42]\n",
      " [  4  53 408]]\n"
     ]
    }
   ],
   "source": [
    "probabilities = svm_meta_classifier.predict_proba(test_meta_features)\n",
    "\n",
    "# Calculate precision-recall curve and find optimal thresholds for each class\n",
    "svm_thresh = []\n",
    "for i in range(probabilities.shape[1]):  # Iterate over each class\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test == i, probabilities[:, i])\n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "    optimal_idx = np.nanargmax(f1_scores)  # Handle cases where precision and recall are both zero\n",
    "    svm_thresh.append(thresholds[optimal_idx])\n",
    "\n",
    "# Apply the optimized thresholds to make adjusted predictions\n",
    "adjusted_predictions = np.array([np.argmax([probabilities[i, j] if probabilities[i, j] >= svm_thresh[j] else 0\n",
    "                                         for j in range(probabilities.shape[1])])\n",
    "                              for i in range(len(probabilities))])\n",
    "\n",
    "# Evaluate\n",
    "adjusted_precision = precision_score(y_test, adjusted_predictions, average='macro')\n",
    "adjusted_recall = recall_score(y_test, adjusted_predictions, average='macro')\n",
    "adjusted_accuracy = accuracy_score(y_test, adjusted_predictions)\n",
    "adjusted_f1 = f1_score(y_test, adjusted_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_test, adjusted_predictions)\n",
    "\n",
    "print(\"Optimized thresholds for each class:\", svm_thresh)\n",
    "print(\"SVM\")\n",
    "print(f\"Precision: {adjusted_precision:.4f}\")\n",
    "print(f\"Recall: {adjusted_recall:.4f}\")\n",
    "print(f\"Ensemble accuracy: {adjusted_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {adjusted_f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "92382252-0d77-45d8-bb20-8c5c7f2a983b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:27:09.708962Z",
     "iopub.status.busy": "2024-09-25T08:27:09.708880Z",
     "iopub.status.idle": "2024-09-25T08:27:10.155780Z",
     "shell.execute_reply": "2024-09-25T08:27:10.154544Z",
     "shell.execute_reply.started": "2024-09-25T08:27:09.708954Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated cells count: 4\n"
     ]
    }
   ],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '5-2!B7:E7'  \n",
    "\n",
    "values = [[\n",
    "    f\"{adjusted_precision * 100:.2f}\",\n",
    "    f\"{adjusted_recall * 100:.2f}\",\n",
    "    f\"{adjusted_accuracy * 100:.2f}\",\n",
    "    f\"{adjusted_f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0143f6-14c3-431a-b08b-7f182a0c7c96",
   "metadata": {},
   "source": [
    "## TEST DATA C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a7c1fca-bf56-43cf-8559-e8acfd5dc262",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:27:10.157735Z",
     "iopub.status.busy": "2024-09-25T08:27:10.157358Z",
     "iopub.status.idle": "2024-09-25T08:27:40.183392Z",
     "shell.execute_reply": "2024-09-25T08:27:40.183004Z",
     "shell.execute_reply.started": "2024-09-25T08:27:10.157638Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Load validation data\n",
    "validation_file_path = 'Corpus/FiReCS/FiReCS_data_c.csv'\n",
    "validation_df = pd.read_csv(validation_file_path)\n",
    "\n",
    "X_val = validation_df['review'].values \n",
    "y_val = validation_df['label'].values\n",
    "\n",
    "# Generate meta-features for data c dataset\n",
    "val_meta_features = get_predictions(model_info, X_val, y_val, device) \n",
    "\n",
    "# Predict using the logistic regression meta-classifier\n",
    "val_lr_predictions = lr_meta_classifier.predict(val_meta_features)\n",
    "\n",
    "# Predict using the naive bayes meta-classifier\n",
    "val_nb_predictions = nb_meta_classifier.predict(val_meta_features)\n",
    "\n",
    "# Predict using the decision tree meta-classifier\n",
    "val_dt_predictions = dt_meta_classifier.predict(val_meta_features)\n",
    "\n",
    "# Predict using the svm meta-classifier\n",
    "val_svm_predictions = svm_meta_classifier.predict(val_meta_features)\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0693ac-17b2-4645-be71-fe4c1f337e38",
   "metadata": {},
   "source": [
    "### LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5303f868-1507-4252-9f50-136aa337f630",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:27:40.183928Z",
     "iopub.status.busy": "2024-09-25T08:27:40.183835Z",
     "iopub.status.idle": "2024-09-25T08:27:40.188949Z",
     "shell.execute_reply": "2024-09-25T08:27:40.188718Z",
     "shell.execute_reply.started": "2024-09-25T08:27:40.183921Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on HS-Data C Dataset\n",
      "Precision: 0.8238784688735028\n",
      "Recall: 0.8132268144458692\n",
      "Accuracy: 0.8131553860819828\n",
      "F1 Score: 0.8165894921703359\n",
      "Confusion Matrix:\n",
      "[[267  74   0]\n",
      " [ 40 293  31]\n",
      " [  3  48 293]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the predictions\n",
    "precision = precision_score(y_val, val_lr_predictions, average='macro')\n",
    "recall = recall_score(y_val, val_lr_predictions, average='macro')\n",
    "accuracy = accuracy_score(y_val, val_lr_predictions)\n",
    "f1 = f1_score(y_val, val_lr_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_val, val_lr_predictions)\n",
    "\n",
    "print(\"Evaluation on HS-Data C Dataset\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d732e24d-540c-4934-a359-e7098db0eaaf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:27:40.189587Z",
     "iopub.status.busy": "2024-09-25T08:27:40.189394Z",
     "iopub.status.idle": "2024-09-25T08:27:40.197131Z",
     "shell.execute_reply": "2024-09-25T08:27:40.196900Z",
     "shell.execute_reply.started": "2024-09-25T08:27:40.189579Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results\n",
      "Precision: 0.8239\n",
      "Recall: 0.8132\n",
      "Accuracy: 0.8132\n",
      "F1 Score: 0.8166\n",
      "Confusion Matrix:\n",
      "[[267  74   0]\n",
      " [ 40 293  31]\n",
      " [  3  48 293]]\n"
     ]
    }
   ],
   "source": [
    "lr_validation_probabilities = lr_meta_classifier.predict_proba(val_meta_features)\n",
    "\n",
    "# Apply thresholds to the validation set probabilities to make final predictions\n",
    "lr_validation_predictions = np.array([np.argmax([lr_validation_probabilities[i, j] if lr_validation_probabilities[i, j] >= lr_thresh[j] else 0\n",
    "                                              for j in range(lr_validation_probabilities.shape[1])])\n",
    "                                   for i in range(len(lr_validation_probabilities))])\n",
    "\n",
    "# Evaluate threshold on validation set\n",
    "adjusted_precision = precision_score(y_val, lr_validation_predictions, average='macro')\n",
    "adjusted_recall = recall_score(y_val, lr_validation_predictions, average='macro')\n",
    "adjusted_accuracy = accuracy_score(y_val, lr_validation_predictions)\n",
    "adjusted_f1 = f1_score(y_val, lr_validation_predictions, average='macro')\n",
    "adjusted_conf_matrix = confusion_matrix(y_val, lr_validation_predictions)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Validation Results\")\n",
    "print(f\"Precision: {adjusted_precision:.4f}\")\n",
    "print(f\"Recall: {adjusted_recall:.4f}\")\n",
    "print(f\"Accuracy: {adjusted_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {adjusted_f1:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(adjusted_conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "35d847f4-0bc4-4f4f-a1ff-22d5d990820f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:27:40.197665Z",
     "iopub.status.busy": "2024-09-25T08:27:40.197529Z",
     "iopub.status.idle": "2024-09-25T08:27:40.754094Z",
     "shell.execute_reply": "2024-09-25T08:27:40.751806Z",
     "shell.execute_reply.started": "2024-09-25T08:27:40.197654Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated cells count: 4\n"
     ]
    }
   ],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '5-2!F4:I4'  \n",
    "\n",
    "values = [[\n",
    "    f\"{adjusted_precision * 100:.2f}\",\n",
    "    f\"{adjusted_recall * 100:.2f}\",\n",
    "    f\"{adjusted_accuracy * 100:.2f}\",\n",
    "    f\"{adjusted_f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d20e88-5a01-4b56-ad36-37c984d10277",
   "metadata": {},
   "source": [
    "#### Save CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ca78187-3e76-4798-b348-64b200b29eb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:27:40.755791Z",
     "iopub.status.busy": "2024-09-25T08:27:40.755469Z",
     "iopub.status.idle": "2024-09-25T08:27:40.991151Z",
     "shell.execute_reply": "2024-09-25T08:27:40.990913Z",
     "shell.execute_reply.started": "2024-09-25T08:27:40.755771Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-df95758a049541aa95e0677911f3e178.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-df95758a049541aa95e0677911f3e178.vega-embed details,\n",
       "  #altair-viz-df95758a049541aa95e0677911f3e178.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-df95758a049541aa95e0677911f3e178\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-df95758a049541aa95e0677911f3e178\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-df95758a049541aa95e0677911f3e178\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"rect\"}, \"encoding\": {\"color\": {\"field\": \"Count\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"True\", \"type\": \"ordinal\"}, {\"field\": \"Predicted\", \"type\": \"ordinal\"}, {\"field\": \"Count\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Predicted\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}, \"y\": {\"field\": \"True\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}}, \"title\": \"OF_Using_FIRE 5STK-2 LR\"}, {\"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"middle\", \"fontSize\": 12}, \"encoding\": {\"color\": {\"condition\": {\"test\": \"(datum.Count > 146.5)\", \"value\": \"white\"}, \"value\": \"black\"}, \"text\": {\"field\": \"Count\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"True\", \"type\": \"ordinal\"}, {\"field\": \"Predicted\", \"type\": \"ordinal\"}, {\"field\": \"Count\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Predicted\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}, \"y\": {\"field\": \"True\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}}, \"title\": \"OF_Using_FIRE 5STK-2 LR\"}], \"data\": {\"name\": \"data-e04e789db6380d26416623c9e6eaca6c\"}, \"height\": 300, \"width\": 400, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-e04e789db6380d26416623c9e6eaca6c\": [{\"True\": \"Negative\", \"Predicted\": \"Negative\", \"Count\": 267}, {\"True\": \"Neutral\", \"Predicted\": \"Negative\", \"Count\": 40}, {\"True\": \"Positive\", \"Predicted\": \"Negative\", \"Count\": 3}, {\"True\": \"Negative\", \"Predicted\": \"Neutral\", \"Count\": 74}, {\"True\": \"Neutral\", \"Predicted\": \"Neutral\", \"Count\": 293}, {\"True\": \"Positive\", \"Predicted\": \"Neutral\", \"Count\": 48}, {\"True\": \"Negative\", \"Predicted\": \"Positive\", \"Count\": 0}, {\"True\": \"Neutral\", \"Predicted\": \"Positive\", \"Count\": 31}, {\"True\": \"Positive\", \"Predicted\": \"Positive\", \"Count\": 293}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import altair as alt\n",
    "import altair_saver\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_val, lr_validation_predictions)\n",
    "\n",
    "# Define class names\n",
    "class_names = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "# Convert confusion matrix to DataFrame\n",
    "cm_df = pd.DataFrame(cm, index=class_names, columns=class_names).reset_index().melt(id_vars='index')\n",
    "cm_df.columns = ['True', 'Predicted', 'Count']\n",
    "\n",
    "# Ensure the order of categories\n",
    "cm_df['True'] = pd.Categorical(cm_df['True'], categories=class_names, ordered=True)\n",
    "cm_df['Predicted'] = pd.Categorical(cm_df['Predicted'], categories=class_names, ordered=True)\n",
    "\n",
    "# Create the Altair plot\n",
    "heatmap = alt.Chart(cm_df).mark_rect().encode(\n",
    "    x=alt.X('Predicted:O', sort=class_names),\n",
    "    y=alt.Y('True:O', sort=class_names),\n",
    "    color='Count:Q',\n",
    "    tooltip=['True', 'Predicted', 'Count']\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=300,\n",
    "    title='OF_Using_FIRE 5STK-2 LR'\n",
    ")\n",
    "\n",
    "# Add text labels\n",
    "text = heatmap.mark_text(\n",
    "    align='center',\n",
    "    baseline='middle',\n",
    "    fontSize=12\n",
    ").encode(\n",
    "    text='Count:Q',\n",
    "    color=alt.condition(\n",
    "        alt.datum.Count > cm.max() / 2,\n",
    "        alt.value('white'),\n",
    "        alt.value('black')\n",
    "    )\n",
    ")\n",
    "\n",
    "# Combine heatmap and text\n",
    "final_chart = heatmap + text\n",
    "\n",
    "# Display the plot\n",
    "final_chart.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4018e7ba-2de6-44d9-9a6f-bf13ccb33108",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:27:40.991760Z",
     "iopub.status.busy": "2024-09-25T08:27:40.991631Z",
     "iopub.status.idle": "2024-09-25T08:27:41.343186Z",
     "shell.execute_reply": "2024-09-25T08:27:41.342867Z",
     "shell.execute_reply.started": "2024-09-25T08:27:40.991752Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to Results/Ensemble Model Results/On FireCS dataset/OF Using FIRE ENSEMBLE/Stacking/OF_Using_FIRE 5STK-2 LR.png\n"
     ]
    }
   ],
   "source": [
    "# Specify the folder path\n",
    "folder_path = os.path.expanduser('Results/Ensemble Model Results/On FireCS dataset/OF Using FIRE ENSEMBLE/Stacking/')\n",
    "\n",
    "# Save the plot using vl-convert\n",
    "file_path_png = os.path.join(folder_path, 'OF_Using_FIRE 5STK-2 LR.png')\n",
    "final_chart.save(file_path_png)\n",
    "\n",
    "print(f\"Plot saved to {file_path_png}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e3bc0f-597f-47e3-ba99-5d9cafd1aea3",
   "metadata": {},
   "source": [
    "### NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0af5051f-834f-4646-afef-37bfdfdc43d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:27:41.343742Z",
     "iopub.status.busy": "2024-09-25T08:27:41.343656Z",
     "iopub.status.idle": "2024-09-25T08:27:41.349801Z",
     "shell.execute_reply": "2024-09-25T08:27:41.349513Z",
     "shell.execute_reply.started": "2024-09-25T08:27:41.343734Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on HS-Data C Dataset\n",
      "Precision: 0.8252644542738882\n",
      "Recall: 0.8141596150785948\n",
      "Accuracy: 0.8141086749285034\n",
      "F1 Score: 0.8177073945385049\n",
      "Confusion Matrix:\n",
      "[[269  72   0]\n",
      " [ 43 294  27]\n",
      " [  3  50 291]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the predictions\n",
    "precision = precision_score(y_val, val_nb_predictions, average='macro')\n",
    "recall = recall_score(y_val, val_nb_predictions, average='macro')\n",
    "accuracy = accuracy_score(y_val, val_nb_predictions)\n",
    "f1 = f1_score(y_val, val_nb_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_val, val_nb_predictions)\n",
    "\n",
    "print(\"Evaluation on HS-Data C Dataset\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d1acd42b-ca2c-40be-b90e-e7fb7f6eeb2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:27:41.350450Z",
     "iopub.status.busy": "2024-09-25T08:27:41.350365Z",
     "iopub.status.idle": "2024-09-25T08:27:41.358810Z",
     "shell.execute_reply": "2024-09-25T08:27:41.358525Z",
     "shell.execute_reply.started": "2024-09-25T08:27:41.350441Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results\n",
      "Precision: 0.8253\n",
      "Recall: 0.8142\n",
      "Accuracy: 0.8141\n",
      "F1 Score: 0.8177\n",
      "Confusion Matrix:\n",
      "[[269  72   0]\n",
      " [ 43 294  27]\n",
      " [  3  50 291]]\n"
     ]
    }
   ],
   "source": [
    "nb_validation_probabilities = nb_meta_classifier.predict_proba(val_meta_features)\n",
    "\n",
    "# Apply thresholds to the validation set probabilities to make final predictions\n",
    "nb_validation_predictions = np.array([np.argmax([nb_validation_probabilities[i, j] if nb_validation_probabilities[i, j] >= nb_thresh[j] else 0\n",
    "                                              for j in range(nb_validation_probabilities.shape[1])])\n",
    "                                   for i in range(len(nb_validation_probabilities))])\n",
    "\n",
    "# Evaluate threshold on validation set\n",
    "adjusted_precision = precision_score(y_val, nb_validation_predictions, average='macro')\n",
    "adjusted_recall = recall_score(y_val, nb_validation_predictions, average='macro')\n",
    "adjusted_accuracy = accuracy_score(y_val, nb_validation_predictions)\n",
    "adjusted_f1 = f1_score(y_val, nb_validation_predictions, average='macro')\n",
    "adjusted_conf_matrix = confusion_matrix(y_val, nb_validation_predictions)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Validation Results\")\n",
    "print(f\"Precision: {adjusted_precision:.4f}\")\n",
    "print(f\"Recall: {adjusted_recall:.4f}\")\n",
    "print(f\"Accuracy: {adjusted_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {adjusted_f1:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(adjusted_conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fe5b7918-e4a2-4fd5-bfc3-74bb308a085b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:27:41.359303Z",
     "iopub.status.busy": "2024-09-25T08:27:41.359237Z",
     "iopub.status.idle": "2024-09-25T08:27:41.797786Z",
     "shell.execute_reply": "2024-09-25T08:27:41.796611Z",
     "shell.execute_reply.started": "2024-09-25T08:27:41.359297Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated cells count: 4\n"
     ]
    }
   ],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '5-2!F5:I5'  \n",
    "\n",
    "values = [[\n",
    "    f\"{adjusted_precision * 100:.2f}\",\n",
    "    f\"{adjusted_recall * 100:.2f}\",\n",
    "    f\"{adjusted_accuracy * 100:.2f}\",\n",
    "    f\"{adjusted_f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65529983-86a3-4c32-b155-c08fcdf20b31",
   "metadata": {},
   "source": [
    "#### Save CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea993771-7e1b-4a65-8e32-29912f2564d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:27:41.799557Z",
     "iopub.status.busy": "2024-09-25T08:27:41.799267Z",
     "iopub.status.idle": "2024-09-25T08:27:41.853770Z",
     "shell.execute_reply": "2024-09-25T08:27:41.853365Z",
     "shell.execute_reply.started": "2024-09-25T08:27:41.799536Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-4895fe239961480aaee784bd06d820a3.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-4895fe239961480aaee784bd06d820a3.vega-embed details,\n",
       "  #altair-viz-4895fe239961480aaee784bd06d820a3.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-4895fe239961480aaee784bd06d820a3\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-4895fe239961480aaee784bd06d820a3\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-4895fe239961480aaee784bd06d820a3\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"rect\"}, \"encoding\": {\"color\": {\"field\": \"Count\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"True\", \"type\": \"ordinal\"}, {\"field\": \"Predicted\", \"type\": \"ordinal\"}, {\"field\": \"Count\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Predicted\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}, \"y\": {\"field\": \"True\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}}, \"title\": \"OF_Using_FIRE 5STK-2 NB\"}, {\"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"middle\", \"fontSize\": 12}, \"encoding\": {\"color\": {\"condition\": {\"test\": \"(datum.Count > 147.0)\", \"value\": \"white\"}, \"value\": \"black\"}, \"text\": {\"field\": \"Count\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"True\", \"type\": \"ordinal\"}, {\"field\": \"Predicted\", \"type\": \"ordinal\"}, {\"field\": \"Count\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Predicted\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}, \"y\": {\"field\": \"True\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}}, \"title\": \"OF_Using_FIRE 5STK-2 NB\"}], \"data\": {\"name\": \"data-caf99b5aa5932ac5af89834f6ca72095\"}, \"height\": 300, \"width\": 400, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-caf99b5aa5932ac5af89834f6ca72095\": [{\"True\": \"Negative\", \"Predicted\": \"Negative\", \"Count\": 269}, {\"True\": \"Neutral\", \"Predicted\": \"Negative\", \"Count\": 43}, {\"True\": \"Positive\", \"Predicted\": \"Negative\", \"Count\": 3}, {\"True\": \"Negative\", \"Predicted\": \"Neutral\", \"Count\": 72}, {\"True\": \"Neutral\", \"Predicted\": \"Neutral\", \"Count\": 294}, {\"True\": \"Positive\", \"Predicted\": \"Neutral\", \"Count\": 50}, {\"True\": \"Negative\", \"Predicted\": \"Positive\", \"Count\": 0}, {\"True\": \"Neutral\", \"Predicted\": \"Positive\", \"Count\": 27}, {\"True\": \"Positive\", \"Predicted\": \"Positive\", \"Count\": 291}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import altair as alt\n",
    "import altair_saver\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_val, nb_validation_predictions)\n",
    "\n",
    "# Define class names\n",
    "class_names = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "# Convert confusion matrix to DataFrame\n",
    "cm_df = pd.DataFrame(cm, index=class_names, columns=class_names).reset_index().melt(id_vars='index')\n",
    "cm_df.columns = ['True', 'Predicted', 'Count']\n",
    "\n",
    "# Ensure the order of categories\n",
    "cm_df['True'] = pd.Categorical(cm_df['True'], categories=class_names, ordered=True)\n",
    "cm_df['Predicted'] = pd.Categorical(cm_df['Predicted'], categories=class_names, ordered=True)\n",
    "\n",
    "# Create the Altair plot\n",
    "heatmap = alt.Chart(cm_df).mark_rect().encode(\n",
    "    x=alt.X('Predicted:O', sort=class_names),\n",
    "    y=alt.Y('True:O', sort=class_names),\n",
    "    color='Count:Q',\n",
    "    tooltip=['True', 'Predicted', 'Count']\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=300,\n",
    "    title='OF_Using_FIRE 5STK-2 NB'\n",
    ")\n",
    "\n",
    "# Add text labels\n",
    "text = heatmap.mark_text(\n",
    "    align='center',\n",
    "    baseline='middle',\n",
    "    fontSize=12\n",
    ").encode(\n",
    "    text='Count:Q',\n",
    "    color=alt.condition(\n",
    "        alt.datum.Count > cm.max() / 2,\n",
    "        alt.value('white'),\n",
    "        alt.value('black')\n",
    "    )\n",
    ")\n",
    "\n",
    "# Combine heatmap and text\n",
    "final_chart = heatmap + text\n",
    "\n",
    "# Display the plot\n",
    "final_chart.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "031b9ce6-7d92-4735-a298-e8f7812ebae0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:27:41.854544Z",
     "iopub.status.busy": "2024-09-25T08:27:41.854437Z",
     "iopub.status.idle": "2024-09-25T08:27:41.901039Z",
     "shell.execute_reply": "2024-09-25T08:27:41.900660Z",
     "shell.execute_reply.started": "2024-09-25T08:27:41.854535Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to Results/Ensemble Model Results/On FireCS dataset/OF Using FIRE ENSEMBLE/Stacking/OF_Using_FIRE 5STK-2 NB.png\n"
     ]
    }
   ],
   "source": [
    "# Specify the folder path\n",
    "folder_path = os.path.expanduser('Results/Ensemble Model Results/On FireCS dataset/OF Using FIRE ENSEMBLE/Stacking/')\n",
    "\n",
    "# Save the plot using vl-convert\n",
    "file_path_png = os.path.join(folder_path, 'OF_Using_FIRE 5STK-2 NB.png')\n",
    "final_chart.save(file_path_png)\n",
    "\n",
    "print(f\"Plot saved to {file_path_png}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba2269b-62c4-43d2-8394-9aa3c1a27678",
   "metadata": {},
   "source": [
    "### DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0448f107-62d6-4f1a-8b04-4378b79f3d3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:27:41.901703Z",
     "iopub.status.busy": "2024-09-25T08:27:41.901616Z",
     "iopub.status.idle": "2024-09-25T08:27:41.907181Z",
     "shell.execute_reply": "2024-09-25T08:27:41.906924Z",
     "shell.execute_reply.started": "2024-09-25T08:27:41.901695Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on HS-Data C Dataset\n",
      "Precision: 0.8170380269335332\n",
      "Recall: 0.8078260823947246\n",
      "Accuracy: 0.8074356530028599\n",
      "F1 Score: 0.810871702237887\n",
      "Confusion Matrix:\n",
      "[[278  63   0]\n",
      " [ 50 287  27]\n",
      " [  7  55 282]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the predictions\n",
    "precision = precision_score(y_val, val_dt_predictions, average='macro')\n",
    "recall = recall_score(y_val, val_dt_predictions, average='macro')\n",
    "accuracy = accuracy_score(y_val, val_dt_predictions)\n",
    "f1 = f1_score(y_val, val_dt_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_val, val_dt_predictions)\n",
    "\n",
    "print(\"Evaluation on HS-Data C Dataset\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9a0f105d-eb8f-4450-9d41-d90c97cf028c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:27:41.907814Z",
     "iopub.status.busy": "2024-09-25T08:27:41.907690Z",
     "iopub.status.idle": "2024-09-25T08:27:41.916856Z",
     "shell.execute_reply": "2024-09-25T08:27:41.916572Z",
     "shell.execute_reply.started": "2024-09-25T08:27:41.907806Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results\n",
      "Precision: 0.8170\n",
      "Recall: 0.8078\n",
      "Accuracy: 0.8074\n",
      "F1 Score: 0.8109\n",
      "Confusion Matrix:\n",
      "[[278  63   0]\n",
      " [ 50 287  27]\n",
      " [  7  55 282]]\n"
     ]
    }
   ],
   "source": [
    "dt_validation_probabilities = dt_meta_classifier.predict_proba(val_meta_features)\n",
    "\n",
    "# Apply thresholds to the validation set probabilities to make final predictions\n",
    "dt_validation_predictions = np.array([np.argmax([dt_validation_probabilities[i, j] if dt_validation_probabilities[i, j] >= dt_thresh[j] else 0\n",
    "                                              for j in range(dt_validation_probabilities.shape[1])])\n",
    "                                   for i in range(len(dt_validation_probabilities))])\n",
    "\n",
    "# Evaluate threshold on validation set\n",
    "adjusted_precision = precision_score(y_val, dt_validation_predictions, average='macro')\n",
    "adjusted_recall = recall_score(y_val, dt_validation_predictions, average='macro')\n",
    "adjusted_accuracy = accuracy_score(y_val, dt_validation_predictions)\n",
    "adjusted_f1 = f1_score(y_val, dt_validation_predictions, average='macro')\n",
    "adjusted_conf_matrix = confusion_matrix(y_val, dt_validation_predictions)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Validation Results\")\n",
    "print(f\"Precision: {adjusted_precision:.4f}\")\n",
    "print(f\"Recall: {adjusted_recall:.4f}\")\n",
    "print(f\"Accuracy: {adjusted_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {adjusted_f1:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(adjusted_conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dec85bf2-3044-4247-90ec-703089be962b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:27:41.917419Z",
     "iopub.status.busy": "2024-09-25T08:27:41.917326Z",
     "iopub.status.idle": "2024-09-25T08:27:42.360171Z",
     "shell.execute_reply": "2024-09-25T08:27:42.358749Z",
     "shell.execute_reply.started": "2024-09-25T08:27:41.917411Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated cells count: 4\n"
     ]
    }
   ],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '5-2!F6:I6'  \n",
    "\n",
    "values = [[\n",
    "    f\"{adjusted_precision * 100:.2f}\",\n",
    "    f\"{adjusted_recall * 100:.2f}\",\n",
    "    f\"{adjusted_accuracy * 100:.2f}\",\n",
    "    f\"{adjusted_f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8589d71-c489-4214-9c56-4a3a7ed69506",
   "metadata": {},
   "source": [
    "#### Save CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bb07bbd3-2021-4e16-8b59-3908f095b7cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:27:42.361417Z",
     "iopub.status.busy": "2024-09-25T08:27:42.361206Z",
     "iopub.status.idle": "2024-09-25T08:27:42.411235Z",
     "shell.execute_reply": "2024-09-25T08:27:42.410882Z",
     "shell.execute_reply.started": "2024-09-25T08:27:42.361398Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-fb66046fb146492c9a79eb6a0032f480.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-fb66046fb146492c9a79eb6a0032f480.vega-embed details,\n",
       "  #altair-viz-fb66046fb146492c9a79eb6a0032f480.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-fb66046fb146492c9a79eb6a0032f480\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-fb66046fb146492c9a79eb6a0032f480\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-fb66046fb146492c9a79eb6a0032f480\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"rect\"}, \"encoding\": {\"color\": {\"field\": \"Count\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"True\", \"type\": \"ordinal\"}, {\"field\": \"Predicted\", \"type\": \"ordinal\"}, {\"field\": \"Count\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Predicted\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}, \"y\": {\"field\": \"True\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}}, \"title\": \"OF_Using_FIRE 5STK-2 DT\"}, {\"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"middle\", \"fontSize\": 12}, \"encoding\": {\"color\": {\"condition\": {\"test\": \"(datum.Count > 143.5)\", \"value\": \"white\"}, \"value\": \"black\"}, \"text\": {\"field\": \"Count\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"True\", \"type\": \"ordinal\"}, {\"field\": \"Predicted\", \"type\": \"ordinal\"}, {\"field\": \"Count\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Predicted\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}, \"y\": {\"field\": \"True\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}}, \"title\": \"OF_Using_FIRE 5STK-2 DT\"}], \"data\": {\"name\": \"data-fbbc67cc7146d659ef8b86b2248383df\"}, \"height\": 300, \"width\": 400, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-fbbc67cc7146d659ef8b86b2248383df\": [{\"True\": \"Negative\", \"Predicted\": \"Negative\", \"Count\": 278}, {\"True\": \"Neutral\", \"Predicted\": \"Negative\", \"Count\": 50}, {\"True\": \"Positive\", \"Predicted\": \"Negative\", \"Count\": 7}, {\"True\": \"Negative\", \"Predicted\": \"Neutral\", \"Count\": 63}, {\"True\": \"Neutral\", \"Predicted\": \"Neutral\", \"Count\": 287}, {\"True\": \"Positive\", \"Predicted\": \"Neutral\", \"Count\": 55}, {\"True\": \"Negative\", \"Predicted\": \"Positive\", \"Count\": 0}, {\"True\": \"Neutral\", \"Predicted\": \"Positive\", \"Count\": 27}, {\"True\": \"Positive\", \"Predicted\": \"Positive\", \"Count\": 282}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import altair as alt\n",
    "import altair_saver\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_val, dt_validation_predictions)\n",
    "\n",
    "# Define class names\n",
    "class_names = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "# Convert confusion matrix to DataFrame\n",
    "cm_df = pd.DataFrame(cm, index=class_names, columns=class_names).reset_index().melt(id_vars='index')\n",
    "cm_df.columns = ['True', 'Predicted', 'Count']\n",
    "\n",
    "# Ensure the order of categories\n",
    "cm_df['True'] = pd.Categorical(cm_df['True'], categories=class_names, ordered=True)\n",
    "cm_df['Predicted'] = pd.Categorical(cm_df['Predicted'], categories=class_names, ordered=True)\n",
    "\n",
    "# Create the Altair plot\n",
    "heatmap = alt.Chart(cm_df).mark_rect().encode(\n",
    "    x=alt.X('Predicted:O', sort=class_names),\n",
    "    y=alt.Y('True:O', sort=class_names),\n",
    "    color='Count:Q',\n",
    "    tooltip=['True', 'Predicted', 'Count']\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=300,\n",
    "    title='OF_Using_FIRE 5STK-2 DT'\n",
    ")\n",
    "\n",
    "# Add text labels\n",
    "text = heatmap.mark_text(\n",
    "    align='center',\n",
    "    baseline='middle',\n",
    "    fontSize=12\n",
    ").encode(\n",
    "    text='Count:Q',\n",
    "    color=alt.condition(\n",
    "        alt.datum.Count > cm.max() / 2,\n",
    "        alt.value('white'),\n",
    "        alt.value('black')\n",
    "    )\n",
    ")\n",
    "\n",
    "# Combine heatmap and text\n",
    "final_chart = heatmap + text\n",
    "\n",
    "# Display the plot\n",
    "final_chart.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5445e621-6288-4a87-9e75-bf4511b2d9a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:27:42.411892Z",
     "iopub.status.busy": "2024-09-25T08:27:42.411788Z",
     "iopub.status.idle": "2024-09-25T08:27:42.458796Z",
     "shell.execute_reply": "2024-09-25T08:27:42.458385Z",
     "shell.execute_reply.started": "2024-09-25T08:27:42.411882Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to Results/Ensemble Model Results/On FireCS dataset/OF Using FIRE ENSEMBLE/Stacking/OF_Using_FIRE 5STK-2 DT.png\n"
     ]
    }
   ],
   "source": [
    "# Specify the folder path\n",
    "folder_path = os.path.expanduser('Results/Ensemble Model Results/On FireCS dataset/OF Using FIRE ENSEMBLE/Stacking/')\n",
    "\n",
    "# Save the plot using vl-convert\n",
    "file_path_png = os.path.join(folder_path, 'OF_Using_FIRE 5STK-2 DT.png')\n",
    "final_chart.save(file_path_png)\n",
    "\n",
    "print(f\"Plot saved to {file_path_png}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6165ef-d0ff-4230-9fdb-3c6a774d728f",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "660f90df-3de4-41b1-9fc6-4285133ec0a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:27:42.459445Z",
     "iopub.status.busy": "2024-09-25T08:27:42.459355Z",
     "iopub.status.idle": "2024-09-25T08:27:42.464751Z",
     "shell.execute_reply": "2024-09-25T08:27:42.464505Z",
     "shell.execute_reply.started": "2024-09-25T08:27:42.459438Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on HS-Data C Dataset\n",
      "Precision: 0.8123026769947788\n",
      "Recall: 0.8040331136730238\n",
      "Accuracy: 0.8036224976167778\n",
      "F1 Score: 0.8068331639398365\n",
      "Confusion Matrix:\n",
      "[[269  70   2]\n",
      " [ 40 284  40]\n",
      " [  3  51 290]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the predictions\n",
    "precision = precision_score(y_val, val_svm_predictions, average='macro')\n",
    "recall = recall_score(y_val, val_svm_predictions, average='macro')\n",
    "accuracy = accuracy_score(y_val, val_svm_predictions)\n",
    "f1 = f1_score(y_val, val_svm_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_val, val_svm_predictions)\n",
    "\n",
    "print(\"Evaluation on HS-Data C Dataset\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ad2fba87-04de-46b7-bc1d-1fbf7d1bb263",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:27:42.465321Z",
     "iopub.status.busy": "2024-09-25T08:27:42.465219Z",
     "iopub.status.idle": "2024-09-25T08:27:42.484961Z",
     "shell.execute_reply": "2024-09-25T08:27:42.484640Z",
     "shell.execute_reply.started": "2024-09-25T08:27:42.465313Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results\n",
      "Precision: 0.8114\n",
      "Recall: 0.8042\n",
      "Accuracy: 0.8036\n",
      "F1 Score: 0.8067\n",
      "Confusion Matrix:\n",
      "[[269  71   1]\n",
      " [ 40 281  43]\n",
      " [  3  48 293]]\n"
     ]
    }
   ],
   "source": [
    "svm_validation_probabilities = svm_meta_classifier.predict_proba(val_meta_features)\n",
    "\n",
    "# Apply thresholds to the validation set probabilities to make final predictions\n",
    "svm_validation_predictions = np.array([np.argmax([svm_validation_probabilities[i, j] if svm_validation_probabilities[i, j] >= svm_thresh[j] else 0\n",
    "                                              for j in range(svm_validation_probabilities.shape[1])])\n",
    "                                   for i in range(len(svm_validation_probabilities))])\n",
    "\n",
    "# Evaluate threshold on validation set\n",
    "adjusted_precision = precision_score(y_val, svm_validation_predictions, average='macro')\n",
    "adjusted_recall = recall_score(y_val, svm_validation_predictions, average='macro')\n",
    "adjusted_accuracy = accuracy_score(y_val, svm_validation_predictions)\n",
    "adjusted_f1 = f1_score(y_val, svm_validation_predictions, average='macro')\n",
    "adjusted_conf_matrix = confusion_matrix(y_val, svm_validation_predictions)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Validation Results\")\n",
    "print(f\"Precision: {adjusted_precision:.4f}\")\n",
    "print(f\"Recall: {adjusted_recall:.4f}\")\n",
    "print(f\"Accuracy: {adjusted_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {adjusted_f1:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(adjusted_conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7644868d-4140-415e-be20-4db4bfbf21b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:27:42.485529Z",
     "iopub.status.busy": "2024-09-25T08:27:42.485454Z",
     "iopub.status.idle": "2024-09-25T08:27:42.845272Z",
     "shell.execute_reply": "2024-09-25T08:27:42.844064Z",
     "shell.execute_reply.started": "2024-09-25T08:27:42.485522Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated cells count: 4\n"
     ]
    }
   ],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '5-2!F7:I7'  \n",
    "\n",
    "values = [[\n",
    "    f\"{adjusted_precision * 100:.2f}\",\n",
    "    f\"{adjusted_recall * 100:.2f}\",\n",
    "    f\"{adjusted_accuracy * 100:.2f}\",\n",
    "    f\"{adjusted_f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682be1a4-7bf8-4e44-9da2-2b7f48eac91c",
   "metadata": {},
   "source": [
    "#### Save CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "939272d5-856b-49da-99a2-4a25d818d2ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:27:42.846852Z",
     "iopub.status.busy": "2024-09-25T08:27:42.846526Z",
     "iopub.status.idle": "2024-09-25T08:27:42.896182Z",
     "shell.execute_reply": "2024-09-25T08:27:42.895701Z",
     "shell.execute_reply.started": "2024-09-25T08:27:42.846828Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-02975a58539149a4ae34853cd1ef2568.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-02975a58539149a4ae34853cd1ef2568.vega-embed details,\n",
       "  #altair-viz-02975a58539149a4ae34853cd1ef2568.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-02975a58539149a4ae34853cd1ef2568\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-02975a58539149a4ae34853cd1ef2568\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-02975a58539149a4ae34853cd1ef2568\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"rect\"}, \"encoding\": {\"color\": {\"field\": \"Count\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"True\", \"type\": \"ordinal\"}, {\"field\": \"Predicted\", \"type\": \"ordinal\"}, {\"field\": \"Count\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Predicted\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}, \"y\": {\"field\": \"True\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}}, \"title\": \"OF_Using_FIRE 5STK-2 SVM\"}, {\"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"middle\", \"fontSize\": 12}, \"encoding\": {\"color\": {\"condition\": {\"test\": \"(datum.Count > 146.5)\", \"value\": \"white\"}, \"value\": \"black\"}, \"text\": {\"field\": \"Count\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"True\", \"type\": \"ordinal\"}, {\"field\": \"Predicted\", \"type\": \"ordinal\"}, {\"field\": \"Count\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Predicted\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}, \"y\": {\"field\": \"True\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}}, \"title\": \"OF_Using_FIRE 5STK-2 SVM\"}], \"data\": {\"name\": \"data-3f8c470af4f6ebc8d5ef8891f2aec5fa\"}, \"height\": 300, \"width\": 400, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-3f8c470af4f6ebc8d5ef8891f2aec5fa\": [{\"True\": \"Negative\", \"Predicted\": \"Negative\", \"Count\": 269}, {\"True\": \"Neutral\", \"Predicted\": \"Negative\", \"Count\": 40}, {\"True\": \"Positive\", \"Predicted\": \"Negative\", \"Count\": 3}, {\"True\": \"Negative\", \"Predicted\": \"Neutral\", \"Count\": 71}, {\"True\": \"Neutral\", \"Predicted\": \"Neutral\", \"Count\": 281}, {\"True\": \"Positive\", \"Predicted\": \"Neutral\", \"Count\": 48}, {\"True\": \"Negative\", \"Predicted\": \"Positive\", \"Count\": 1}, {\"True\": \"Neutral\", \"Predicted\": \"Positive\", \"Count\": 43}, {\"True\": \"Positive\", \"Predicted\": \"Positive\", \"Count\": 293}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import altair as alt\n",
    "import altair_saver\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_val, svm_validation_predictions)\n",
    "\n",
    "# Define class names\n",
    "class_names = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "# Convert confusion matrix to DataFrame\n",
    "cm_df = pd.DataFrame(cm, index=class_names, columns=class_names).reset_index().melt(id_vars='index')\n",
    "cm_df.columns = ['True', 'Predicted', 'Count']\n",
    "\n",
    "# Ensure the order of categories\n",
    "cm_df['True'] = pd.Categorical(cm_df['True'], categories=class_names, ordered=True)\n",
    "cm_df['Predicted'] = pd.Categorical(cm_df['Predicted'], categories=class_names, ordered=True)\n",
    "\n",
    "# Create the Altair plot\n",
    "heatmap = alt.Chart(cm_df).mark_rect().encode(\n",
    "    x=alt.X('Predicted:O', sort=class_names),\n",
    "    y=alt.Y('True:O', sort=class_names),\n",
    "    color='Count:Q',\n",
    "    tooltip=['True', 'Predicted', 'Count']\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=300,\n",
    "    title='OF_Using_FIRE 5STK-2 SVM'\n",
    ")\n",
    "\n",
    "# Add text labels\n",
    "text = heatmap.mark_text(\n",
    "    align='center',\n",
    "    baseline='middle',\n",
    "    fontSize=12\n",
    ").encode(\n",
    "    text='Count:Q',\n",
    "    color=alt.condition(\n",
    "        alt.datum.Count > cm.max() / 2,\n",
    "        alt.value('white'),\n",
    "        alt.value('black')\n",
    "    )\n",
    ")\n",
    "\n",
    "# Combine heatmap and text\n",
    "final_chart = heatmap + text\n",
    "\n",
    "# Display the plot\n",
    "final_chart.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4ab1dbec-94d8-4f9c-b5e8-843b853a71cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:27:42.897080Z",
     "iopub.status.busy": "2024-09-25T08:27:42.896813Z",
     "iopub.status.idle": "2024-09-25T08:27:42.945186Z",
     "shell.execute_reply": "2024-09-25T08:27:42.944795Z",
     "shell.execute_reply.started": "2024-09-25T08:27:42.897066Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to Results/Ensemble Model Results/On FireCS dataset/OF Using FIRE ENSEMBLE/Stacking/OF_Using_FIRE 5STK-2 SVM.png\n"
     ]
    }
   ],
   "source": [
    "# Specify the folder path\n",
    "folder_path = os.path.expanduser('Results/Ensemble Model Results/On FireCS dataset/OF Using FIRE ENSEMBLE/Stacking/')\n",
    "\n",
    "# Save the plot using vl-convert\n",
    "file_path_png = os.path.join(folder_path, 'OF_Using_FIRE 5STK-2 SVM.png')\n",
    "final_chart.save(file_path_png)\n",
    "\n",
    "print(f\"Plot saved to {file_path_png}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a298f212-36ec-4e75-ad74-d7b272d094a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80391c9f-64d7-4e98-b9f0-6ee41cb035f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
