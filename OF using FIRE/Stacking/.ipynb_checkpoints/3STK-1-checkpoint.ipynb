{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dc06b17-fcee-4505-bd74-d98376ce3ed9",
   "metadata": {},
   "source": [
    "# Train Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c6a724-b17e-46f6-aee6-90ef2f7877a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T15:08:53.465538Z",
     "iopub.status.busy": "2024-08-13T15:08:53.465321Z",
     "iopub.status.idle": "2024-08-13T15:08:53.469076Z",
     "shell.execute_reply": "2024-08-13T15:08:53.468592Z",
     "shell.execute_reply.started": "2024-08-13T15:08:53.465526Z"
    }
   },
   "source": [
    "Best F1 score BERT model on HS_C dataset are used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3823c3e6-976a-4eb9-a651-2cfeaa1a3cc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-18T12:50:23.708005Z",
     "iopub.status.busy": "2024-09-18T12:50:23.707714Z",
     "iopub.status.idle": "2024-09-18T12:50:23.836450Z",
     "shell.execute_reply": "2024-09-18T12:50:23.836204Z",
     "shell.execute_reply.started": "2024-09-18T12:50:23.707869Z"
    }
   },
   "outputs": [],
   "source": [
    "# This automates data tabulation onto google sheets \n",
    "\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "import os\n",
    "\n",
    "# new directory path\n",
    "new_directory = '/Users/levan/ATENEO MASTERAL/Thesis'\n",
    "\n",
    "# Change the current working directory\n",
    "os.chdir(new_directory)\n",
    "\n",
    "# Use creds to create a client to interact with the Google Drive API\n",
    "scope = ['https://spreadsheets.google.com/feeds','https://www.googleapis.com/auth/drive']\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_name('thesis-432315-12daec8d1ff6.json', scope)\n",
    "\n",
    "service = build('sheets', 'v4', credentials=creds)\n",
    "\n",
    "client = gspread.authorize(creds)\n",
    "\n",
    "spreadsheet_id = '13Fk5oXX9B_mdHmNpMKQMy29y9iiHWrgQCa4hUTiQKD0' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d70bdb-0504-41ef-913d-e4b7f778f561",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7b193db-3f30-4e5f-a38b-c254bf1e1976",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-18T12:50:23.836957Z",
     "iopub.status.busy": "2024-09-18T12:50:23.836881Z",
     "iopub.status.idle": "2024-09-18T12:50:26.992427Z",
     "shell.execute_reply": "2024-09-18T12:50:26.992187Z",
     "shell.execute_reply.started": "2024-09-18T12:50:23.836946Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AutoConfig\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_recall_curve, f1_score, confusion_matrix, precision_score, recall_score, accuracy_score\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "# new directory path\n",
    "new_directory = '/Users/levan/ATENEO MASTERAL/Thesis/Development'\n",
    "\n",
    "# Change the current working directory\n",
    "os.chdir(new_directory)\n",
    "\n",
    "#Load Data\n",
    "df = pd.read_csv('Corpus/FiReCS/FiReCS_data_b.csv')\n",
    "X = df['review'].values\n",
    "y = df['label'].values\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a307e67b-00c3-47aa-8f83-34bc62c93f83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-11T10:08:58.783500Z",
     "iopub.status.busy": "2024-04-11T10:08:58.782872Z",
     "iopub.status.idle": "2024-04-11T10:08:58.788089Z",
     "shell.execute_reply": "2024-04-11T10:08:58.787147Z",
     "shell.execute_reply.started": "2024-04-11T10:08:58.783465Z"
    }
   },
   "source": [
    "## Load Models and Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e666f7e-9db0-4666-a112-2af127307162",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-18T12:50:26.992892Z",
     "iopub.status.busy": "2024-09-18T12:50:26.992816Z",
     "iopub.status.idle": "2024-09-18T12:50:30.199716Z",
     "shell.execute_reply": "2024-09-18T12:50:30.199409Z",
     "shell.execute_reply.started": "2024-09-18T12:50:26.992885Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_model_and_tokenizer(model_path, tokenizer_path, base_model):\n",
    "    # Load the tokenizer from the local directory\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "    \n",
    "    # Load the configuration from the base model, then update configuration if needed\n",
    "    config = AutoConfig.from_pretrained(base_model, num_labels=3)\n",
    "\n",
    "    # Initialize the model with the configuration\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_path, config=config)\n",
    "\n",
    "    # Ensure the model is in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    return model, tokenizer\n",
    "\n",
    "model_info = {\n",
    "    \n",
    "    'BERT cased': {\n",
    "        'model_path': 'BERT models/1 FiReCS/fire_bert-base-cased-finetuned',\n",
    "        'tokenizer_path': 'BERT models/1 FiReCS/fire_bert-base-cased-finetuned',\n",
    "        'base_model': 'google-bert/bert-base-cased'\n",
    "    },\n",
    "\n",
    "    'DistilBERT uncased': {\n",
    "        'model_path': 'BERT models/1 FiReCS/fire_distilbert-base-uncased-finetuned',\n",
    "        'tokenizer_path': 'BERT models/1 FiReCS/fire_distilbert-base-uncased-finetuned',\n",
    "        'base_model': 'distilbert/distilbert-base-uncased'\n",
    "    },\n",
    "\n",
    "    'DeBERTa': {\n",
    "        'model_path': 'BERT models/1 FiReCS/fire_DeBERTa-finetuned',\n",
    "        'tokenizer_path': 'BERT models/1 FiReCS/fire_DeBERTa-finetuned',\n",
    "        'base_model': 'microsoft/deberta-v3-base'\n",
    "    }\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "models_and_tokenizers = {name: load_model_and_tokenizer(info['model_path'], \n",
    "                                                        info['tokenizer_path'], \n",
    "                                                        info['base_model']) \n",
    "                         for name, info in model_info.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a9b906-a837-4de8-b8a2-05aa44074c5c",
   "metadata": {},
   "source": [
    "## Apply Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05f7b2f9-3bc4-4d6d-8595-8971899238c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-18T12:50:30.200183Z",
     "iopub.status.busy": "2024-09-18T12:50:30.200115Z",
     "iopub.status.idle": "2024-09-18T12:50:30.202964Z",
     "shell.execute_reply": "2024-09-18T12:50:30.202742Z",
     "shell.execute_reply.started": "2024-09-18T12:50:30.200177Z"
    }
   },
   "outputs": [],
   "source": [
    "class MultiModelTextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, labels, models_and_tokenizers, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.models_and_tokenizers = models_and_tokenizers\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.texts[index])\n",
    "        label = self.labels[index]\n",
    "\n",
    "        model_inputs = {}\n",
    "        for name, (model, tokenizer) in self.models_and_tokenizers.items():\n",
    "            encoding = tokenizer.encode_plus(\n",
    "                text,\n",
    "                add_special_tokens=True,\n",
    "                max_length=self.max_len,\n",
    "                return_token_type_ids=False,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                return_attention_mask=True,\n",
    "                return_tensors='pt',\n",
    "            )\n",
    "            model_inputs[name] = {\n",
    "                'input_ids': encoding['input_ids'].squeeze(0),  # Remove batch dimension\n",
    "                'attention_mask': encoding['attention_mask'].squeeze(0)  # Remove batch dimension\n",
    "            }\n",
    "        return {'model_inputs': model_inputs, 'label': torch.tensor(label, dtype=torch.long)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d574483-f790-48ba-a7d0-07cc8f2973d4",
   "metadata": {},
   "source": [
    "## BERT Training for Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e6167c5-79fd-4536-815c-237ec599453a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-18T12:50:30.203471Z",
     "iopub.status.busy": "2024-09-18T12:50:30.203381Z",
     "iopub.status.idle": "2024-09-18T12:50:30.206606Z",
     "shell.execute_reply": "2024-09-18T12:50:30.206394Z",
     "shell.execute_reply.started": "2024-09-18T12:50:30.203464Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_base_learner(model, data_loader, optimizer, device):\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    correct_predictions = 0\n",
    "    losses = []\n",
    "\n",
    "    for batch in data_loader:\n",
    "        # Accessing inputs for the current model\n",
    "        inputs = batch['model_inputs']\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        for model_name, model_inputs in inputs.items():\n",
    "            # Forward pass\n",
    "            outputs = model(input_ids=model_inputs['input_ids'].squeeze(1).to(device),\n",
    "                attention_mask=model_inputs['attention_mask'].squeeze(1).to(device),\n",
    "                labels=labels)\n",
    "\n",
    "            loss = outputs.loss\n",
    "            preds = outputs.logits.argmax(dim=1)\n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    return correct_predictions.float() / len(data_loader.dataset), np.mean(losses).astype(np.float32)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def eval_model(model, data_loader, device):\n",
    "    model = model.eval()\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for d in data_loader:\n",
    "            input_ids = d[\"input_ids\"].to(device)\n",
    "            attention_mask = d[\"attention_mask\"].to(device)\n",
    "            labels = d[\"label\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            preds = outputs.logits.argmax(dim=1)\n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "\n",
    "    return correct_predictions.double() / len(data_loader.dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b36fee-48a1-4eda-bf0b-c59982cbba14",
   "metadata": {},
   "source": [
    "## Train Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99eb6be0-fb6e-441b-bfaa-853e75a01983",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-18T12:50:30.207995Z",
     "iopub.status.busy": "2024-09-18T12:50:30.207896Z",
     "iopub.status.idle": "2024-09-18T12:50:30.231869Z",
     "shell.execute_reply": "2024-09-18T12:50:30.231554Z",
     "shell.execute_reply.started": "2024-09-18T12:50:30.207989Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, confusion_matrix\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "\n",
    "def train_stacking_classifier(models_and_tokenizers, X_train, y_train, device, max_len=128):\n",
    "    n_splits = 4\n",
    "    skf = StratifiedKFold(n_splits=n_splits)\n",
    "    base_learners_predictions_train = np.zeros((len(X_train), len(models_and_tokenizers)))\n",
    "    fold_idx = 0\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_train, y_train):\n",
    "        fold_idx += 1\n",
    "        print(f\"Training fold {fold_idx}/{n_splits}...\")\n",
    "        train_texts, val_texts = X_train[train_idx], X_train[val_idx]\n",
    "        train_labels, val_labels = y_train[train_idx], y_train[val_idx]\n",
    "        \n",
    "        model_idx = 0\n",
    "        for name, (model, tokenizer) in models_and_tokenizers.items():\n",
    "            train_dataset = MultiModelTextDataset(train_texts, train_labels, {name: (model, tokenizer)}, max_len)\n",
    "            val_dataset = MultiModelTextDataset(val_texts, val_labels, {name: (model, tokenizer)}, max_len)\n",
    "            train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "            \n",
    "            optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "            train_base_learner(model, train_loader, optimizer, device)\n",
    "            \n",
    "            val_preds = []\n",
    "            model.eval()\n",
    "            for batch in val_loader:\n",
    "                inputs = batch['model_inputs'][name]\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(input_ids=inputs['input_ids'].to(device), attention_mask=inputs['attention_mask'].to(device))\n",
    "                val_preds.extend(outputs.logits.argmax(dim=1).cpu().numpy())\n",
    "            \n",
    "            base_learners_predictions_train[val_idx, model_idx] = np.array(val_preds)\n",
    "            model_idx += 1\n",
    "\n",
    "    return base_learners_predictions_train, y_train\n",
    "\n",
    "def get_predictions(models_and_tokenizers, X, y, device, max_len=128):\n",
    "    predictions = np.zeros((len(X), len(models_and_tokenizers)))\n",
    "    model_idx = 0\n",
    "    for name, (model, tokenizer) in models_and_tokenizers.items():\n",
    "        dataset = MultiModelTextDataset(X, y, {name: (model, tokenizer)}, max_len)\n",
    "        loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
    "        \n",
    "        preds = []\n",
    "        model.eval()\n",
    "        for batch in loader:\n",
    "            inputs = batch['model_inputs'][name]\n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_ids=inputs['input_ids'].to(device), attention_mask=inputs['attention_mask'].to(device))\n",
    "            preds.extend(outputs.logits.argmax(dim=1).cpu().numpy())\n",
    "        \n",
    "        predictions[:, model_idx] = np.array(preds)\n",
    "        model_idx += 1\n",
    "\n",
    "    return predictions\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58472c03-8cb9-4a28-b8f3-fd5227c0e620",
   "metadata": {},
   "source": [
    "## Perform Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da0e67bd-3f57-4bf1-aa4e-1537a9132002",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-18T12:50:30.232439Z",
     "iopub.status.busy": "2024-09-18T12:50:30.232307Z",
     "iopub.status.idle": "2024-09-18T12:50:30.235800Z",
     "shell.execute_reply": "2024-09-18T12:50:30.235536Z",
     "shell.execute_reply.started": "2024-09-18T12:50:30.232432Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36436c2d-846d-46ab-ae3c-b36c5bdda6a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-18T12:50:30.236292Z",
     "iopub.status.busy": "2024-09-18T12:50:30.236223Z",
     "iopub.status.idle": "2024-09-18T12:58:51.116756Z",
     "shell.execute_reply": "2024-09-18T12:58:51.116445Z",
     "shell.execute_reply.started": "2024-09-18T12:50:30.236286Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/transformers/optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 2/4...\n",
      "Training fold 3/4...\n",
      "Training fold 4/4...\n",
      "peak memory: 4087.19 MiB, increment: 2174.42 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# Train stacking classifier (using 4-fold cross validation for each BERT model) on Train Set and retrieve training meta-features\n",
    "train_meta_features, _ = train_stacking_classifier(models_and_tokenizers, X_train, y_train, device)\n",
    "\n",
    "# Generate predictions for the test set to be used as test meta-features\n",
    "test_meta_features = get_predictions(models_and_tokenizers, X_test, y_test, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d42e0b-1855-4774-8f83-599a6158e526",
   "metadata": {},
   "source": [
    "### Train LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "265a5311-c2a4-48a0-9f21-d803350fb89f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-18T12:58:51.117376Z",
     "iopub.status.busy": "2024-09-18T12:58:51.117289Z",
     "iopub.status.idle": "2024-09-18T12:58:51.883979Z",
     "shell.execute_reply": "2024-09-18T12:58:51.883653Z",
     "shell.execute_reply.started": "2024-09-18T12:58:51.117369Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 4087.89 MiB, increment: 0.70 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "\n",
    "lr_meta_classifier = LogisticRegression()\n",
    "lr_meta_classifier.fit(train_meta_features, y_train)\n",
    "\n",
    "lr_final_predictions = lr_meta_classifier.predict(test_meta_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ea06bb-fab4-4f49-99e4-19680ec1b870",
   "metadata": {},
   "source": [
    "### Train NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "244b0f68-e401-4d18-913f-a3a153dd8104",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-18T12:58:51.884661Z",
     "iopub.status.busy": "2024-09-18T12:58:51.884581Z",
     "iopub.status.idle": "2024-09-18T12:58:53.318552Z",
     "shell.execute_reply": "2024-09-18T12:58:53.318198Z",
     "shell.execute_reply.started": "2024-09-18T12:58:51.884654Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 4087.92 MiB, increment: 0.02 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "\n",
    "nb_meta_classifier = GaussianNB()\n",
    "nb_meta_classifier.fit(train_meta_features, y_train)\n",
    "\n",
    "nb_final_predictions = nb_meta_classifier.predict(test_meta_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e50604f-9bef-4db4-bf92-89f9d2874e89",
   "metadata": {},
   "source": [
    "### Train DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3990ca03-b860-4b65-97e7-47f551754ab7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-18T12:58:53.319154Z",
     "iopub.status.busy": "2024-09-18T12:58:53.319061Z",
     "iopub.status.idle": "2024-09-18T12:58:54.763602Z",
     "shell.execute_reply": "2024-09-18T12:58:54.763231Z",
     "shell.execute_reply.started": "2024-09-18T12:58:53.319144Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 4088.39 MiB, increment: 0.47 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "\n",
    "dt_meta_classifier = DecisionTreeClassifier(max_depth=None)\n",
    "dt_meta_classifier.fit(train_meta_features, y_train)\n",
    "\n",
    "dt_final_predictions = dt_meta_classifier.predict(test_meta_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986bd8f0-b569-4eaf-8e13-a51529e871e6",
   "metadata": {},
   "source": [
    "### Train SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "460a4087-b343-4249-b794-db90baabf11c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-18T12:58:54.764294Z",
     "iopub.status.busy": "2024-09-18T12:58:54.764204Z",
     "iopub.status.idle": "2024-09-18T12:58:55.495775Z",
     "shell.execute_reply": "2024-09-18T12:58:55.495453Z",
     "shell.execute_reply.started": "2024-09-18T12:58:54.764287Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 4091.47 MiB, increment: 3.08 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "\n",
    "svm_meta_classifier = SVC(kernel='linear', probability=True)\n",
    "svm_meta_classifier.fit(train_meta_features, y_train)\n",
    "\n",
    "svm_final_predictions = svm_meta_classifier.predict(test_meta_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad340b68-d07e-473a-bbc4-138ef8e0271a",
   "metadata": {},
   "source": [
    "## EVALUATE MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93ba0c5-a053-45fb-8e97-b09c67959bc8",
   "metadata": {},
   "source": [
    "### LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d015915-5eb9-4a73-9ef6-5fc1bd4d0e8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-18T12:58:55.496505Z",
     "iopub.status.busy": "2024-09-18T12:58:55.496387Z",
     "iopub.status.idle": "2024-09-18T12:58:55.502864Z",
     "shell.execute_reply": "2024-09-18T12:58:55.502604Z",
     "shell.execute_reply.started": "2024-09-18T12:58:55.496498Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Precision: 0.840177934741322\n",
      "Recall: 0.8299192540689556\n",
      "Ensemble accuracy: 0.8298022598870056\n",
      "F1 Score: 0.8332093509307912\n",
      "Confusion Matrix:\n",
      "[[380  78   2]\n",
      " [ 57 404  30]\n",
      " [  0  74 391]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "precision = precision_score(y_test, lr_final_predictions, average='macro')\n",
    "recall = recall_score(y_test, lr_final_predictions, average='macro')\n",
    "accuracy = accuracy_score(y_test, lr_final_predictions)\n",
    "f1 = f1_score(y_test, lr_final_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_test, lr_final_predictions)\n",
    "\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Ensemble accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8f0cb82-3466-4ed1-8131-5b8715817f8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-18T13:11:20.290953Z",
     "iopub.status.busy": "2024-09-18T13:11:20.290345Z",
     "iopub.status.idle": "2024-09-18T13:11:20.318977Z",
     "shell.execute_reply": "2024-09-18T13:11:20.318579Z",
     "shell.execute_reply.started": "2024-09-18T13:11:20.290918Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized thresholds for each class: [0.8030075963821669, 0.3547972477920736, 0.7939251539422403]\n",
      "Logistic Regression\n",
      "Precision: 0.8421\n",
      "Recall: 0.8306\n",
      "Ensemble accuracy: 0.8305\n",
      "F1 Score: 0.8341672080670809\n",
      "Confusion Matrix:\n",
      "[[381  79   0]\n",
      " [ 57 406  28]\n",
      " [  0  76 389]]\n"
     ]
    }
   ],
   "source": [
    "probabilities = lr_meta_classifier.predict_proba(test_meta_features)\n",
    "\n",
    "# Calculate precision-recall curve and find optimal thresholds for each class\n",
    "lr_thresh = []\n",
    "for i in range(probabilities.shape[1]):  # Iterate over each class\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test == i, probabilities[:, i])\n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "    optimal_idx = np.nanargmax(f1_scores)  # Handle cases where precision and recall are both zero\n",
    "    lr_thresh.append(thresholds[optimal_idx])\n",
    "\n",
    "# Apply the optimized thresholds to make adjusted predictions\n",
    "adjusted_predictions = np.array([np.argmax([probabilities[i, j] if probabilities[i, j] >= lr_thresh[j] else 0\n",
    "                                         for j in range(probabilities.shape[1])])\n",
    "                              for i in range(len(probabilities))])\n",
    "\n",
    "# Evaluate\n",
    "adjusted_precision = precision_score(y_test, adjusted_predictions, average='macro')\n",
    "adjusted_recall = recall_score(y_test, adjusted_predictions, average='macro')\n",
    "adjusted_accuracy = accuracy_score(y_test, adjusted_predictions)\n",
    "adjusted_f1 = f1_score(y_test, adjusted_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_test, adjusted_predictions)\n",
    "\n",
    "print(\"Optimized thresholds for each class:\", lr_thresh)\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Precision: {adjusted_precision:.4f}\")\n",
    "print(f\"Recall: {adjusted_recall:.4f}\")\n",
    "print(f\"Ensemble accuracy: {adjusted_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {adjusted_f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c3c869f-17ad-4e4a-ad5e-92c092fb4b3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-18T13:14:10.760996Z",
     "iopub.status.busy": "2024-09-18T13:14:10.760288Z",
     "iopub.status.idle": "2024-09-18T13:14:11.128979Z",
     "shell.execute_reply": "2024-09-18T13:14:11.122461Z",
     "shell.execute_reply.started": "2024-09-18T13:14:10.760962Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(probabilities.shape[1]):  # For each class\n",
    "    plt.hist(probabilities[:, i], bins=50, alpha=0.5, label=f'Class {i}')\n",
    "plt.title('Distribution of Predicted Probabilities for Each Class')\n",
    "plt.xlabel('Predicted Probability')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c650bc-c7b7-4f3d-b8c7-c415ed29f2f1",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-18T12:58:55.674933Z",
     "iopub.status.idle": "2024-09-18T12:58:55.675030Z",
     "shell.execute_reply": "2024-09-18T12:58:55.674977Z",
     "shell.execute_reply.started": "2024-09-18T12:58:55.674973Z"
    }
   },
   "outputs": [],
   "source": [
    "# Threshold optimization\n",
    "thresholds = np.linspace(0.01, 0.99, 99)\n",
    "scores = [f1_score(y_test, lr_prob_scores >= t, average='macro') for t in thresholds]\n",
    "best_thresh = thresholds[np.argmax(scores)]\n",
    "adjusted_predictions = (lr_prob_scores >= best_thresh).astype(int)\n",
    "\n",
    "# Evaluate with the new threshold\n",
    "adjusted_precision = precision_score(y_test, adjusted_predictions, average='macro')\n",
    "adjusted_recall = recall_score(y_test, adjusted_predictions, average='macro')\n",
    "adjusted_accuracy = accuracy_score(y_test, adjusted_predictions)\n",
    "adjusted_f1 = f1_score(y_test, adjusted_predictions, average='macro')\n",
    "adjusted_conf_matrix = confusion_matrix(y_test, adjusted_predictions)\n",
    "\n",
    "print(f\"Adjusted threshold: {best_thresh}\")\n",
    "print(\"Optimized Logistic Regression\")\n",
    "print(f\"Precision: {adjusted_precision}\")\n",
    "print(f\"Recall: {adjusted_recall}\")\n",
    "print(f\"Accuracy: {adjusted_accuracy}\")\n",
    "print(f\"F1 Score: {adjusted_f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(adjusted_conf_matrix)\n",
    "\n",
    "lr_thresh = best_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc6b32b-5f2a-4017-8a2b-e393ee1f85b3",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-18T12:58:55.675344Z",
     "iopub.status.idle": "2024-09-18T12:58:55.675428Z",
     "shell.execute_reply": "2024-09-18T12:58:55.675381Z",
     "shell.execute_reply.started": "2024-09-18T12:58:55.675378Z"
    }
   },
   "outputs": [],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '3-1!B4:E4'  \n",
    "\n",
    "values = [[\n",
    "    f\"{adjusted_precision * 100:.2f}\",\n",
    "    f\"{adjusted_recall * 100:.2f}\",\n",
    "    f\"{adjusted_accuracy * 100:.2f}\",\n",
    "    f\"{adjusted_f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f311d02-936c-467e-ae14-e0c9cd0f0211",
   "metadata": {},
   "source": [
    "### NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cde7aba-1d7b-4fbd-94f0-98b9e5b2756a",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-18T12:58:55.675900Z",
     "iopub.status.idle": "2024-09-18T12:58:55.676013Z",
     "shell.execute_reply": "2024-09-18T12:58:55.675957Z",
     "shell.execute_reply.started": "2024-09-18T12:58:55.675952Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "precision = precision_score(y_test, nb_final_predictions, average='macro')\n",
    "recall = recall_score(y_test, nb_final_predictions, average='macro')\n",
    "accuracy = accuracy_score(y_test, nb_final_predictions)\n",
    "f1 = f1_score(y_test, nb_final_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_test, nb_final_predictions)\n",
    "\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Ensemble accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07991bda-71ea-4786-996b-61a3ae0132ff",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-18T12:58:55.677025Z",
     "iopub.status.idle": "2024-09-18T12:58:55.677202Z",
     "shell.execute_reply": "2024-09-18T12:58:55.677153Z",
     "shell.execute_reply.started": "2024-09-18T12:58:55.677149Z"
    }
   },
   "outputs": [],
   "source": [
    "probabilities = nb_meta_classifier.predict_proba(test_meta_features)\n",
    "\n",
    "# Calculate precision-recall curve and find optimal thresholds for each class\n",
    "nb_thresh = []\n",
    "for i in range(probabilities.shape[1]):  # Iterate over each class\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test == i, probabilities[:, i])\n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "    optimal_idx = np.nanargmax(f1_scores)  # Handle cases where precision and recall are both zero\n",
    "    nb_thresh.append(thresholds[optimal_idx])\n",
    "\n",
    "# Apply the optimized thresholds to make adjusted predictions\n",
    "adjusted_predictions = np.array([np.argmax([probabilities[i, j] if probabilities[i, j] >= nb_thresh[j] else 0\n",
    "                                         for j in range(probabilities.shape[1])])\n",
    "                              for i in range(len(probabilities))])\n",
    "\n",
    "# Evaluate\n",
    "adjusted_precision = precision_score(y_test, adjusted_predictions, average='macro')\n",
    "adjusted_recall = recall_score(y_test, adjusted_predictions, average='macro')\n",
    "adjusted_accuracy = accuracy_score(y_test, adjusted_predictions)\n",
    "adjusted_f1 = f1_score(y_test, adjusted_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_test, adjusted_predictions)\n",
    "\n",
    "print(\"Optimized thresholds for each class:\", nb_thresh)\n",
    "print(\"Naive Bayes\")\n",
    "print(f\"Precision: {adjusted_precision:.4f}\")\n",
    "print(f\"Recall: {adjusted_recall:.4f}\")\n",
    "print(f\"Ensemble accuracy: {adjusted_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {adjusted_f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0903f29c-3dd0-4901-b045-45bf1b895fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(probabilities.shape[1]):  # For each class\n",
    "    plt.hist(probabilities[:, i], bins=50, alpha=0.5, label=f'Class {i}')\n",
    "plt.title('Distribution of Predicted Probabilities for Each Class')\n",
    "plt.xlabel('Predicted Probability')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecf64b8-5a1a-4cea-a077-2049e0459dd9",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-18T12:58:55.677469Z",
     "iopub.status.idle": "2024-09-18T12:58:55.677575Z",
     "shell.execute_reply": "2024-09-18T12:58:55.677520Z",
     "shell.execute_reply.started": "2024-09-18T12:58:55.677515Z"
    }
   },
   "outputs": [],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '3-1!B5:E5'  \n",
    "\n",
    "values = [[\n",
    "    f\"{adjusted_precision * 100:.2f}\",\n",
    "    f\"{adjusted_recall * 100:.2f}\",\n",
    "    f\"{adjusted_accuracy * 100:.2f}\",\n",
    "    f\"{adjusted_f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958d063b-7c6a-43d7-aaa2-0b93e3d56610",
   "metadata": {},
   "source": [
    "### DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c799950-2309-4a08-9778-351ab70a85db",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-18T12:58:55.677896Z",
     "iopub.status.idle": "2024-09-18T12:58:55.677986Z",
     "shell.execute_reply": "2024-09-18T12:58:55.677936Z",
     "shell.execute_reply.started": "2024-09-18T12:58:55.677932Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "precision = precision_score(y_test, dt_final_predictions, average='macro')\n",
    "recall = recall_score(y_test, dt_final_predictions, average='macro')\n",
    "accuracy = accuracy_score(y_test, dt_final_predictions)\n",
    "f1 = f1_score(y_test, dt_final_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_test, dt_final_predictions)\n",
    "\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Ensemble accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a63b5fc-8c61-409f-86bf-470f00eb6d99",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-18T12:58:55.678793Z",
     "iopub.status.idle": "2024-09-18T12:58:55.678898Z",
     "shell.execute_reply": "2024-09-18T12:58:55.678844Z",
     "shell.execute_reply.started": "2024-09-18T12:58:55.678839Z"
    }
   },
   "outputs": [],
   "source": [
    "probabilities = dt_meta_classifier.predict_proba(test_meta_features)\n",
    "\n",
    "# Calculate precision-recall curve and find optimal thresholds for each class\n",
    "dt_thresh = []\n",
    "for i in range(probabilities.shape[1]):  # Iterate over each class\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test == i, probabilities[:, i])\n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "    optimal_idx = np.nanargmax(f1_scores)  # Handle cases where precision and recall are both zero\n",
    "    dt_thresh.append(thresholds[optimal_idx])\n",
    "\n",
    "# Apply the optimized thresholds to make adjusted predictions\n",
    "adjusted_predictions = np.array([np.argmax([probabilities[i, j] if probabilities[i, j] >= dt_thresh[j] else 0\n",
    "                                         for j in range(probabilities.shape[1])])\n",
    "                              for i in range(len(probabilities))])\n",
    "\n",
    "# Evaluate\n",
    "adjusted_precision = precision_score(y_test, adjusted_predictions, average='macro')\n",
    "adjusted_recall = recall_score(y_test, adjusted_predictions, average='macro')\n",
    "adjusted_accuracy = accuracy_score(y_test, adjusted_predictions)\n",
    "adjusted_f1 = f1_score(y_test, adjusted_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_test, adjusted_predictions)\n",
    "\n",
    "print(\"Optimized thresholds for each class:\", dt_thresh)\n",
    "print(\"Decision Tree\")\n",
    "print(f\"Precision: {adjusted_precision:.4f}\")\n",
    "print(f\"Recall: {adjusted_recall:.4f}\")\n",
    "print(f\"Ensemble accuracy: {adjusted_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {adjusted_f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59db5724-688c-4bd3-ba20-0d250545b1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(probabilities.shape[1]):  # For each class\n",
    "    plt.hist(probabilities[:, i], bins=50, alpha=0.5, label=f'Class {i}')\n",
    "plt.title('Distribution of Predicted Probabilities for Each Class')\n",
    "plt.xlabel('Predicted Probability')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9653e844-4196-4d63-9b61-4998f3dba2d0",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-18T12:58:55.679195Z",
     "iopub.status.idle": "2024-09-18T12:58:55.679295Z",
     "shell.execute_reply": "2024-09-18T12:58:55.679240Z",
     "shell.execute_reply.started": "2024-09-18T12:58:55.679235Z"
    }
   },
   "outputs": [],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '3-1!B6:E6'  \n",
    "\n",
    "values = [[\n",
    "    f\"{adjusted_precision * 100:.2f}\",\n",
    "    f\"{adjusted_recall * 100:.2f}\",\n",
    "    f\"{adjusted_accuracy * 100:.2f}\",\n",
    "    f\"{adjusted_f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24614471-4cf3-4349-b8bb-98715c2db8a9",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5a4d67-5a7a-4f32-b9c4-6f5c7612a256",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-18T12:58:55.679786Z",
     "iopub.status.idle": "2024-09-18T12:58:55.679876Z",
     "shell.execute_reply": "2024-09-18T12:58:55.679826Z",
     "shell.execute_reply.started": "2024-09-18T12:58:55.679822Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "precision = precision_score(y_test, svm_final_predictions, average='macro')\n",
    "recall = recall_score(y_test, svm_final_predictions, average='macro')\n",
    "accuracy = accuracy_score(y_test, svm_final_predictions)\n",
    "f1 = f1_score(y_test, svm_final_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_test, svm_final_predictions)\n",
    "\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Ensemble accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4bf24f-5e38-4acf-b0d1-c42ddb5a862f",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-18T12:58:55.680566Z",
     "iopub.status.idle": "2024-09-18T12:58:55.680661Z",
     "shell.execute_reply": "2024-09-18T12:58:55.680608Z",
     "shell.execute_reply.started": "2024-09-18T12:58:55.680604Z"
    }
   },
   "outputs": [],
   "source": [
    "probabilities = svm_meta_classifier.predict_proba(test_meta_features)\n",
    "\n",
    "# Calculate precision-recall curve and find optimal thresholds for each class\n",
    "svm_thresh = []\n",
    "for i in range(probabilities.shape[1]):  # Iterate over each class\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test == i, probabilities[:, i])\n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "    optimal_idx = np.nanargmax(f1_scores)  # Handle cases where precision and recall are both zero\n",
    "    svm_thresh.append(thresholds[optimal_idx])\n",
    "\n",
    "# Apply the optimized thresholds to make adjusted predictions\n",
    "adjusted_predictions = np.array([np.argmax([probabilities[i, j] if probabilities[i, j] >= svm_thresh[j] else 0\n",
    "                                         for j in range(probabilities.shape[1])])\n",
    "                              for i in range(len(probabilities))])\n",
    "\n",
    "# Evaluate\n",
    "adjusted_precision = precision_score(y_test, adjusted_predictions, average='macro')\n",
    "adjusted_recall = recall_score(y_test, adjusted_predictions, average='macro')\n",
    "adjusted_accuracy = accuracy_score(y_test, adjusted_predictions)\n",
    "adjusted_f1 = f1_score(y_test, adjusted_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_test, adjusted_predictions)\n",
    "\n",
    "print(\"Optimized thresholds for each class:\", svm_thresh)\n",
    "print(\"SVM\")\n",
    "print(f\"Precision: {adjusted_precision:.4f}\")\n",
    "print(f\"Recall: {adjusted_recall:.4f}\")\n",
    "print(f\"Ensemble accuracy: {adjusted_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {adjusted_f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fc2377-f91b-4712-8903-70c3009db9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(probabilities.shape[1]):  # For each class\n",
    "    plt.hist(probabilities[:, i], bins=50, alpha=0.5, label=f'Class {i}')\n",
    "plt.title('Distribution of Predicted Probabilities for Each Class')\n",
    "plt.xlabel('Predicted Probability')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92382252-0d77-45d8-bb20-8c5c7f2a983b",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-18T12:58:55.680913Z",
     "iopub.status.idle": "2024-09-18T12:58:55.681011Z",
     "shell.execute_reply": "2024-09-18T12:58:55.680958Z",
     "shell.execute_reply.started": "2024-09-18T12:58:55.680953Z"
    }
   },
   "outputs": [],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '3-1!B7:E7'  \n",
    "\n",
    "values = [[\n",
    "    f\"{adjusted_precision * 100:.2f}\",\n",
    "    f\"{adjusted_recall * 100:.2f}\",\n",
    "    f\"{adjusted_accuracy * 100:.2f}\",\n",
    "    f\"{adjusted_f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0143f6-14c3-431a-b08b-7f182a0c7c96",
   "metadata": {},
   "source": [
    "## TEST DATA C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a7c1fca-bf56-43cf-8559-e8acfd5dc262",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-18T13:21:22.438034Z",
     "iopub.status.busy": "2024-09-18T13:21:22.437560Z",
     "iopub.status.idle": "2024-09-18T13:21:36.518623Z",
     "shell.execute_reply": "2024-09-18T13:21:36.518196Z",
     "shell.execute_reply.started": "2024-09-18T13:21:22.438015Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Load validation data\n",
    "validation_file_path = 'Corpus/FiReCS/FiReCS_data_c.csv'\n",
    "validation_df = pd.read_csv(validation_file_path)\n",
    "\n",
    "X_val = validation_df['review'].values \n",
    "y_val = validation_df['label'].values\n",
    "\n",
    "# Generate meta-features for data c dataset\n",
    "val_meta_features = get_predictions(models_and_tokenizers, X_val, y_val, device) \n",
    "\n",
    "# Predict using the logistic regression meta-classifier\n",
    "val_lr_predictions = lr_meta_classifier.predict(val_meta_features)\n",
    "\n",
    "# Predict using the naive bayes meta-classifier\n",
    "val_nb_predictions = nb_meta_classifier.predict(val_meta_features)\n",
    "\n",
    "# Predict using the decision tree meta-classifier\n",
    "val_dt_predictions = dt_meta_classifier.predict(val_meta_features)\n",
    "\n",
    "# Predict using the svm meta-classifier\n",
    "val_svm_predictions = svm_meta_classifier.predict(val_meta_features)\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0693ac-17b2-4645-be71-fe4c1f337e38",
   "metadata": {},
   "source": [
    "### LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5303f868-1507-4252-9f50-136aa337f630",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-18T13:21:36.519415Z",
     "iopub.status.busy": "2024-09-18T13:21:36.519334Z",
     "iopub.status.idle": "2024-09-18T13:21:36.524381Z",
     "shell.execute_reply": "2024-09-18T13:21:36.524128Z",
     "shell.execute_reply.started": "2024-09-18T13:21:36.519408Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on HS-Data C Dataset\n",
      "Precision: 0.8310362970545816\n",
      "Recall: 0.8198820434379325\n",
      "Accuracy: 0.8198284080076264\n",
      "F1 Score: 0.823411104262168\n",
      "Confusion Matrix:\n",
      "[[277  62   2]\n",
      " [ 41 297  26]\n",
      " [  1  57 286]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the predictions\n",
    "precision = precision_score(y_val, val_lr_predictions, average='macro')\n",
    "recall = recall_score(y_val, val_lr_predictions, average='macro')\n",
    "accuracy = accuracy_score(y_val, val_lr_predictions)\n",
    "f1 = f1_score(y_val, val_lr_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_val, val_lr_predictions)\n",
    "\n",
    "print(\"Evaluation on HS-Data C Dataset\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d732e24d-540c-4934-a359-e7098db0eaaf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-18T13:21:36.524887Z",
     "iopub.status.busy": "2024-09-18T13:21:36.524818Z",
     "iopub.status.idle": "2024-09-18T13:21:36.532647Z",
     "shell.execute_reply": "2024-09-18T13:21:36.532399Z",
     "shell.execute_reply.started": "2024-09-18T13:21:36.524881Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results\n",
      "Precision: 0.8321\n",
      "Recall: 0.8198\n",
      "Accuracy: 0.8198\n",
      "F1 Score: 0.8236\n",
      "Confusion Matrix:\n",
      "[[277  62   2]\n",
      " [ 41 299  24]\n",
      " [  1  59 284]]\n"
     ]
    }
   ],
   "source": [
    "lr_validation_probabilities = lr_meta_classifier.predict_proba(val_meta_features)\n",
    "\n",
    "# Apply thresholds to the validation set probabilities to make final predictions\n",
    "lr_validation_predictions = np.array([np.argmax([lr_validation_probabilities[i, j] if lr_validation_probabilities[i, j] >= lr_thresh[j] else 0\n",
    "                                              for j in range(lr_validation_probabilities.shape[1])])\n",
    "                                   for i in range(len(lr_validation_probabilities))])\n",
    "\n",
    "# Evaluate threshold on validation set\n",
    "adjusted_precision = precision_score(y_val, lr_validation_predictions, average='macro')\n",
    "adjusted_recall = recall_score(y_val, lr_validation_predictions, average='macro')\n",
    "adjusted_accuracy = accuracy_score(y_val, lr_validation_predictions)\n",
    "adjusted_f1 = f1_score(y_val, lr_validation_predictions, average='macro')\n",
    "adjusted_conf_matrix = confusion_matrix(y_val, lr_validation_predictions)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Validation Results\")\n",
    "print(f\"Precision: {adjusted_precision:.4f}\")\n",
    "print(f\"Recall: {adjusted_recall:.4f}\")\n",
    "print(f\"Accuracy: {adjusted_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {adjusted_f1:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(adjusted_conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35d847f4-0bc4-4f4f-a1ff-22d5d990820f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-18T13:21:36.533588Z",
     "iopub.status.busy": "2024-09-18T13:21:36.533506Z",
     "iopub.status.idle": "2024-09-18T13:21:37.789730Z",
     "shell.execute_reply": "2024-09-18T13:21:37.788948Z",
     "shell.execute_reply.started": "2024-09-18T13:21:36.533581Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated cells count: 4\n"
     ]
    }
   ],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '3-1!F4:I4'  \n",
    "\n",
    "values = [[\n",
    "    f\"{adjusted_precision * 100:.2f}\",\n",
    "    f\"{adjusted_recall * 100:.2f}\",\n",
    "    f\"{adjusted_accuracy * 100:.2f}\",\n",
    "    f\"{adjusted_f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d20e88-5a01-4b56-ad36-37c984d10277",
   "metadata": {},
   "source": [
    "#### Save CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ca78187-3e76-4798-b348-64b200b29eb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-18T13:25:03.089951Z",
     "iopub.status.busy": "2024-09-18T13:25:03.089252Z",
     "iopub.status.idle": "2024-09-18T13:25:03.155508Z",
     "shell.execute_reply": "2024-09-18T13:25:03.155136Z",
     "shell.execute_reply.started": "2024-09-18T13:25:03.089912Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-d2dbaca72e054d3dbad0fa0441be6583.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-d2dbaca72e054d3dbad0fa0441be6583.vega-embed details,\n",
       "  #altair-viz-d2dbaca72e054d3dbad0fa0441be6583.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-d2dbaca72e054d3dbad0fa0441be6583\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-d2dbaca72e054d3dbad0fa0441be6583\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-d2dbaca72e054d3dbad0fa0441be6583\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"rect\"}, \"encoding\": {\"color\": {\"field\": \"Count\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"True\", \"type\": \"ordinal\"}, {\"field\": \"Predicted\", \"type\": \"ordinal\"}, {\"field\": \"Count\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Predicted\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}, \"y\": {\"field\": \"True\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}}, \"title\": \"OF_Using_FIRE 3STK-1 LR\"}, {\"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"middle\", \"fontSize\": 12}, \"encoding\": {\"color\": {\"condition\": {\"test\": \"(datum.Count > 149.5)\", \"value\": \"white\"}, \"value\": \"black\"}, \"text\": {\"field\": \"Count\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"True\", \"type\": \"ordinal\"}, {\"field\": \"Predicted\", \"type\": \"ordinal\"}, {\"field\": \"Count\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Predicted\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}, \"y\": {\"field\": \"True\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}}, \"title\": \"OF_Using_FIRE 3STK-1 LR\"}], \"data\": {\"name\": \"data-5da77d512ad13194d1011a627e057c95\"}, \"height\": 300, \"width\": 400, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-5da77d512ad13194d1011a627e057c95\": [{\"True\": \"Negative\", \"Predicted\": \"Negative\", \"Count\": 277}, {\"True\": \"Neutral\", \"Predicted\": \"Negative\", \"Count\": 41}, {\"True\": \"Positive\", \"Predicted\": \"Negative\", \"Count\": 1}, {\"True\": \"Negative\", \"Predicted\": \"Neutral\", \"Count\": 62}, {\"True\": \"Neutral\", \"Predicted\": \"Neutral\", \"Count\": 299}, {\"True\": \"Positive\", \"Predicted\": \"Neutral\", \"Count\": 59}, {\"True\": \"Negative\", \"Predicted\": \"Positive\", \"Count\": 2}, {\"True\": \"Neutral\", \"Predicted\": \"Positive\", \"Count\": 24}, {\"True\": \"Positive\", \"Predicted\": \"Positive\", \"Count\": 284}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import altair as alt\n",
    "import altair_saver\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_val, lr_validation_predictions)\n",
    "\n",
    "# Define class names\n",
    "class_names = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "# Convert confusion matrix to DataFrame\n",
    "cm_df = pd.DataFrame(cm, index=class_names, columns=class_names).reset_index().melt(id_vars='index')\n",
    "cm_df.columns = ['True', 'Predicted', 'Count']\n",
    "\n",
    "# Ensure the order of categories\n",
    "cm_df['True'] = pd.Categorical(cm_df['True'], categories=class_names, ordered=True)\n",
    "cm_df['Predicted'] = pd.Categorical(cm_df['Predicted'], categories=class_names, ordered=True)\n",
    "\n",
    "# Create the Altair plot\n",
    "heatmap = alt.Chart(cm_df).mark_rect().encode(\n",
    "    x=alt.X('Predicted:O', sort=class_names),\n",
    "    y=alt.Y('True:O', sort=class_names),\n",
    "    color='Count:Q',\n",
    "    tooltip=['True', 'Predicted', 'Count']\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=300,\n",
    "    title='OF_Using_FIRE 3STK-1 LR'\n",
    ")\n",
    "\n",
    "# Add text labels\n",
    "text = heatmap.mark_text(\n",
    "    align='center',\n",
    "    baseline='middle',\n",
    "    fontSize=12\n",
    ").encode(\n",
    "    text='Count:Q',\n",
    "    color=alt.condition(\n",
    "        alt.datum.Count > cm.max() / 2,\n",
    "        alt.value('white'),\n",
    "        alt.value('black')\n",
    "    )\n",
    ")\n",
    "\n",
    "# Combine heatmap and text\n",
    "final_chart = heatmap + text\n",
    "\n",
    "# Display the plot\n",
    "final_chart.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4018e7ba-2de6-44d9-9a6f-bf13ccb33108",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-18T12:58:55.684102Z",
     "iopub.status.idle": "2024-09-18T12:58:55.684203Z",
     "shell.execute_reply": "2024-09-18T12:58:55.684149Z",
     "shell.execute_reply.started": "2024-09-18T12:58:55.684145Z"
    }
   },
   "outputs": [],
   "source": [
    "# Specify the folder path\n",
    "folder_path = os.path.expanduser('Results/Ensemble Model Results/On FireCS dataset/OF Using FIRE ENSEMBLE/Stacking/')\n",
    "\n",
    "# Save the plot using vl-convert\n",
    "file_path_png = os.path.join(folder_path, 'OF_Using_FIRE 3STK-1 LR.png')\n",
    "final_chart.save(file_path_png)\n",
    "\n",
    "print(f\"Plot saved to {file_path_png}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e3bc0f-597f-47e3-ba99-5d9cafd1aea3",
   "metadata": {},
   "source": [
    "### NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af5051f-834f-4646-afef-37bfdfdc43d3",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-18T12:58:55.684670Z",
     "iopub.status.idle": "2024-09-18T12:58:55.684783Z",
     "shell.execute_reply": "2024-09-18T12:58:55.684727Z",
     "shell.execute_reply.started": "2024-09-18T12:58:55.684722Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate the predictions\n",
    "precision = precision_score(y_val, val_nb_predictions, average='macro')\n",
    "recall = recall_score(y_val, val_nb_predictions, average='macro')\n",
    "accuracy = accuracy_score(y_val, val_nb_predictions)\n",
    "f1 = f1_score(y_val, val_nb_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_val, val_nb_predictions)\n",
    "\n",
    "print(\"Evaluation on HS-Data C Dataset\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1acd42b-ca2c-40be-b90e-e7fb7f6eeb2a",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-18T12:58:55.686030Z",
     "iopub.status.idle": "2024-09-18T12:58:55.686127Z",
     "shell.execute_reply": "2024-09-18T12:58:55.686073Z",
     "shell.execute_reply.started": "2024-09-18T12:58:55.686069Z"
    }
   },
   "outputs": [],
   "source": [
    "nb_validation_probabilities = nb_meta_classifier.predict_proba(val_meta_features)\n",
    "\n",
    "# Apply thresholds to the validation set probabilities to make final predictions\n",
    "nb_validation_predictions = np.array([np.argmax([nb_validation_probabilities[i, j] if nb_validation_probabilities[i, j] >= nb_thresh[j] else 0\n",
    "                                              for j in range(nb_validation_probabilities.shape[1])])\n",
    "                                   for i in range(len(nb_validation_probabilities))])\n",
    "\n",
    "# Evaluate threshold on validation set\n",
    "adjusted_precision = precision_score(y_val, nb_validation_predictions, average='macro')\n",
    "adjusted_recall = recall_score(y_val, nb_validation_predictions, average='macro')\n",
    "adjusted_accuracy = accuracy_score(y_val, nb_validation_predictions)\n",
    "adjusted_f1 = f1_score(y_val, nb_validation_predictions, average='macro')\n",
    "adjusted_conf_matrix = confusion_matrix(y_val, nb_validation_predictions)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Validation Results\")\n",
    "print(f\"Precision: {adjusted_precision:.4f}\")\n",
    "print(f\"Recall: {adjusted_recall:.4f}\")\n",
    "print(f\"Accuracy: {adjusted_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {adjusted_f1:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(adjusted_conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5b7918-e4a2-4fd5-bfc3-74bb308a085b",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-18T12:58:55.686598Z",
     "iopub.status.idle": "2024-09-18T12:58:55.686692Z",
     "shell.execute_reply": "2024-09-18T12:58:55.686640Z",
     "shell.execute_reply.started": "2024-09-18T12:58:55.686637Z"
    }
   },
   "outputs": [],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '3-1!F5:I5'  \n",
    "\n",
    "values = [[\n",
    "    f\"{adjusted_precision * 100:.2f}\",\n",
    "    f\"{adjusted_recall * 100:.2f}\",\n",
    "    f\"{adjusted_accuracy * 100:.2f}\",\n",
    "    f\"{adjusted_f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65529983-86a3-4c32-b155-c08fcdf20b31",
   "metadata": {},
   "source": [
    "#### Save CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea993771-7e1b-4a65-8e32-29912f2564d0",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-18T12:58:55.687043Z",
     "iopub.status.idle": "2024-09-18T12:58:55.687219Z",
     "shell.execute_reply": "2024-09-18T12:58:55.687090Z",
     "shell.execute_reply.started": "2024-09-18T12:58:55.687085Z"
    }
   },
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "import altair_saver\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_val, nb_validation_predictions)\n",
    "\n",
    "# Define class names\n",
    "class_names = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "# Convert confusion matrix to DataFrame\n",
    "cm_df = pd.DataFrame(cm, index=class_names, columns=class_names).reset_index().melt(id_vars='index')\n",
    "cm_df.columns = ['True', 'Predicted', 'Count']\n",
    "\n",
    "# Ensure the order of categories\n",
    "cm_df['True'] = pd.Categorical(cm_df['True'], categories=class_names, ordered=True)\n",
    "cm_df['Predicted'] = pd.Categorical(cm_df['Predicted'], categories=class_names, ordered=True)\n",
    "\n",
    "# Create the Altair plot\n",
    "heatmap = alt.Chart(cm_df).mark_rect().encode(\n",
    "    x=alt.X('Predicted:O', sort=class_names),\n",
    "    y=alt.Y('True:O', sort=class_names),\n",
    "    color='Count:Q',\n",
    "    tooltip=['True', 'Predicted', 'Count']\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=300,\n",
    "    title='OF_Using_FIRE 3STK-1 NB'\n",
    ")\n",
    "\n",
    "# Add text labels\n",
    "text = heatmap.mark_text(\n",
    "    align='center',\n",
    "    baseline='middle',\n",
    "    fontSize=12\n",
    ").encode(\n",
    "    text='Count:Q',\n",
    "    color=alt.condition(\n",
    "        alt.datum.Count > cm.max() / 2,\n",
    "        alt.value('white'),\n",
    "        alt.value('black')\n",
    "    )\n",
    ")\n",
    "\n",
    "# Combine heatmap and text\n",
    "final_chart = heatmap + text\n",
    "\n",
    "# Display the plot\n",
    "final_chart.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031b9ce6-7d92-4735-a298-e8f7812ebae0",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-18T12:58:55.687876Z",
     "iopub.status.idle": "2024-09-18T12:58:55.687982Z",
     "shell.execute_reply": "2024-09-18T12:58:55.687928Z",
     "shell.execute_reply.started": "2024-09-18T12:58:55.687924Z"
    }
   },
   "outputs": [],
   "source": [
    "# Specify the folder path\n",
    "folder_path = os.path.expanduser('Results/Ensemble Model Results/On FireCS dataset/OF Using FIRE ENSEMBLE/Stacking/')\n",
    "\n",
    "# Save the plot using vl-convert\n",
    "file_path_png = os.path.join(folder_path, 'OF_Using_FIRE 3STK-1 NB.png')\n",
    "final_chart.save(file_path_png)\n",
    "\n",
    "print(f\"Plot saved to {file_path_png}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba2269b-62c4-43d2-8394-9aa3c1a27678",
   "metadata": {},
   "source": [
    "### DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0448f107-62d6-4f1a-8b04-4378b79f3d3d",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-18T12:58:55.688548Z",
     "iopub.status.idle": "2024-09-18T12:58:55.688646Z",
     "shell.execute_reply": "2024-09-18T12:58:55.688593Z",
     "shell.execute_reply.started": "2024-09-18T12:58:55.688590Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate the predictions\n",
    "precision = precision_score(y_val, val_dt_predictions, average='macro')\n",
    "recall = recall_score(y_val, val_dt_predictions, average='macro')\n",
    "accuracy = accuracy_score(y_val, val_dt_predictions)\n",
    "f1 = f1_score(y_val, val_dt_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_val, val_dt_predictions)\n",
    "\n",
    "print(\"Evaluation on HS-Data C Dataset\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0f105d-eb8f-4450-9d41-d90c97cf028c",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-18T12:58:55.689662Z",
     "iopub.status.idle": "2024-09-18T12:58:55.689789Z",
     "shell.execute_reply": "2024-09-18T12:58:55.689731Z",
     "shell.execute_reply.started": "2024-09-18T12:58:55.689723Z"
    }
   },
   "outputs": [],
   "source": [
    "dt_validation_probabilities = dt_meta_classifier.predict_proba(val_meta_features)\n",
    "\n",
    "# Apply thresholds to the validation set probabilities to make final predictions\n",
    "dt_validation_predictions = np.array([np.argmax([dt_validation_probabilities[i, j] if dt_validation_probabilities[i, j] >= dt_thresh[j] else 0\n",
    "                                              for j in range(dt_validation_probabilities.shape[1])])\n",
    "                                   for i in range(len(dt_validation_probabilities))])\n",
    "\n",
    "# Evaluate threshold on validation set\n",
    "adjusted_precision = precision_score(y_val, dt_validation_predictions, average='macro')\n",
    "adjusted_recall = recall_score(y_val, dt_validation_predictions, average='macro')\n",
    "adjusted_accuracy = accuracy_score(y_val, dt_validation_predictions)\n",
    "adjusted_f1 = f1_score(y_val, dt_validation_predictions, average='macro')\n",
    "adjusted_conf_matrix = confusion_matrix(y_val, dt_validation_predictions)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Validation Results\")\n",
    "print(f\"Precision: {adjusted_precision:.4f}\")\n",
    "print(f\"Recall: {adjusted_recall:.4f}\")\n",
    "print(f\"Accuracy: {adjusted_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {adjusted_f1:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(adjusted_conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec85bf2-3044-4247-90ec-703089be962b",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-18T12:58:55.690297Z",
     "iopub.status.idle": "2024-09-18T12:58:55.690397Z",
     "shell.execute_reply": "2024-09-18T12:58:55.690340Z",
     "shell.execute_reply.started": "2024-09-18T12:58:55.690337Z"
    }
   },
   "outputs": [],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '3-1!F6:I6'  \n",
    "\n",
    "values = [[\n",
    "    f\"{adjusted_precision * 100:.2f}\",\n",
    "    f\"{adjusted_recall * 100:.2f}\",\n",
    "    f\"{adjusted_accuracy * 100:.2f}\",\n",
    "    f\"{adjusted_f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8589d71-c489-4214-9c56-4a3a7ed69506",
   "metadata": {},
   "source": [
    "#### Save CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb07bbd3-2021-4e16-8b59-3908f095b7cf",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-18T12:58:55.690805Z",
     "iopub.status.idle": "2024-09-18T12:58:55.690910Z",
     "shell.execute_reply": "2024-09-18T12:58:55.690850Z",
     "shell.execute_reply.started": "2024-09-18T12:58:55.690846Z"
    }
   },
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "import altair_saver\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_val, dt_validation_predictions)\n",
    "\n",
    "# Define class names\n",
    "class_names = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "# Convert confusion matrix to DataFrame\n",
    "cm_df = pd.DataFrame(cm, index=class_names, columns=class_names).reset_index().melt(id_vars='index')\n",
    "cm_df.columns = ['True', 'Predicted', 'Count']\n",
    "\n",
    "# Ensure the order of categories\n",
    "cm_df['True'] = pd.Categorical(cm_df['True'], categories=class_names, ordered=True)\n",
    "cm_df['Predicted'] = pd.Categorical(cm_df['Predicted'], categories=class_names, ordered=True)\n",
    "\n",
    "# Create the Altair plot\n",
    "heatmap = alt.Chart(cm_df).mark_rect().encode(\n",
    "    x=alt.X('Predicted:O', sort=class_names),\n",
    "    y=alt.Y('True:O', sort=class_names),\n",
    "    color='Count:Q',\n",
    "    tooltip=['True', 'Predicted', 'Count']\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=300,\n",
    "    title='OF_Using_FIRE 3STK-1 DT'\n",
    ")\n",
    "\n",
    "# Add text labels\n",
    "text = heatmap.mark_text(\n",
    "    align='center',\n",
    "    baseline='middle',\n",
    "    fontSize=12\n",
    ").encode(\n",
    "    text='Count:Q',\n",
    "    color=alt.condition(\n",
    "        alt.datum.Count > cm.max() / 2,\n",
    "        alt.value('white'),\n",
    "        alt.value('black')\n",
    "    )\n",
    ")\n",
    "\n",
    "# Combine heatmap and text\n",
    "final_chart = heatmap + text\n",
    "\n",
    "# Display the plot\n",
    "final_chart.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5445e621-6288-4a87-9e75-bf4511b2d9a7",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-18T12:58:55.691424Z",
     "iopub.status.idle": "2024-09-18T12:58:55.691529Z",
     "shell.execute_reply": "2024-09-18T12:58:55.691474Z",
     "shell.execute_reply.started": "2024-09-18T12:58:55.691471Z"
    }
   },
   "outputs": [],
   "source": [
    "# Specify the folder path\n",
    "folder_path = os.path.expanduser('Results/Ensemble Model Results/On FireCS dataset/OF Using FIRE ENSEMBLE/Stacking/')\n",
    "\n",
    "# Save the plot using vl-convert\n",
    "file_path_png = os.path.join(folder_path, 'OF_Using_FIRE 3STK-1 DT.png')\n",
    "final_chart.save(file_path_png)\n",
    "\n",
    "print(f\"Plot saved to {file_path_png}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6165ef-d0ff-4230-9fdb-3c6a774d728f",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660f90df-3de4-41b1-9fc6-4285133ec0a8",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-18T12:58:55.691824Z",
     "iopub.status.idle": "2024-09-18T12:58:55.691912Z",
     "shell.execute_reply": "2024-09-18T12:58:55.691866Z",
     "shell.execute_reply.started": "2024-09-18T12:58:55.691862Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate the predictions\n",
    "precision = precision_score(y_val, val_svm_predictions, average='macro')\n",
    "recall = recall_score(y_val, val_svm_predictions, average='macro')\n",
    "accuracy = accuracy_score(y_val, val_svm_predictions)\n",
    "f1 = f1_score(y_val, val_svm_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_val, val_svm_predictions)\n",
    "\n",
    "print(\"Evaluation on HS-Data C Dataset\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2fba87-04de-46b7-bc1d-1fbf7d1bb263",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-18T12:58:55.692651Z",
     "iopub.status.idle": "2024-09-18T12:58:55.692772Z",
     "shell.execute_reply": "2024-09-18T12:58:55.692701Z",
     "shell.execute_reply.started": "2024-09-18T12:58:55.692697Z"
    }
   },
   "outputs": [],
   "source": [
    "svm_validation_probabilities = svm_meta_classifier.predict_proba(val_meta_features)\n",
    "\n",
    "# Apply thresholds to the validation set probabilities to make final predictions\n",
    "svm_validation_predictions = np.array([np.argmax([svm_validation_probabilities[i, j] if svm_validation_probabilities[i, j] >= svm_thresh[j] else 0\n",
    "                                              for j in range(svm_validation_probabilities.shape[1])])\n",
    "                                   for i in range(len(svm_validation_probabilities))])\n",
    "\n",
    "# Evaluate threshold on validation set\n",
    "adjusted_precision = precision_score(y_val, svm_validation_predictions, average='macro')\n",
    "adjusted_recall = recall_score(y_val, svm_validation_predictions, average='macro')\n",
    "adjusted_accuracy = accuracy_score(y_val, svm_validation_predictions)\n",
    "adjusted_f1 = f1_score(y_val, svm_validation_predictions, average='macro')\n",
    "adjusted_conf_matrix = confusion_matrix(y_val, svm_validation_predictions)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Validation Results\")\n",
    "print(f\"Precision: {adjusted_precision:.4f}\")\n",
    "print(f\"Recall: {adjusted_recall:.4f}\")\n",
    "print(f\"Accuracy: {adjusted_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {adjusted_f1:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(adjusted_conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7644868d-4140-415e-be20-4db4bfbf21b7",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-18T12:58:55.693162Z",
     "iopub.status.idle": "2024-09-18T12:58:55.693472Z",
     "shell.execute_reply": "2024-09-18T12:58:55.693373Z",
     "shell.execute_reply.started": "2024-09-18T12:58:55.693366Z"
    }
   },
   "outputs": [],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '3-1!F7:I7'  \n",
    "\n",
    "values = [[\n",
    "    f\"{adjusted_precision * 100:.2f}\",\n",
    "    f\"{adjusted_recall * 100:.2f}\",\n",
    "    f\"{adjusted_accuracy * 100:.2f}\",\n",
    "    f\"{adjusted_f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682be1a4-7bf8-4e44-9da2-2b7f48eac91c",
   "metadata": {},
   "source": [
    "#### Save CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939272d5-856b-49da-99a2-4a25d818d2ea",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-18T12:58:55.693998Z",
     "iopub.status.idle": "2024-09-18T12:58:55.694124Z",
     "shell.execute_reply": "2024-09-18T12:58:55.694059Z",
     "shell.execute_reply.started": "2024-09-18T12:58:55.694056Z"
    }
   },
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "import altair_saver\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_val, svm_validation_predictions)\n",
    "\n",
    "# Define class names\n",
    "class_names = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "# Convert confusion matrix to DataFrame\n",
    "cm_df = pd.DataFrame(cm, index=class_names, columns=class_names).reset_index().melt(id_vars='index')\n",
    "cm_df.columns = ['True', 'Predicted', 'Count']\n",
    "\n",
    "# Ensure the order of categories\n",
    "cm_df['True'] = pd.Categorical(cm_df['True'], categories=class_names, ordered=True)\n",
    "cm_df['Predicted'] = pd.Categorical(cm_df['Predicted'], categories=class_names, ordered=True)\n",
    "\n",
    "# Create the Altair plot\n",
    "heatmap = alt.Chart(cm_df).mark_rect().encode(\n",
    "    x=alt.X('Predicted:O', sort=class_names),\n",
    "    y=alt.Y('True:O', sort=class_names),\n",
    "    color='Count:Q',\n",
    "    tooltip=['True', 'Predicted', 'Count']\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=300,\n",
    "    title='OF_Using_FIRE 3STK-1 SVM'\n",
    ")\n",
    "\n",
    "# Add text labels\n",
    "text = heatmap.mark_text(\n",
    "    align='center',\n",
    "    baseline='middle',\n",
    "    fontSize=12\n",
    ").encode(\n",
    "    text='Count:Q',\n",
    "    color=alt.condition(\n",
    "        alt.datum.Count > cm.max() / 2,\n",
    "        alt.value('white'),\n",
    "        alt.value('black')\n",
    "    )\n",
    ")\n",
    "\n",
    "# Combine heatmap and text\n",
    "final_chart = heatmap + text\n",
    "\n",
    "# Display the plot\n",
    "final_chart.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab1dbec-94d8-4f9c-b5e8-843b853a71cb",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-18T12:58:55.694674Z",
     "iopub.status.idle": "2024-09-18T12:58:55.694789Z",
     "shell.execute_reply": "2024-09-18T12:58:55.694727Z",
     "shell.execute_reply.started": "2024-09-18T12:58:55.694724Z"
    }
   },
   "outputs": [],
   "source": [
    "# Specify the folder path\n",
    "folder_path = os.path.expanduser('Results/Ensemble Model Results/On FireCS dataset/OF Using FIRE ENSEMBLE/Stacking/')\n",
    "\n",
    "# Save the plot using vl-convert\n",
    "file_path_png = os.path.join(folder_path, 'OF_Using_FIRE 3STK-1 SVM.png')\n",
    "final_chart.save(file_path_png)\n",
    "\n",
    "print(f\"Plot saved to {file_path_png}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a298f212-36ec-4e75-ad74-d7b272d094a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80391c9f-64d7-4e98-b9f0-6ee41cb035f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
