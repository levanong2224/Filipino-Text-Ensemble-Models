{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dc06b17-fcee-4505-bd74-d98376ce3ed9",
   "metadata": {},
   "source": [
    "# Train Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c6a724-b17e-46f6-aee6-90ef2f7877a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T15:08:53.465538Z",
     "iopub.status.busy": "2024-08-13T15:08:53.465321Z",
     "iopub.status.idle": "2024-08-13T15:08:53.469076Z",
     "shell.execute_reply": "2024-08-13T15:08:53.468592Z",
     "shell.execute_reply.started": "2024-08-13T15:08:53.465526Z"
    }
   },
   "source": [
    "Best F1 score BERT model on HS_C dataset are used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3823c3e6-976a-4eb9-a651-2cfeaa1a3cc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T12:39:46.070071Z",
     "iopub.status.busy": "2024-09-09T12:39:46.069965Z",
     "iopub.status.idle": "2024-09-09T12:39:46.189950Z",
     "shell.execute_reply": "2024-09-09T12:39:46.189688Z",
     "shell.execute_reply.started": "2024-09-09T12:39:46.070061Z"
    }
   },
   "outputs": [],
   "source": [
    "# This automates data tabulation onto google sheets \n",
    "\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "import os\n",
    "\n",
    "# new directory path\n",
    "new_directory = '/Users/levan/ATENEO MASTERAL/Thesis'\n",
    "\n",
    "# Change the current working directory\n",
    "os.chdir(new_directory)\n",
    "\n",
    "# Use creds to create a client to interact with the Google Drive API\n",
    "scope = ['https://spreadsheets.google.com/feeds','https://www.googleapis.com/auth/drive']\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_name('thesis-432315-12daec8d1ff6.json', scope)\n",
    "\n",
    "service = build('sheets', 'v4', credentials=creds)\n",
    "\n",
    "client = gspread.authorize(creds)\n",
    "\n",
    "spreadsheet_id = '13Fk5oXX9B_mdHmNpMKQMy29y9iiHWrgQCa4hUTiQKD0' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d70bdb-0504-41ef-913d-e4b7f778f561",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7b193db-3f30-4e5f-a38b-c254bf1e1976",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T12:39:46.190451Z",
     "iopub.status.busy": "2024-09-09T12:39:46.190376Z",
     "iopub.status.idle": "2024-09-09T12:39:47.981498Z",
     "shell.execute_reply": "2024-09-09T12:39:47.981210Z",
     "shell.execute_reply.started": "2024-09-09T12:39:46.190445Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AutoConfig\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_recall_curve, f1_score, confusion_matrix, precision_score, recall_score, accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "# new directory path\n",
    "new_directory = '/Users/levan/ATENEO MASTERAL/Thesis/Development'\n",
    "\n",
    "# Change the current working directory\n",
    "os.chdir(new_directory)\n",
    "\n",
    "#Load Data\n",
    "df = pd.read_csv('Corpus/FiReCS/FiReCS_data_b.csv')\n",
    "X = df['review'].values\n",
    "y = df['label'].values\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a307e67b-00c3-47aa-8f83-34bc62c93f83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-11T10:08:58.783500Z",
     "iopub.status.busy": "2024-04-11T10:08:58.782872Z",
     "iopub.status.idle": "2024-04-11T10:08:58.788089Z",
     "shell.execute_reply": "2024-04-11T10:08:58.787147Z",
     "shell.execute_reply.started": "2024-04-11T10:08:58.783465Z"
    }
   },
   "source": [
    "## Load Models and Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e666f7e-9db0-4666-a112-2af127307162",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T12:39:47.982055Z",
     "iopub.status.busy": "2024-09-09T12:39:47.981937Z",
     "iopub.status.idle": "2024-09-09T12:39:54.097459Z",
     "shell.execute_reply": "2024-09-09T12:39:54.097200Z",
     "shell.execute_reply.started": "2024-09-09T12:39:47.982048Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_model_and_tokenizer(model_path, tokenizer_path, base_model):\n",
    "    # Load the tokenizer from the local directory\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "    \n",
    "    # Load the configuration from the base model, then update configuration if needed\n",
    "    config = AutoConfig.from_pretrained(base_model, num_labels=3)\n",
    "\n",
    "    # Initialize the model with the configuration\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_path, config=config)\n",
    "\n",
    "    # Ensure the model is in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    return model, tokenizer\n",
    "\n",
    "model_info = {\n",
    "    \n",
    "    'BERT cased': {\n",
    "        'model_path': 'BERT models/1 FiReCS/fire_bert-base-cased-finetuned',\n",
    "        'tokenizer_path': 'BERT models/1 FiReCS/fire_bert-base-cased-finetuned',\n",
    "        'base_model': 'google-bert/bert-base-cased'\n",
    "    },\n",
    "\n",
    "    'DistilBERT uncased': {\n",
    "        'model_path': 'BERT models/1 FiReCS/fire_distilbert-base-uncased-finetuned',\n",
    "        'tokenizer_path': 'BERT models/1 FiReCS/fire_distilbert-base-uncased-finetuned',\n",
    "        'base_model': 'distilbert/distilbert-base-uncased'\n",
    "    },\n",
    "\n",
    "    'DeBERTa': {\n",
    "        'model_path': 'BERT models/1 FiReCS/fire_DeBERTa-finetuned',\n",
    "        'tokenizer_path': 'BERT models/1 FiReCS/fire_DeBERTa-finetuned',\n",
    "        'base_model': 'microsoft/deberta-v3-base'\n",
    "    },\n",
    "    \n",
    "    'BERT uncased': {\n",
    "        'model_path': 'BERT models/1 FiReCS/fire_bert-base-uncased-finetuned',\n",
    "        'tokenizer_path': 'BERT models/1 FiReCS/fire_bert-base-uncased-finetuned',\n",
    "        'base_model': 'google-bert/bert-base-uncased'\n",
    "    },\n",
    "\n",
    "    'HateBERT': {\n",
    "        'model_path': 'BERT models/1 FiReCS/fire_HateBERT-finetuned',\n",
    "        'tokenizer_path': 'BERT models/1 FiReCS/fire_HateBERT-finetuned',\n",
    "        'base_model': 'GroNLP/hateBERT'\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "models_and_tokenizers = {name: load_model_and_tokenizer(info['model_path'], \n",
    "                                                        info['tokenizer_path'], \n",
    "                                                        info['base_model']) \n",
    "                         for name, info in model_info.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a9b906-a837-4de8-b8a2-05aa44074c5c",
   "metadata": {},
   "source": [
    "## Apply Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05f7b2f9-3bc4-4d6d-8595-8971899238c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T12:39:54.098016Z",
     "iopub.status.busy": "2024-09-09T12:39:54.097936Z",
     "iopub.status.idle": "2024-09-09T12:39:54.100744Z",
     "shell.execute_reply": "2024-09-09T12:39:54.100490Z",
     "shell.execute_reply.started": "2024-09-09T12:39:54.098009Z"
    }
   },
   "outputs": [],
   "source": [
    "class MultiModelTextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, labels, models_and_tokenizers, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.models_and_tokenizers = models_and_tokenizers\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.texts[index])\n",
    "        label = self.labels[index]\n",
    "\n",
    "        model_inputs = {}\n",
    "        for name, (model, tokenizer) in self.models_and_tokenizers.items():\n",
    "            encoding = tokenizer.encode_plus(\n",
    "                text,\n",
    "                add_special_tokens=True,\n",
    "                max_length=self.max_len,\n",
    "                return_token_type_ids=False,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                return_attention_mask=True,\n",
    "                return_tensors='pt',\n",
    "            )\n",
    "            model_inputs[name] = {\n",
    "                'input_ids': encoding['input_ids'].squeeze(0),  # Remove batch dimension\n",
    "                'attention_mask': encoding['attention_mask'].squeeze(0)  # Remove batch dimension\n",
    "            }\n",
    "        return {'model_inputs': model_inputs, 'label': torch.tensor(label, dtype=torch.long)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d574483-f790-48ba-a7d0-07cc8f2973d4",
   "metadata": {},
   "source": [
    "## BERT Training for Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e6167c5-79fd-4536-815c-237ec599453a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T12:39:54.101123Z",
     "iopub.status.busy": "2024-09-09T12:39:54.101056Z",
     "iopub.status.idle": "2024-09-09T12:39:54.104246Z",
     "shell.execute_reply": "2024-09-09T12:39:54.104045Z",
     "shell.execute_reply.started": "2024-09-09T12:39:54.101117Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_base_learner(model, data_loader, optimizer, device):\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    correct_predictions = 0\n",
    "    losses = []\n",
    "\n",
    "    for batch in data_loader:\n",
    "        # Accessing inputs for the current model\n",
    "        inputs = batch['model_inputs']\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        for model_name, model_inputs in inputs.items():\n",
    "            # Forward pass\n",
    "            outputs = model(input_ids=model_inputs['input_ids'].squeeze(1).to(device),\n",
    "                attention_mask=model_inputs['attention_mask'].squeeze(1).to(device),\n",
    "                labels=labels)\n",
    "\n",
    "            loss = outputs.loss\n",
    "            preds = outputs.logits.argmax(dim=1)\n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    return correct_predictions.float() / len(data_loader.dataset), np.mean(losses).astype(np.float32)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def eval_model(model, data_loader, device):\n",
    "    model = model.eval()\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for d in data_loader:\n",
    "            input_ids = d[\"input_ids\"].to(device)\n",
    "            attention_mask = d[\"attention_mask\"].to(device)\n",
    "            labels = d[\"label\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            preds = outputs.logits.argmax(dim=1)\n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "\n",
    "    return correct_predictions.double() / len(data_loader.dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b36fee-48a1-4eda-bf0b-c59982cbba14",
   "metadata": {},
   "source": [
    "## Train Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99eb6be0-fb6e-441b-bfaa-853e75a01983",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T12:39:54.105637Z",
     "iopub.status.busy": "2024-09-09T12:39:54.105543Z",
     "iopub.status.idle": "2024-09-09T12:39:54.121085Z",
     "shell.execute_reply": "2024-09-09T12:39:54.120805Z",
     "shell.execute_reply.started": "2024-09-09T12:39:54.105630Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, confusion_matrix\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "\n",
    "def train_stacking_classifier(models_and_tokenizers, X_train, y_train, device, max_len=128):\n",
    "    n_splits = 4\n",
    "    skf = StratifiedKFold(n_splits=n_splits)\n",
    "    base_learners_predictions_train = np.zeros((len(X_train), len(models_and_tokenizers)))\n",
    "    fold_idx = 0\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_train, y_train):\n",
    "        fold_idx += 1\n",
    "        print(f\"Training fold {fold_idx}/{n_splits}...\")\n",
    "        train_texts, val_texts = X_train[train_idx], X_train[val_idx]\n",
    "        train_labels, val_labels = y_train[train_idx], y_train[val_idx]\n",
    "        \n",
    "        model_idx = 0\n",
    "        for name, (model, tokenizer) in models_and_tokenizers.items():\n",
    "            train_dataset = MultiModelTextDataset(train_texts, train_labels, {name: (model, tokenizer)}, max_len)\n",
    "            val_dataset = MultiModelTextDataset(val_texts, val_labels, {name: (model, tokenizer)}, max_len)\n",
    "            train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "            \n",
    "            optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "            train_base_learner(model, train_loader, optimizer, device)\n",
    "            \n",
    "            val_preds = []\n",
    "            model.eval()\n",
    "            for batch in val_loader:\n",
    "                inputs = batch['model_inputs'][name]\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(input_ids=inputs['input_ids'].to(device), attention_mask=inputs['attention_mask'].to(device))\n",
    "                val_preds.extend(outputs.logits.argmax(dim=1).cpu().numpy())\n",
    "            \n",
    "            base_learners_predictions_train[val_idx, model_idx] = np.array(val_preds)\n",
    "            model_idx += 1\n",
    "\n",
    "    return base_learners_predictions_train, y_train\n",
    "\n",
    "def get_predictions(models_and_tokenizers, X, y, device, max_len=128):\n",
    "    predictions = np.zeros((len(X), len(models_and_tokenizers)))\n",
    "    model_idx = 0\n",
    "    for name, (model, tokenizer) in models_and_tokenizers.items():\n",
    "        dataset = MultiModelTextDataset(X, y, {name: (model, tokenizer)}, max_len)\n",
    "        loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
    "        \n",
    "        preds = []\n",
    "        model.eval()\n",
    "        for batch in loader:\n",
    "            inputs = batch['model_inputs'][name]\n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_ids=inputs['input_ids'].to(device), attention_mask=inputs['attention_mask'].to(device))\n",
    "            preds.extend(outputs.logits.argmax(dim=1).cpu().numpy())\n",
    "        \n",
    "        predictions[:, model_idx] = np.array(preds)\n",
    "        model_idx += 1\n",
    "\n",
    "    return predictions\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58472c03-8cb9-4a28-b8f3-fd5227c0e620",
   "metadata": {},
   "source": [
    "## Perform Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da0e67bd-3f57-4bf1-aa4e-1537a9132002",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T12:39:54.121688Z",
     "iopub.status.busy": "2024-09-09T12:39:54.121562Z",
     "iopub.status.idle": "2024-09-09T12:39:54.125407Z",
     "shell.execute_reply": "2024-09-09T12:39:54.125141Z",
     "shell.execute_reply.started": "2024-09-09T12:39:54.121681Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36436c2d-846d-46ab-ae3c-b36c5bdda6a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T12:39:54.125840Z",
     "iopub.status.busy": "2024-09-09T12:39:54.125769Z",
     "iopub.status.idle": "2024-09-09T13:03:05.208359Z",
     "shell.execute_reply": "2024-09-09T13:03:05.208066Z",
     "shell.execute_reply.started": "2024-09-09T12:39:54.125830Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/transformers/optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 2/4...\n",
      "Training fold 3/4...\n",
      "Training fold 4/4...\n",
      "peak memory: 2822.73 MiB, increment: 58.38 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# Train stacking classifier (using 4-fold cross validation for each BERT model) on Train Set and retrieve training meta-features\n",
    "train_meta_features, _ = train_stacking_classifier(models_and_tokenizers, X_train, y_train, device)\n",
    "\n",
    "# Generate predictions for the test set to be used as test meta-features\n",
    "test_meta_features = get_predictions(models_and_tokenizers, X_test, y_test, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d42e0b-1855-4774-8f83-599a6158e526",
   "metadata": {},
   "source": [
    "### Train LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "265a5311-c2a4-48a0-9f21-d803350fb89f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T13:03:05.209023Z",
     "iopub.status.busy": "2024-09-09T13:03:05.208941Z",
     "iopub.status.idle": "2024-09-09T13:03:06.061584Z",
     "shell.execute_reply": "2024-09-09T13:03:06.056332Z",
     "shell.execute_reply.started": "2024-09-09T13:03:05.209016Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1666.45 MiB, increment: 1.17 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "\n",
    "lr_meta_classifier = LogisticRegression()\n",
    "lr_meta_classifier.fit(train_meta_features, y_train)\n",
    "\n",
    "lr_final_predictions = lr_meta_classifier.predict(test_meta_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ea06bb-fab4-4f49-99e4-19680ec1b870",
   "metadata": {},
   "source": [
    "### Train NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "244b0f68-e401-4d18-913f-a3a153dd8104",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T13:03:06.062733Z",
     "iopub.status.busy": "2024-09-09T13:03:06.062582Z",
     "iopub.status.idle": "2024-09-09T13:03:07.392396Z",
     "shell.execute_reply": "2024-09-09T13:03:07.392008Z",
     "shell.execute_reply.started": "2024-09-09T13:03:06.062718Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1666.77 MiB, increment: 0.28 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "\n",
    "nb_meta_classifier = GaussianNB()\n",
    "nb_meta_classifier.fit(train_meta_features, y_train)\n",
    "\n",
    "nb_final_predictions = nb_meta_classifier.predict(test_meta_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e50604f-9bef-4db4-bf92-89f9d2874e89",
   "metadata": {},
   "source": [
    "### Train DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3990ca03-b860-4b65-97e7-47f551754ab7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T13:03:07.393203Z",
     "iopub.status.busy": "2024-09-09T13:03:07.393110Z",
     "iopub.status.idle": "2024-09-09T13:03:08.658176Z",
     "shell.execute_reply": "2024-09-09T13:03:08.657813Z",
     "shell.execute_reply.started": "2024-09-09T13:03:07.393194Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1667.27 MiB, increment: 0.50 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "\n",
    "dt_meta_classifier = DecisionTreeClassifier(max_depth=None)\n",
    "dt_meta_classifier.fit(train_meta_features, y_train)\n",
    "\n",
    "dt_final_predictions = dt_meta_classifier.predict(test_meta_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986bd8f0-b569-4eaf-8e13-a51529e871e6",
   "metadata": {},
   "source": [
    "### Train SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "460a4087-b343-4249-b794-db90baabf11c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T13:03:08.658984Z",
     "iopub.status.busy": "2024-09-09T13:03:08.658844Z",
     "iopub.status.idle": "2024-09-09T13:03:09.349701Z",
     "shell.execute_reply": "2024-09-09T13:03:09.349235Z",
     "shell.execute_reply.started": "2024-09-09T13:03:08.658972Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1697.95 MiB, increment: 30.69 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "\n",
    "svm_meta_classifier = SVC(kernel='linear', probability=True)\n",
    "svm_meta_classifier.fit(train_meta_features, y_train)\n",
    "\n",
    "svm_final_predictions = svm_meta_classifier.predict(test_meta_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad340b68-d07e-473a-bbc4-138ef8e0271a",
   "metadata": {},
   "source": [
    "## EVALUATE MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93ba0c5-a053-45fb-8e97-b09c67959bc8",
   "metadata": {},
   "source": [
    "### LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d015915-5eb9-4a73-9ef6-5fc1bd4d0e8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T13:03:09.350389Z",
     "iopub.status.busy": "2024-09-09T13:03:09.350304Z",
     "iopub.status.idle": "2024-09-09T13:03:09.356566Z",
     "shell.execute_reply": "2024-09-09T13:03:09.356339Z",
     "shell.execute_reply.started": "2024-09-09T13:03:09.350381Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Precision: 0.7787091366303437\n",
      "Recall: 0.8001722652885443\n",
      "Ensemble accuracy: 0.8010429201764941\n",
      "F1 Score: 0.7892948173322005\n",
      "Confusion Matrix:\n",
      "[[1068  264]\n",
      " [ 232  929]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "precision = precision_score(y_test, lr_final_predictions, average='macro')\n",
    "recall = recall_score(y_test, lr_final_predictions, average='macro')\n",
    "accuracy = accuracy_score(y_test, lr_final_predictions)\n",
    "f1 = f1_score(y_test, lr_final_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_test, lr_final_predictions)\n",
    "\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Ensemble accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8c650bc-c7b7-4f3d-b8c7-c415ed29f2f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T13:03:09.620625Z",
     "iopub.status.busy": "2024-09-09T13:03:09.620466Z",
     "iopub.status.idle": "2024-09-09T13:03:09.697533Z",
     "shell.execute_reply": "2024-09-09T13:03:09.697274Z",
     "shell.execute_reply.started": "2024-09-09T13:03:09.620613Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted threshold: 0.22\n",
      "Optimized Logistic Regression\n",
      "Precision: 0.7338709677419355\n",
      "Recall: 0.8621877691645133\n",
      "Accuracy: 0.7902125952667469\n",
      "F1 Score: 0.7928712871287129\n",
      "Confusion Matrix:\n",
      "[[ 969  363]\n",
      " [ 160 1001]]\n"
     ]
    }
   ],
   "source": [
    "probabilities = lr_meta_classifier.predict_proba(test_meta_features)\n",
    "\n",
    "# Calculate precision-recall curve and find optimal thresholds for each class\n",
    "lr_thresh = []\n",
    "for i in range(probabilities.shape[1]):  # Iterate over each class\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test == i, probabilities[:, i])\n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "    optimal_idx = np.nanargmax(f1_scores)  # Handle cases where precision and recall are both zero\n",
    "    lr_thresh.append(thresholds[optimal_idx])\n",
    "\n",
    "# Apply the optimized thresholds to make adjusted predictions\n",
    "adjusted_predictions = np.array([np.argmax([probabilities[i, j] if probabilities[i, j] >= lr_thresh[j] else 0\n",
    "                                         for j in range(probabilities.shape[1])])\n",
    "                              for i in range(len(probabilities))])\n",
    "\n",
    "# Evaluate\n",
    "adjusted_precision = precision_score(y_test, adjusted_predictions, average='macro')\n",
    "adjusted_recall = recall_score(y_test, adjusted_predictions, average='macro')\n",
    "adjusted_accuracy = accuracy_score(y_test, adjusted_predictions)\n",
    "adjusted_f1 = f1_score(y_test, adjusted_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_test, adjusted_predictions)\n",
    "\n",
    "print(\"Optimized thresholds for each class:\", lr_thresh)\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Precision: {adjusted_precision:.4f}\")\n",
    "print(f\"Recall: {adjusted_recall:.4f}\")\n",
    "print(f\"Ensemble accuracy: {adjusted_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {adjusted_f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfc6b32b-5f2a-4017-8a2b-e393ee1f85b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T13:03:09.698019Z",
     "iopub.status.busy": "2024-09-09T13:03:09.697946Z",
     "iopub.status.idle": "2024-09-09T13:03:10.894661Z",
     "shell.execute_reply": "2024-09-09T13:03:10.892782Z",
     "shell.execute_reply.started": "2024-09-09T13:03:09.698013Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated cells count: 4\n"
     ]
    }
   ],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '5-1!B4:E4'  \n",
    "\n",
    "values = [[\n",
    "    f\"{adjusted_precision * 100:.2f}\",\n",
    "    f\"{adjusted_recall * 100:.2f}\",\n",
    "    f\"{adjusted_accuracy * 100:.2f}\",\n",
    "    f\"{adjusted_f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f311d02-936c-467e-ae14-e0c9cd0f0211",
   "metadata": {},
   "source": [
    "### NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3cde7aba-1d7b-4fbd-94f0-98b9e5b2756a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T13:03:10.898974Z",
     "iopub.status.busy": "2024-09-09T13:03:10.897631Z",
     "iopub.status.idle": "2024-09-09T13:03:10.921116Z",
     "shell.execute_reply": "2024-09-09T13:03:10.920054Z",
     "shell.execute_reply.started": "2024-09-09T13:03:10.898920Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Precision: 0.7760199833472107\n",
      "Recall: 0.8027562446167097\n",
      "Ensemble accuracy: 0.8002406738868832\n",
      "F1 Score: 0.7891617273497037\n",
      "Confusion Matrix:\n",
      "[[1063  269]\n",
      " [ 229  932]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "precision = precision_score(y_test, nb_final_predictions, average='macro')\n",
    "recall = recall_score(y_test, nb_final_predictions, average='macro')\n",
    "accuracy = accuracy_score(y_test, nb_final_predictions)\n",
    "f1 = f1_score(y_test, nb_final_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_test, nb_final_predictions)\n",
    "\n",
    "print(\"Naive Bayes\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Ensemble accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07991bda-71ea-4786-996b-61a3ae0132ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T13:03:11.001831Z",
     "iopub.status.busy": "2024-09-09T13:03:11.001750Z",
     "iopub.status.idle": "2024-09-09T13:03:11.073313Z",
     "shell.execute_reply": "2024-09-09T13:03:11.073086Z",
     "shell.execute_reply.started": "2024-09-09T13:03:11.001822Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted threshold: 0.22\n",
      "Optimized Logistic Regression\n",
      "Precision: 0.7736625514403292\n",
      "Recall: 0.8096468561584841\n",
      "Accuracy: 0.8010429201764941\n",
      "F1 Score: 0.7912457912457912\n",
      "Confusion Matrix:\n",
      "[[1057  275]\n",
      " [ 221  940]]\n"
     ]
    }
   ],
   "source": [
    "probabilities = nb_meta_classifier.predict_proba(test_meta_features)\n",
    "\n",
    "# Calculate precision-recall curve and find optimal thresholds for each class\n",
    "nb_thresh = []\n",
    "for i in range(probabilities.shape[1]):  # Iterate over each class\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test == i, probabilities[:, i])\n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "    optimal_idx = np.nanargmax(f1_scores)  # Handle cases where precision and recall are both zero\n",
    "    nb_thresh.append(thresholds[optimal_idx])\n",
    "\n",
    "# Apply the optimized thresholds to make adjusted predictions\n",
    "adjusted_predictions = np.array([np.argmax([probabilities[i, j] if probabilities[i, j] >= nb_thresh[j] else 0\n",
    "                                         for j in range(probabilities.shape[1])])\n",
    "                              for i in range(len(probabilities))])\n",
    "\n",
    "# Evaluate\n",
    "adjusted_precision = precision_score(y_test, adjusted_predictions, average='macro')\n",
    "adjusted_recall = recall_score(y_test, adjusted_predictions, average='macro')\n",
    "adjusted_accuracy = accuracy_score(y_test, adjusted_predictions)\n",
    "adjusted_f1 = f1_score(y_test, adjusted_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_test, adjusted_predictions)\n",
    "\n",
    "print(\"Optimized thresholds for each class:\", nb_thresh)\n",
    "print(\"Naive Bayes\")\n",
    "print(f\"Precision: {adjusted_precision:.4f}\")\n",
    "print(f\"Recall: {adjusted_recall:.4f}\")\n",
    "print(f\"Ensemble accuracy: {adjusted_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {adjusted_f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aecf64b8-5a1a-4cea-a077-2049e0459dd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T13:03:11.073787Z",
     "iopub.status.busy": "2024-09-09T13:03:11.073715Z",
     "iopub.status.idle": "2024-09-09T13:03:11.509064Z",
     "shell.execute_reply": "2024-09-09T13:03:11.507501Z",
     "shell.execute_reply.started": "2024-09-09T13:03:11.073782Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated cells count: 4\n"
     ]
    }
   ],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '5-1!B5:E5'  \n",
    "\n",
    "values = [[\n",
    "    f\"{adjusted_precision * 100:.2f}\",\n",
    "    f\"{adjusted_recall * 100:.2f}\",\n",
    "    f\"{adjusted_accuracy * 100:.2f}\",\n",
    "    f\"{adjusted_f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958d063b-7c6a-43d7-aaa2-0b93e3d56610",
   "metadata": {},
   "source": [
    "### DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c799950-2309-4a08-9778-351ab70a85db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T13:03:11.524227Z",
     "iopub.status.busy": "2024-09-09T13:03:11.523859Z",
     "iopub.status.idle": "2024-09-09T13:03:11.540376Z",
     "shell.execute_reply": "2024-09-09T13:03:11.539901Z",
     "shell.execute_reply.started": "2024-09-09T13:03:11.524204Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Precision: 0.7823834196891192\n",
      "Recall: 0.7803617571059431\n",
      "Ensemble accuracy: 0.7966305655836342\n",
      "F1 Score: 0.7813712807244502\n",
      "Confusion Matrix:\n",
      "[[1080  252]\n",
      " [ 255  906]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "precision = precision_score(y_test, dt_final_predictions, average='macro')\n",
    "recall = recall_score(y_test, dt_final_predictions, average='macro')\n",
    "accuracy = accuracy_score(y_test, dt_final_predictions)\n",
    "f1 = f1_score(y_test, dt_final_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_test, dt_final_predictions)\n",
    "\n",
    "print(\"Decision Tree\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Ensemble accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a63b5fc-8c61-409f-86bf-470f00eb6d99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T13:03:11.618016Z",
     "iopub.status.busy": "2024-09-09T13:03:11.617930Z",
     "iopub.status.idle": "2024-09-09T13:03:11.690603Z",
     "shell.execute_reply": "2024-09-09T13:03:11.690345Z",
     "shell.execute_reply.started": "2024-09-09T13:03:11.618010Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted threshold: 0.3\n",
      "Optimized Logistic Regression\n",
      "Precision: 0.7217081850533807\n",
      "Recall: 0.8733850129198967\n",
      "Accuracy: 0.7841957480946651\n",
      "F1 Score: 0.7903351519875292\n",
      "Confusion Matrix:\n",
      "[[ 941  391]\n",
      " [ 147 1014]]\n"
     ]
    }
   ],
   "source": [
    "probabilities = dt_meta_classifier.predict_proba(test_meta_features)\n",
    "\n",
    "# Calculate precision-recall curve and find optimal thresholds for each class\n",
    "dt_thresh = []\n",
    "for i in range(probabilities.shape[1]):  # Iterate over each class\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test == i, probabilities[:, i])\n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "    optimal_idx = np.nanargmax(f1_scores)  # Handle cases where precision and recall are both zero\n",
    "    dt_thresh.append(thresholds[optimal_idx])\n",
    "\n",
    "# Apply the optimized thresholds to make adjusted predictions\n",
    "adjusted_predictions = np.array([np.argmax([probabilities[i, j] if probabilities[i, j] >= dt_thresh[j] else 0\n",
    "                                         for j in range(probabilities.shape[1])])\n",
    "                              for i in range(len(probabilities))])\n",
    "\n",
    "# Evaluate\n",
    "adjusted_precision = precision_score(y_test, adjusted_predictions, average='macro')\n",
    "adjusted_recall = recall_score(y_test, adjusted_predictions, average='macro')\n",
    "adjusted_accuracy = accuracy_score(y_test, adjusted_predictions)\n",
    "adjusted_f1 = f1_score(y_test, adjusted_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_test, adjusted_predictions)\n",
    "\n",
    "print(\"Optimized thresholds for each class:\", dt_thresh)\n",
    "print(\"Decision Tree\")\n",
    "print(f\"Precision: {adjusted_precision:.4f}\")\n",
    "print(f\"Recall: {adjusted_recall:.4f}\")\n",
    "print(f\"Ensemble accuracy: {adjusted_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {adjusted_f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9653e844-4196-4d63-9b61-4998f3dba2d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T13:03:11.691031Z",
     "iopub.status.busy": "2024-09-09T13:03:11.690961Z",
     "iopub.status.idle": "2024-09-09T13:03:12.019760Z",
     "shell.execute_reply": "2024-09-09T13:03:12.018000Z",
     "shell.execute_reply.started": "2024-09-09T13:03:11.691025Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated cells count: 4\n"
     ]
    }
   ],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '5-1!B6:E6'  \n",
    "\n",
    "values = [[\n",
    "    f\"{adjusted_precision * 100:.2f}\",\n",
    "    f\"{adjusted_recall * 100:.2f}\",\n",
    "    f\"{adjusted_accuracy * 100:.2f}\",\n",
    "    f\"{adjusted_f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24614471-4cf3-4349-b8bb-98715c2db8a9",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f5a4d67-5a7a-4f32-b9c4-6f5c7612a256",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T13:03:12.022437Z",
     "iopub.status.busy": "2024-09-09T13:03:12.021904Z",
     "iopub.status.idle": "2024-09-09T13:03:12.040683Z",
     "shell.execute_reply": "2024-09-09T13:03:12.040203Z",
     "shell.execute_reply.started": "2024-09-09T13:03:12.022407Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Precision: 0.7512116316639742\n",
      "Recall: 0.8010335917312662\n",
      "Ensemble accuracy: 0.7837946249498596\n",
      "F1 Score: 0.775323051271363\n",
      "Confusion Matrix:\n",
      "[[1024  308]\n",
      " [ 231  930]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "precision = precision_score(y_test, svm_final_predictions, average='macro')\n",
    "recall = recall_score(y_test, svm_final_predictions, average='macro')\n",
    "accuracy = accuracy_score(y_test, svm_final_predictions)\n",
    "f1 = f1_score(y_test, svm_final_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_test, svm_final_predictions)\n",
    "\n",
    "print(\"SVM\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Ensemble accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f4bf24f-5e38-4acf-b0d1-c42ddb5a862f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T13:03:12.146942Z",
     "iopub.status.busy": "2024-09-09T13:03:12.146861Z",
     "iopub.status.idle": "2024-09-09T13:03:12.217332Z",
     "shell.execute_reply": "2024-09-09T13:03:12.217112Z",
     "shell.execute_reply.started": "2024-09-09T13:03:12.146936Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted threshold: 0.13\n",
      "Optimized Logistic Regression\n",
      "Precision: 0.7512116316639742\n",
      "Recall: 0.8010335917312662\n",
      "Accuracy: 0.7837946249498596\n",
      "F1 Score: 0.775323051271363\n",
      "Confusion Matrix:\n",
      "[[1024  308]\n",
      " [ 231  930]]\n"
     ]
    }
   ],
   "source": [
    "probabilities = svm_meta_classifier.predict_proba(test_meta_features)\n",
    "\n",
    "# Calculate precision-recall curve and find optimal thresholds for each class\n",
    "svm_thresh = []\n",
    "for i in range(probabilities.shape[1]):  # Iterate over each class\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test == i, probabilities[:, i])\n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "    optimal_idx = np.nanargmax(f1_scores)  # Handle cases where precision and recall are both zero\n",
    "    svm_thresh.append(thresholds[optimal_idx])\n",
    "\n",
    "# Apply the optimized thresholds to make adjusted predictions\n",
    "adjusted_predictions = np.array([np.argmax([probabilities[i, j] if probabilities[i, j] >= svm_thresh[j] else 0\n",
    "                                         for j in range(probabilities.shape[1])])\n",
    "                              for i in range(len(probabilities))])\n",
    "\n",
    "# Evaluate\n",
    "adjusted_precision = precision_score(y_test, adjusted_predictions, average='macro')\n",
    "adjusted_recall = recall_score(y_test, adjusted_predictions, average='macro')\n",
    "adjusted_accuracy = accuracy_score(y_test, adjusted_predictions)\n",
    "adjusted_f1 = f1_score(y_test, adjusted_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_test, adjusted_predictions)\n",
    "\n",
    "print(\"Optimized thresholds for each class:\", svm_thresh)\n",
    "print(\"SVM\")\n",
    "print(f\"Precision: {adjusted_precision:.4f}\")\n",
    "print(f\"Recall: {adjusted_recall:.4f}\")\n",
    "print(f\"Ensemble accuracy: {adjusted_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {adjusted_f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "92382252-0d77-45d8-bb20-8c5c7f2a983b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T13:03:12.217904Z",
     "iopub.status.busy": "2024-09-09T13:03:12.217805Z",
     "iopub.status.idle": "2024-09-09T13:03:12.643462Z",
     "shell.execute_reply": "2024-09-09T13:03:12.641549Z",
     "shell.execute_reply.started": "2024-09-09T13:03:12.217897Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated cells count: 4\n"
     ]
    }
   ],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '5-1!B7:E7'  \n",
    "\n",
    "values = [[\n",
    "    f\"{adjusted_precision * 100:.2f}\",\n",
    "    f\"{adjusted_recall * 100:.2f}\",\n",
    "    f\"{adjusted_accuracy * 100:.2f}\",\n",
    "    f\"{adjusted_f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0143f6-14c3-431a-b08b-7f182a0c7c96",
   "metadata": {},
   "source": [
    "## TEST DATA C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a7c1fca-bf56-43cf-8559-e8acfd5dc262",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T13:03:12.646703Z",
     "iopub.status.busy": "2024-09-09T13:03:12.645797Z",
     "iopub.status.idle": "2024-09-09T13:03:52.848671Z",
     "shell.execute_reply": "2024-09-09T13:03:52.847980Z",
     "shell.execute_reply.started": "2024-09-09T13:03:12.646663Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Load validation data\n",
    "validation_file_path = 'Corpus/FiReCS/FiReCS_data_c.csv'\n",
    "validation_df = pd.read_csv(validation_file_path)\n",
    "\n",
    "X_val = validation_df['review'].values \n",
    "y_val = validation_df['label'].values\n",
    "\n",
    "# Generate meta-features for data c dataset\n",
    "val_meta_features = get_predictions(models_and_tokenizers, X_val, y_val, device) \n",
    "\n",
    "# Predict using the logistic regression meta-classifier\n",
    "val_lr_predictions = lr_meta_classifier.predict(val_meta_features)\n",
    "\n",
    "# Predict using the naive bayes meta-classifier\n",
    "val_nb_predictions = nb_meta_classifier.predict(val_meta_features)\n",
    "\n",
    "# Predict using the decision tree meta-classifier\n",
    "val_dt_predictions = dt_meta_classifier.predict(val_meta_features)\n",
    "\n",
    "# Predict using the svm meta-classifier\n",
    "val_svm_predictions = svm_meta_classifier.predict(val_meta_features)\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0693ac-17b2-4645-be71-fe4c1f337e38",
   "metadata": {},
   "source": [
    "### LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5303f868-1507-4252-9f50-136aa337f630",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T13:03:52.850708Z",
     "iopub.status.busy": "2024-09-09T13:03:52.849609Z",
     "iopub.status.idle": "2024-09-09T13:03:52.865860Z",
     "shell.execute_reply": "2024-09-09T13:03:52.865338Z",
     "shell.execute_reply.started": "2024-09-09T13:03:52.850690Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on HS-Data C Dataset\n",
      "Precision: 0.7652838427947598\n",
      "Recall: 0.8151162790697675\n",
      "Accuracy: 0.797509474824039\n",
      "F1 Score: 0.7894144144144144\n",
      "Confusion Matrix:\n",
      "[[772 215]\n",
      " [159 701]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the predictions\n",
    "precision = precision_score(y_val, val_lr_predictions, average='macro')\n",
    "recall = recall_score(y_val, val_lr_predictions, average='macro')\n",
    "accuracy = accuracy_score(y_val, val_lr_predictions)\n",
    "f1 = f1_score(y_val, val_lr_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_val, val_lr_predictions)\n",
    "\n",
    "print(\"Evaluation on HS-Data C Dataset\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d732e24d-540c-4934-a359-e7098db0eaaf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T13:03:52.979048Z",
     "iopub.status.busy": "2024-09-09T13:03:52.978310Z",
     "iopub.status.idle": "2024-09-09T13:03:52.987549Z",
     "shell.execute_reply": "2024-09-09T13:03:52.986998Z",
     "shell.execute_reply.started": "2024-09-09T13:03:52.979028Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted threshold: 0.22\n",
      "Optimized Logistic Regression\n",
      "Precision: 0.7304761904761905\n",
      "Recall: 0.891860465116279\n",
      "Accuracy: 0.7964266377910124\n",
      "F1 Score: 0.8031413612565445\n",
      "Confusion Matrix:\n",
      "[[704 283]\n",
      " [ 93 767]]\n"
     ]
    }
   ],
   "source": [
    "lr_validation_probabilities = lr_meta_classifier.predict_proba(val_meta_features)\n",
    "\n",
    "# Apply thresholds to the validation set probabilities to make final predictions\n",
    "lr_validation_predictions = np.array([np.argmax([lr_validation_probabilities[i, j] if lr_validation_probabilities[i, j] >= lr_thresh[j] else 0\n",
    "                                              for j in range(lr_validation_probabilities.shape[1])])\n",
    "                                   for i in range(len(lr_validation_probabilities))])\n",
    "\n",
    "# Evaluate threshold on validation set\n",
    "adjusted_precision = precision_score(y_val, lr_validation_predictions, average='macro')\n",
    "adjusted_recall = recall_score(y_val, lr_validation_predictions, average='macro')\n",
    "adjusted_accuracy = accuracy_score(y_val, lr_validation_predictions)\n",
    "adjusted_f1 = f1_score(y_val, lr_validation_predictions, average='macro')\n",
    "adjusted_conf_matrix = confusion_matrix(y_val, lr_validation_predictions)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Validation Results\")\n",
    "print(f\"Precision: {adjusted_precision:.4f}\")\n",
    "print(f\"Recall: {adjusted_recall:.4f}\")\n",
    "print(f\"Accuracy: {adjusted_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {adjusted_f1:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(adjusted_conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "35d847f4-0bc4-4f4f-a1ff-22d5d990820f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T13:03:52.988506Z",
     "iopub.status.busy": "2024-09-09T13:03:52.988321Z",
     "iopub.status.idle": "2024-09-09T13:03:53.597891Z",
     "shell.execute_reply": "2024-09-09T13:03:53.596021Z",
     "shell.execute_reply.started": "2024-09-09T13:03:52.988492Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated cells count: 4\n"
     ]
    }
   ],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '5-1!F4:I4'  \n",
    "\n",
    "values = [[\n",
    "    f\"{adjusted_precision * 100:.2f}\",\n",
    "    f\"{adjusted_recall * 100:.2f}\",\n",
    "    f\"{adjusted_accuracy * 100:.2f}\",\n",
    "    f\"{adjusted_f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d20e88-5a01-4b56-ad36-37c984d10277",
   "metadata": {},
   "source": [
    "#### Save CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3ca78187-3e76-4798-b348-64b200b29eb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T13:03:53.600680Z",
     "iopub.status.busy": "2024-09-09T13:03:53.599965Z",
     "iopub.status.idle": "2024-09-09T13:03:53.823723Z",
     "shell.execute_reply": "2024-09-09T13:03:53.823463Z",
     "shell.execute_reply.started": "2024-09-09T13:03:53.600641Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-4f40c7e3273847989469a768b652d854.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-4f40c7e3273847989469a768b652d854.vega-embed details,\n",
       "  #altair-viz-4f40c7e3273847989469a768b652d854.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-4f40c7e3273847989469a768b652d854\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-4f40c7e3273847989469a768b652d854\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-4f40c7e3273847989469a768b652d854\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"rect\"}, \"encoding\": {\"color\": {\"field\": \"Count\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"True\", \"type\": \"ordinal\"}, {\"field\": \"Predicted\", \"type\": \"ordinal\"}, {\"field\": \"Count\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Predicted\", \"sort\": [\"Hate Speech\", \"Non Hatespeech\"], \"type\": \"ordinal\"}, \"y\": {\"field\": \"True\", \"sort\": [\"Hate Speech\", \"Non Hatespeech\"], \"type\": \"ordinal\"}}, \"title\": \"OH_Using_HS 5STK-1 LR\"}, {\"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"middle\", \"fontSize\": 12}, \"encoding\": {\"color\": {\"condition\": {\"test\": \"(datum.Count > 383.5)\", \"value\": \"white\"}, \"value\": \"black\"}, \"text\": {\"field\": \"Count\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"True\", \"type\": \"ordinal\"}, {\"field\": \"Predicted\", \"type\": \"ordinal\"}, {\"field\": \"Count\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Predicted\", \"sort\": [\"Hate Speech\", \"Non Hatespeech\"], \"type\": \"ordinal\"}, \"y\": {\"field\": \"True\", \"sort\": [\"Hate Speech\", \"Non Hatespeech\"], \"type\": \"ordinal\"}}, \"title\": \"OH_Using_HS 5STK-1 LR\"}], \"data\": {\"name\": \"data-575c099cd8752bd43bff2809ca8aacbc\"}, \"height\": 300, \"width\": 400, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-575c099cd8752bd43bff2809ca8aacbc\": [{\"True\": \"Hate Speech\", \"Predicted\": \"Hate Speech\", \"Count\": 704}, {\"True\": \"Non Hatespeech\", \"Predicted\": \"Hate Speech\", \"Count\": 93}, {\"True\": \"Hate Speech\", \"Predicted\": \"Non Hatespeech\", \"Count\": 283}, {\"True\": \"Non Hatespeech\", \"Predicted\": \"Non Hatespeech\", \"Count\": 767}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import altair as alt\n",
    "import altair_saver\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_val, lr_validation_predictions)\n",
    "\n",
    "# Define class names\n",
    "class_names = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "# Convert confusion matrix to DataFrame\n",
    "cm_df = pd.DataFrame(cm, index=class_names, columns=class_names).reset_index().melt(id_vars='index')\n",
    "cm_df.columns = ['True', 'Predicted', 'Count']\n",
    "\n",
    "# Ensure the order of categories\n",
    "cm_df['True'] = pd.Categorical(cm_df['True'], categories=class_names, ordered=True)\n",
    "cm_df['Predicted'] = pd.Categorical(cm_df['Predicted'], categories=class_names, ordered=True)\n",
    "\n",
    "# Create the Altair plot\n",
    "heatmap = alt.Chart(cm_df).mark_rect().encode(\n",
    "    x=alt.X('Predicted:O', sort=class_names),\n",
    "    y=alt.Y('True:O', sort=class_names),\n",
    "    color='Count:Q',\n",
    "    tooltip=['True', 'Predicted', 'Count']\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=300,\n",
    "    title='OF_Using_FIRE 5STK-1 LR'\n",
    ")\n",
    "\n",
    "# Add text labels\n",
    "text = heatmap.mark_text(\n",
    "    align='center',\n",
    "    baseline='middle',\n",
    "    fontSize=12\n",
    ").encode(\n",
    "    text='Count:Q',\n",
    "    color=alt.condition(\n",
    "        alt.datum.Count > cm.max() / 2,\n",
    "        alt.value('white'),\n",
    "        alt.value('black')\n",
    "    )\n",
    ")\n",
    "\n",
    "# Combine heatmap and text\n",
    "final_chart = heatmap + text\n",
    "\n",
    "# Display the plot\n",
    "final_chart.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4018e7ba-2de6-44d9-9a6f-bf13ccb33108",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T13:03:53.824356Z",
     "iopub.status.busy": "2024-09-09T13:03:53.824233Z",
     "iopub.status.idle": "2024-09-09T13:03:54.223542Z",
     "shell.execute_reply": "2024-09-09T13:03:54.223285Z",
     "shell.execute_reply.started": "2024-09-09T13:03:53.824349Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to Results/Ensemble Model Results/On Hatespeech dataset/OH Using HS Ensemble/Blending/OH_Using_HS 5STK-1 LR.png\n"
     ]
    }
   ],
   "source": [
    "# Specify the folder path\n",
    "folder_path = os.path.expanduser('Results/Ensemble Model Results/On FireCS dataset/OF Using FIRE ENSEMBLE/Stacking/')\n",
    "\n",
    "# Save the plot using vl-convert\n",
    "file_path_png = os.path.join(folder_path, 'OF_Using_FIRE 5STK-1 LR.png')\n",
    "final_chart.save(file_path_png)\n",
    "\n",
    "print(f\"Plot saved to {file_path_png}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e3bc0f-597f-47e3-ba99-5d9cafd1aea3",
   "metadata": {},
   "source": [
    "### NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0af5051f-834f-4646-afef-37bfdfdc43d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T13:03:54.224150Z",
     "iopub.status.busy": "2024-09-09T13:03:54.224025Z",
     "iopub.status.idle": "2024-09-09T13:03:54.229327Z",
     "shell.execute_reply": "2024-09-09T13:03:54.229118Z",
     "shell.execute_reply.started": "2024-09-09T13:03:54.224142Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on HS-Data C Dataset\n",
      "Precision: 0.7709011943539631\n",
      "Recall: 0.8255813953488372\n",
      "Accuracy: 0.8045479155387114\n",
      "F1 Score: 0.7973048848961257\n",
      "Confusion Matrix:\n",
      "[[776 211]\n",
      " [150 710]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the predictions\n",
    "precision = precision_score(y_val, val_nb_predictions, average='macro')\n",
    "recall = recall_score(y_val, val_nb_predictions, average='macro')\n",
    "accuracy = accuracy_score(y_val, val_nb_predictions)\n",
    "f1 = f1_score(y_val, val_nb_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_val, val_nb_predictions)\n",
    "\n",
    "print(\"Evaluation on HS-Data C Dataset\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d1acd42b-ca2c-40be-b90e-e7fb7f6eeb2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T13:03:54.287021Z",
     "iopub.status.busy": "2024-09-09T13:03:54.286944Z",
     "iopub.status.idle": "2024-09-09T13:03:54.292663Z",
     "shell.execute_reply": "2024-09-09T13:03:54.292450Z",
     "shell.execute_reply.started": "2024-09-09T13:03:54.287015Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted threshold: 0.22\n",
      "Optimized Naive Bayes\n",
      "Precision: 0.7630736392742796\n",
      "Recall: 0.8313953488372093\n",
      "Accuracy: 0.8012994044396319\n",
      "F1 Score: 0.7957707289927657\n",
      "Confusion Matrix:\n",
      "[[765 222]\n",
      " [145 715]]\n"
     ]
    }
   ],
   "source": [
    "nb_validation_probabilities = nb_meta_classifier.predict_proba(val_meta_features)\n",
    "\n",
    "# Apply thresholds to the validation set probabilities to make final predictions\n",
    "nb_validation_predictions = np.array([np.argmax([nb_validation_probabilities[i, j] if nb_validation_probabilities[i, j] >= nb_thresh[j] else 0\n",
    "                                              for j in range(nb_validation_probabilities.shape[1])])\n",
    "                                   for i in range(len(nb_validation_probabilities))])\n",
    "\n",
    "# Evaluate threshold on validation set\n",
    "adjusted_precision = precision_score(y_val, nb_validation_predictions, average='macro')\n",
    "adjusted_recall = recall_score(y_val, nb_validation_predictions, average='macro')\n",
    "adjusted_accuracy = accuracy_score(y_val, nb_validation_predictions)\n",
    "adjusted_f1 = f1_score(y_val, nb_validation_predictions, average='macro')\n",
    "adjusted_conf_matrix = confusion_matrix(y_val, nb_validation_predictions)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Validation Results\")\n",
    "print(f\"Precision: {adjusted_precision:.4f}\")\n",
    "print(f\"Recall: {adjusted_recall:.4f}\")\n",
    "print(f\"Accuracy: {adjusted_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {adjusted_f1:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(adjusted_conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fe5b7918-e4a2-4fd5-bfc3-74bb308a085b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T13:03:54.293186Z",
     "iopub.status.busy": "2024-09-09T13:03:54.293101Z",
     "iopub.status.idle": "2024-09-09T13:03:54.616762Z",
     "shell.execute_reply": "2024-09-09T13:03:54.616377Z",
     "shell.execute_reply.started": "2024-09-09T13:03:54.293179Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated cells count: 4\n"
     ]
    }
   ],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '5-1!F5:I5'  \n",
    "\n",
    "values = [[\n",
    "    f\"{adjusted_precision * 100:.2f}\",\n",
    "    f\"{adjusted_recall * 100:.2f}\",\n",
    "    f\"{adjusted_accuracy * 100:.2f}\",\n",
    "    f\"{adjusted_f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65529983-86a3-4c32-b155-c08fcdf20b31",
   "metadata": {},
   "source": [
    "#### Save CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ea993771-7e1b-4a65-8e32-29912f2564d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T13:03:54.617518Z",
     "iopub.status.busy": "2024-09-09T13:03:54.617401Z",
     "iopub.status.idle": "2024-09-09T13:03:54.649224Z",
     "shell.execute_reply": "2024-09-09T13:03:54.648962Z",
     "shell.execute_reply.started": "2024-09-09T13:03:54.617508Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-eb11b6f592ba4615a514fb5aeea2572c.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-eb11b6f592ba4615a514fb5aeea2572c.vega-embed details,\n",
       "  #altair-viz-eb11b6f592ba4615a514fb5aeea2572c.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-eb11b6f592ba4615a514fb5aeea2572c\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-eb11b6f592ba4615a514fb5aeea2572c\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-eb11b6f592ba4615a514fb5aeea2572c\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"rect\"}, \"encoding\": {\"color\": {\"field\": \"Count\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"True\", \"type\": \"ordinal\"}, {\"field\": \"Predicted\", \"type\": \"ordinal\"}, {\"field\": \"Count\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Predicted\", \"sort\": [\"Hate Speech\", \"Non Hatespeech\"], \"type\": \"ordinal\"}, \"y\": {\"field\": \"True\", \"sort\": [\"Hate Speech\", \"Non Hatespeech\"], \"type\": \"ordinal\"}}, \"title\": \"OH_Using_HS 5STK-1 NB\"}, {\"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"middle\", \"fontSize\": 12}, \"encoding\": {\"color\": {\"condition\": {\"test\": \"(datum.Count > 382.5)\", \"value\": \"white\"}, \"value\": \"black\"}, \"text\": {\"field\": \"Count\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"True\", \"type\": \"ordinal\"}, {\"field\": \"Predicted\", \"type\": \"ordinal\"}, {\"field\": \"Count\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Predicted\", \"sort\": [\"Hate Speech\", \"Non Hatespeech\"], \"type\": \"ordinal\"}, \"y\": {\"field\": \"True\", \"sort\": [\"Hate Speech\", \"Non Hatespeech\"], \"type\": \"ordinal\"}}, \"title\": \"OH_Using_HS 5STK-1 NB\"}], \"data\": {\"name\": \"data-782c6a53b039b16f3f70c78599dca7a8\"}, \"height\": 300, \"width\": 400, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-782c6a53b039b16f3f70c78599dca7a8\": [{\"True\": \"Hate Speech\", \"Predicted\": \"Hate Speech\", \"Count\": 765}, {\"True\": \"Non Hatespeech\", \"Predicted\": \"Hate Speech\", \"Count\": 145}, {\"True\": \"Hate Speech\", \"Predicted\": \"Non Hatespeech\", \"Count\": 222}, {\"True\": \"Non Hatespeech\", \"Predicted\": \"Non Hatespeech\", \"Count\": 715}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import altair as alt\n",
    "import altair_saver\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_val, nb_validation_predictions)\n",
    "\n",
    "# Define class names\n",
    "class_names = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "# Convert confusion matrix to DataFrame\n",
    "cm_df = pd.DataFrame(cm, index=class_names, columns=class_names).reset_index().melt(id_vars='index')\n",
    "cm_df.columns = ['True', 'Predicted', 'Count']\n",
    "\n",
    "# Ensure the order of categories\n",
    "cm_df['True'] = pd.Categorical(cm_df['True'], categories=class_names, ordered=True)\n",
    "cm_df['Predicted'] = pd.Categorical(cm_df['Predicted'], categories=class_names, ordered=True)\n",
    "\n",
    "# Create the Altair plot\n",
    "heatmap = alt.Chart(cm_df).mark_rect().encode(\n",
    "    x=alt.X('Predicted:O', sort=class_names),\n",
    "    y=alt.Y('True:O', sort=class_names),\n",
    "    color='Count:Q',\n",
    "    tooltip=['True', 'Predicted', 'Count']\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=300,\n",
    "    title='OF_Using_FIRE 5STK-1 NB'\n",
    ")\n",
    "\n",
    "# Add text labels\n",
    "text = heatmap.mark_text(\n",
    "    align='center',\n",
    "    baseline='middle',\n",
    "    fontSize=12\n",
    ").encode(\n",
    "    text='Count:Q',\n",
    "    color=alt.condition(\n",
    "        alt.datum.Count > cm.max() / 2,\n",
    "        alt.value('white'),\n",
    "        alt.value('black')\n",
    "    )\n",
    ")\n",
    "\n",
    "# Combine heatmap and text\n",
    "final_chart = heatmap + text\n",
    "\n",
    "# Display the plot\n",
    "final_chart.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "031b9ce6-7d92-4735-a298-e8f7812ebae0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T13:03:54.649618Z",
     "iopub.status.busy": "2024-09-09T13:03:54.649542Z",
     "iopub.status.idle": "2024-09-09T13:03:54.686312Z",
     "shell.execute_reply": "2024-09-09T13:03:54.686070Z",
     "shell.execute_reply.started": "2024-09-09T13:03:54.649611Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to Results/Ensemble Model Results/On Hatespeech dataset/OH Using HS Ensemble/Blending/OH_Using_HS 5STK-1 NB.png\n"
     ]
    }
   ],
   "source": [
    "# Specify the folder path\n",
    "folder_path = os.path.expanduser('Results/Ensemble Model Results/On FireCS dataset/OF Using FIRE ENSEMBLE/Stacking/')\n",
    "\n",
    "# Save the plot using vl-convert\n",
    "file_path_png = os.path.join(folder_path, 'OF_Using_FIRE 5STK-1 NB.png')\n",
    "final_chart.save(file_path_png)\n",
    "\n",
    "print(f\"Plot saved to {file_path_png}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba2269b-62c4-43d2-8394-9aa3c1a27678",
   "metadata": {},
   "source": [
    "### DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0448f107-62d6-4f1a-8b04-4378b79f3d3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T13:03:54.686857Z",
     "iopub.status.busy": "2024-09-09T13:03:54.686745Z",
     "iopub.status.idle": "2024-09-09T13:03:54.691795Z",
     "shell.execute_reply": "2024-09-09T13:03:54.691596Z",
     "shell.execute_reply.started": "2024-09-09T13:03:54.686851Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on HS-Data C Dataset\n",
      "Precision: 0.7769058295964125\n",
      "Recall: 0.8058139534883721\n",
      "Accuracy: 0.8018408229561451\n",
      "F1 Score: 0.791095890410959\n",
      "Confusion Matrix:\n",
      "[[788 199]\n",
      " [167 693]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the predictions\n",
    "precision = precision_score(y_val, val_dt_predictions, average='macro')\n",
    "recall = recall_score(y_val, val_dt_predictions, average='macro')\n",
    "accuracy = accuracy_score(y_val, val_dt_predictions)\n",
    "f1 = f1_score(y_val, val_dt_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_val, val_dt_predictions)\n",
    "\n",
    "print(\"Evaluation on HS-Data C Dataset\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9a0f105d-eb8f-4450-9d41-d90c97cf028c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T13:03:54.822437Z",
     "iopub.status.busy": "2024-09-09T13:03:54.822307Z",
     "iopub.status.idle": "2024-09-09T13:03:54.827894Z",
     "shell.execute_reply": "2024-09-09T13:03:54.827663Z",
     "shell.execute_reply.started": "2024-09-09T13:03:54.822430Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted threshold: 0.3\n",
      "Optimized Decision Tree\n",
      "Precision: 0.723264540337711\n",
      "Recall: 0.8965116279069767\n",
      "Accuracy: 0.7920952896589063\n",
      "F1 Score: 0.8006230529595015\n",
      "Confusion Matrix:\n",
      "[[692 295]\n",
      " [ 89 771]]\n"
     ]
    }
   ],
   "source": [
    "dt_validation_probabilities = dt_meta_classifier.predict_proba(val_meta_features)\n",
    "\n",
    "# Apply thresholds to the validation set probabilities to make final predictions\n",
    "dt_validation_predictions = np.array([np.argmax([dt_validation_probabilities[i, j] if dt_validation_probabilities[i, j] >= dt_thresh[j] else 0\n",
    "                                              for j in range(dt_validation_probabilities.shape[1])])\n",
    "                                   for i in range(len(dt_validation_probabilities))])\n",
    "\n",
    "# Evaluate threshold on validation set\n",
    "adjusted_precision = precision_score(y_val, dt_validation_predictions, average='macro')\n",
    "adjusted_recall = recall_score(y_val, dt_validation_predictions, average='macro')\n",
    "adjusted_accuracy = accuracy_score(y_val, dt_validation_predictions)\n",
    "adjusted_f1 = f1_score(y_val, dt_validation_predictions, average='macro')\n",
    "adjusted_conf_matrix = confusion_matrix(y_val, dt_validation_predictions)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Validation Results\")\n",
    "print(f\"Precision: {adjusted_precision:.4f}\")\n",
    "print(f\"Recall: {adjusted_recall:.4f}\")\n",
    "print(f\"Accuracy: {adjusted_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {adjusted_f1:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(adjusted_conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dec85bf2-3044-4247-90ec-703089be962b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T13:03:54.828381Z",
     "iopub.status.busy": "2024-09-09T13:03:54.828300Z",
     "iopub.status.idle": "2024-09-09T13:03:55.236659Z",
     "shell.execute_reply": "2024-09-09T13:03:55.234640Z",
     "shell.execute_reply.started": "2024-09-09T13:03:54.828375Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated cells count: 4\n"
     ]
    }
   ],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '5-1!F6:I6'  \n",
    "\n",
    "values = [[\n",
    "    f\"{adjusted_precision * 100:.2f}\",\n",
    "    f\"{adjusted_recall * 100:.2f}\",\n",
    "    f\"{adjusted_accuracy * 100:.2f}\",\n",
    "    f\"{adjusted_f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8589d71-c489-4214-9c56-4a3a7ed69506",
   "metadata": {},
   "source": [
    "#### Save CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bb07bbd3-2021-4e16-8b59-3908f095b7cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T13:03:55.240119Z",
     "iopub.status.busy": "2024-09-09T13:03:55.238931Z",
     "iopub.status.idle": "2024-09-09T13:03:55.293572Z",
     "shell.execute_reply": "2024-09-09T13:03:55.293230Z",
     "shell.execute_reply.started": "2024-09-09T13:03:55.240084Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-ddc0ce6ea0c34284b7e5a2dcc81e4581.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-ddc0ce6ea0c34284b7e5a2dcc81e4581.vega-embed details,\n",
       "  #altair-viz-ddc0ce6ea0c34284b7e5a2dcc81e4581.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-ddc0ce6ea0c34284b7e5a2dcc81e4581\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-ddc0ce6ea0c34284b7e5a2dcc81e4581\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-ddc0ce6ea0c34284b7e5a2dcc81e4581\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"rect\"}, \"encoding\": {\"color\": {\"field\": \"Count\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"True\", \"type\": \"ordinal\"}, {\"field\": \"Predicted\", \"type\": \"ordinal\"}, {\"field\": \"Count\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Predicted\", \"sort\": [\"Hate Speech\", \"Non Hatespeech\"], \"type\": \"ordinal\"}, \"y\": {\"field\": \"True\", \"sort\": [\"Hate Speech\", \"Non Hatespeech\"], \"type\": \"ordinal\"}}, \"title\": \"OH_Using_HS 5STK-1 DT\"}, {\"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"middle\", \"fontSize\": 12}, \"encoding\": {\"color\": {\"condition\": {\"test\": \"(datum.Count > 385.5)\", \"value\": \"white\"}, \"value\": \"black\"}, \"text\": {\"field\": \"Count\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"True\", \"type\": \"ordinal\"}, {\"field\": \"Predicted\", \"type\": \"ordinal\"}, {\"field\": \"Count\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Predicted\", \"sort\": [\"Hate Speech\", \"Non Hatespeech\"], \"type\": \"ordinal\"}, \"y\": {\"field\": \"True\", \"sort\": [\"Hate Speech\", \"Non Hatespeech\"], \"type\": \"ordinal\"}}, \"title\": \"OH_Using_HS 5STK-1 DT\"}], \"data\": {\"name\": \"data-335a503b33bad2ee6e11e989d10d2799\"}, \"height\": 300, \"width\": 400, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-335a503b33bad2ee6e11e989d10d2799\": [{\"True\": \"Hate Speech\", \"Predicted\": \"Hate Speech\", \"Count\": 692}, {\"True\": \"Non Hatespeech\", \"Predicted\": \"Hate Speech\", \"Count\": 89}, {\"True\": \"Hate Speech\", \"Predicted\": \"Non Hatespeech\", \"Count\": 295}, {\"True\": \"Non Hatespeech\", \"Predicted\": \"Non Hatespeech\", \"Count\": 771}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import altair as alt\n",
    "import altair_saver\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_val, dt_validation_predictions)\n",
    "\n",
    "# Define class names\n",
    "class_names = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "# Convert confusion matrix to DataFrame\n",
    "cm_df = pd.DataFrame(cm, index=class_names, columns=class_names).reset_index().melt(id_vars='index')\n",
    "cm_df.columns = ['True', 'Predicted', 'Count']\n",
    "\n",
    "# Ensure the order of categories\n",
    "cm_df['True'] = pd.Categorical(cm_df['True'], categories=class_names, ordered=True)\n",
    "cm_df['Predicted'] = pd.Categorical(cm_df['Predicted'], categories=class_names, ordered=True)\n",
    "\n",
    "# Create the Altair plot\n",
    "heatmap = alt.Chart(cm_df).mark_rect().encode(\n",
    "    x=alt.X('Predicted:O', sort=class_names),\n",
    "    y=alt.Y('True:O', sort=class_names),\n",
    "    color='Count:Q',\n",
    "    tooltip=['True', 'Predicted', 'Count']\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=300,\n",
    "    title='OF_Using_FIRE 5STK-1 DT'\n",
    ")\n",
    "\n",
    "# Add text labels\n",
    "text = heatmap.mark_text(\n",
    "    align='center',\n",
    "    baseline='middle',\n",
    "    fontSize=12\n",
    ").encode(\n",
    "    text='Count:Q',\n",
    "    color=alt.condition(\n",
    "        alt.datum.Count > cm.max() / 2,\n",
    "        alt.value('white'),\n",
    "        alt.value('black')\n",
    "    )\n",
    ")\n",
    "\n",
    "# Combine heatmap and text\n",
    "final_chart = heatmap + text\n",
    "\n",
    "# Display the plot\n",
    "final_chart.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5445e621-6288-4a87-9e75-bf4511b2d9a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T13:03:55.294282Z",
     "iopub.status.busy": "2024-09-09T13:03:55.294177Z",
     "iopub.status.idle": "2024-09-09T13:03:55.333435Z",
     "shell.execute_reply": "2024-09-09T13:03:55.333178Z",
     "shell.execute_reply.started": "2024-09-09T13:03:55.294273Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to Results/Ensemble Model Results/On Hatespeech dataset/OH Using HS Ensemble/Blending/OH_Using_HS 5STK-1 DT.png\n"
     ]
    }
   ],
   "source": [
    "# Specify the folder path\n",
    "folder_path = os.path.expanduser('Results/Ensemble Model Results/On FireCS dataset/OF Using FIRE ENSEMBLE/Stacking/')\n",
    "\n",
    "# Save the plot using vl-convert\n",
    "file_path_png = os.path.join(folder_path, 'OF_Using_FIRE 5STK-1 DT.png')\n",
    "final_chart.save(file_path_png)\n",
    "\n",
    "print(f\"Plot saved to {file_path_png}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6165ef-d0ff-4230-9fdb-3c6a774d728f",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "660f90df-3de4-41b1-9fc6-4285133ec0a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T13:03:55.333869Z",
     "iopub.status.busy": "2024-09-09T13:03:55.333794Z",
     "iopub.status.idle": "2024-09-09T13:03:55.339389Z",
     "shell.execute_reply": "2024-09-09T13:03:55.339170Z",
     "shell.execute_reply.started": "2024-09-09T13:03:55.333863Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on HS-Data C Dataset\n",
      "Precision: 0.7416216216216216\n",
      "Recall: 0.7976744186046512\n",
      "Accuracy: 0.7763941526800217\n",
      "F1 Score: 0.7686274509803922\n",
      "Confusion Matrix:\n",
      "[[748 239]\n",
      " [174 686]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the predictions\n",
    "precision = precision_score(y_val, val_svm_predictions, average='macro')\n",
    "recall = recall_score(y_val, val_svm_predictions, average='macro')\n",
    "accuracy = accuracy_score(y_val, val_svm_predictions)\n",
    "f1 = f1_score(y_val, val_svm_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_val, val_svm_predictions)\n",
    "\n",
    "print(\"Evaluation on HS-Data C Dataset\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ad2fba87-04de-46b7-bc1d-1fbf7d1bb263",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T13:03:55.416200Z",
     "iopub.status.busy": "2024-09-09T13:03:55.416110Z",
     "iopub.status.idle": "2024-09-09T13:03:55.421876Z",
     "shell.execute_reply": "2024-09-09T13:03:55.421669Z",
     "shell.execute_reply.started": "2024-09-09T13:03:55.416193Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted threshold: 0.13\n",
      "Optimized SVM\n",
      "Precision: 0.7416216216216216\n",
      "Recall: 0.7976744186046512\n",
      "Accuracy: 0.7763941526800217\n",
      "F1 Score: 0.7686274509803922\n",
      "Confusion Matrix:\n",
      "[[748 239]\n",
      " [174 686]]\n"
     ]
    }
   ],
   "source": [
    "svm_validation_probabilities = svm_meta_classifier.predict_proba(val_meta_features)\n",
    "\n",
    "# Apply thresholds to the validation set probabilities to make final predictions\n",
    "svm_validation_predictions = np.array([np.argmax([svm_validation_probabilities[i, j] if svm_validation_probabilities[i, j] >= svm_thresh[j] else 0\n",
    "                                              for j in range(svm_validation_probabilities.shape[1])])\n",
    "                                   for i in range(len(svm_validation_probabilities))])\n",
    "\n",
    "# Evaluate threshold on validation set\n",
    "adjusted_precision = precision_score(y_val, svm_validation_predictions, average='macro')\n",
    "adjusted_recall = recall_score(y_val, svm_validation_predictions, average='macro')\n",
    "adjusted_accuracy = accuracy_score(y_val, svm_validation_predictions)\n",
    "adjusted_f1 = f1_score(y_val, svm_validation_predictions, average='macro')\n",
    "adjusted_conf_matrix = confusion_matrix(y_val, svm_validation_predictions)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Validation Results\")\n",
    "print(f\"Precision: {adjusted_precision:.4f}\")\n",
    "print(f\"Recall: {adjusted_recall:.4f}\")\n",
    "print(f\"Accuracy: {adjusted_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {adjusted_f1:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(adjusted_conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7644868d-4140-415e-be20-4db4bfbf21b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T13:03:55.422327Z",
     "iopub.status.busy": "2024-09-09T13:03:55.422243Z",
     "iopub.status.idle": "2024-09-09T13:03:55.741160Z",
     "shell.execute_reply": "2024-09-09T13:03:55.740767Z",
     "shell.execute_reply.started": "2024-09-09T13:03:55.422321Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated cells count: 4\n"
     ]
    }
   ],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '5-1!F7:I7'  \n",
    "\n",
    "values = [[\n",
    "    f\"{adjusted_precision * 100:.2f}\",\n",
    "    f\"{adjusted_recall * 100:.2f}\",\n",
    "    f\"{adjusted_accuracy * 100:.2f}\",\n",
    "    f\"{adjusted_f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682be1a4-7bf8-4e44-9da2-2b7f48eac91c",
   "metadata": {},
   "source": [
    "#### Save CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "939272d5-856b-49da-99a2-4a25d818d2ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T13:03:55.741915Z",
     "iopub.status.busy": "2024-09-09T13:03:55.741815Z",
     "iopub.status.idle": "2024-09-09T13:03:55.771939Z",
     "shell.execute_reply": "2024-09-09T13:03:55.771687Z",
     "shell.execute_reply.started": "2024-09-09T13:03:55.741905Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-88604fa70b8443cf93fd3ed854b05e2e.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-88604fa70b8443cf93fd3ed854b05e2e.vega-embed details,\n",
       "  #altair-viz-88604fa70b8443cf93fd3ed854b05e2e.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-88604fa70b8443cf93fd3ed854b05e2e\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-88604fa70b8443cf93fd3ed854b05e2e\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-88604fa70b8443cf93fd3ed854b05e2e\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"rect\"}, \"encoding\": {\"color\": {\"field\": \"Count\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"True\", \"type\": \"ordinal\"}, {\"field\": \"Predicted\", \"type\": \"ordinal\"}, {\"field\": \"Count\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Predicted\", \"sort\": [\"Hate Speech\", \"Non Hatespeech\"], \"type\": \"ordinal\"}, \"y\": {\"field\": \"True\", \"sort\": [\"Hate Speech\", \"Non Hatespeech\"], \"type\": \"ordinal\"}}, \"title\": \"OH_Using_HS 5STK-1 LR\"}, {\"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"middle\", \"fontSize\": 12}, \"encoding\": {\"color\": {\"condition\": {\"test\": \"(datum.Count > 374.0)\", \"value\": \"white\"}, \"value\": \"black\"}, \"text\": {\"field\": \"Count\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"True\", \"type\": \"ordinal\"}, {\"field\": \"Predicted\", \"type\": \"ordinal\"}, {\"field\": \"Count\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Predicted\", \"sort\": [\"Hate Speech\", \"Non Hatespeech\"], \"type\": \"ordinal\"}, \"y\": {\"field\": \"True\", \"sort\": [\"Hate Speech\", \"Non Hatespeech\"], \"type\": \"ordinal\"}}, \"title\": \"OH_Using_HS 5STK-1 LR\"}], \"data\": {\"name\": \"data-8eebd188bc1028763be9898fe1dff8c1\"}, \"height\": 300, \"width\": 400, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-8eebd188bc1028763be9898fe1dff8c1\": [{\"True\": \"Hate Speech\", \"Predicted\": \"Hate Speech\", \"Count\": 748}, {\"True\": \"Non Hatespeech\", \"Predicted\": \"Hate Speech\", \"Count\": 174}, {\"True\": \"Hate Speech\", \"Predicted\": \"Non Hatespeech\", \"Count\": 239}, {\"True\": \"Non Hatespeech\", \"Predicted\": \"Non Hatespeech\", \"Count\": 686}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import altair as alt\n",
    "import altair_saver\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_val, svm_validation_predictions)\n",
    "\n",
    "# Define class names\n",
    "class_names = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "# Convert confusion matrix to DataFrame\n",
    "cm_df = pd.DataFrame(cm, index=class_names, columns=class_names).reset_index().melt(id_vars='index')\n",
    "cm_df.columns = ['True', 'Predicted', 'Count']\n",
    "\n",
    "# Ensure the order of categories\n",
    "cm_df['True'] = pd.Categorical(cm_df['True'], categories=class_names, ordered=True)\n",
    "cm_df['Predicted'] = pd.Categorical(cm_df['Predicted'], categories=class_names, ordered=True)\n",
    "\n",
    "# Create the Altair plot\n",
    "heatmap = alt.Chart(cm_df).mark_rect().encode(\n",
    "    x=alt.X('Predicted:O', sort=class_names),\n",
    "    y=alt.Y('True:O', sort=class_names),\n",
    "    color='Count:Q',\n",
    "    tooltip=['True', 'Predicted', 'Count']\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=300,\n",
    "    title='OF_Using_FIRE 5STK-1 SVM'\n",
    ")\n",
    "\n",
    "# Add text labels\n",
    "text = heatmap.mark_text(\n",
    "    align='center',\n",
    "    baseline='middle',\n",
    "    fontSize=12\n",
    ").encode(\n",
    "    text='Count:Q',\n",
    "    color=alt.condition(\n",
    "        alt.datum.Count > cm.max() / 2,\n",
    "        alt.value('white'),\n",
    "        alt.value('black')\n",
    "    )\n",
    ")\n",
    "\n",
    "# Combine heatmap and text\n",
    "final_chart = heatmap + text\n",
    "\n",
    "# Display the plot\n",
    "final_chart.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4ab1dbec-94d8-4f9c-b5e8-843b853a71cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T13:03:55.772342Z",
     "iopub.status.busy": "2024-09-09T13:03:55.772272Z",
     "iopub.status.idle": "2024-09-09T13:03:55.807945Z",
     "shell.execute_reply": "2024-09-09T13:03:55.807683Z",
     "shell.execute_reply.started": "2024-09-09T13:03:55.772335Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to Results/Ensemble Model Results/On Hatespeech dataset/OH Using HS Ensemble/Blending/OH_Using_HS 5STK-1 SVM.png\n"
     ]
    }
   ],
   "source": [
    "# Specify the folder path\n",
    "folder_path = os.path.expanduser('Results/Ensemble Model Results/On FireCS dataset/OF Using FIRE ENSEMBLE/Stacking/')\n",
    "\n",
    "# Save the plot using vl-convert\n",
    "file_path_png = os.path.join(folder_path, 'OF_Using_FIRE 5STK-1 SVM.png')\n",
    "final_chart.save(file_path_png)\n",
    "\n",
    "print(f\"Plot saved to {file_path_png}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a298f212-36ec-4e75-ad74-d7b272d094a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80391c9f-64d7-4e98-b9f0-6ee41cb035f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
