{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dc06b17-fcee-4505-bd74-d98376ce3ed9",
   "metadata": {},
   "source": [
    "# Train Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "514f97c1-a1e6-452d-b8fb-95b9a1346323",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:04:19.447595Z",
     "iopub.status.busy": "2024-09-25T07:04:19.447436Z",
     "iopub.status.idle": "2024-09-25T07:04:20.317904Z",
     "shell.execute_reply": "2024-09-25T07:04:20.317604Z",
     "shell.execute_reply.started": "2024-09-25T07:04:19.447587Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.backends.mps.is_available():\n",
    "        # Currently, there's no separate manual seed function for MPS like torch.cuda.manual_seed_all()\n",
    "        pass \n",
    "    else:\n",
    "        print(\"MPS device not available. Using CPU.\")\n",
    "        \n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c6a724-b17e-46f6-aee6-90ef2f7877a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T15:08:53.465538Z",
     "iopub.status.busy": "2024-08-13T15:08:53.465321Z",
     "iopub.status.idle": "2024-08-13T15:08:53.469076Z",
     "shell.execute_reply": "2024-08-13T15:08:53.468592Z",
     "shell.execute_reply.started": "2024-08-13T15:08:53.465526Z"
    }
   },
   "source": [
    "Best F1 score BERT model on HS_C dataset are used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3823c3e6-976a-4eb9-a651-2cfeaa1a3cc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:04:20.318529Z",
     "iopub.status.busy": "2024-09-25T07:04:20.318386Z",
     "iopub.status.idle": "2024-09-25T07:04:20.445185Z",
     "shell.execute_reply": "2024-09-25T07:04:20.444763Z",
     "shell.execute_reply.started": "2024-09-25T07:04:20.318522Z"
    }
   },
   "outputs": [],
   "source": [
    "# This automates data tabulation onto google sheets \n",
    "\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "import os\n",
    "\n",
    "# new directory path\n",
    "new_directory = '/Users/levan/ATENEO MASTERAL/Thesis'\n",
    "\n",
    "# Change the current working directory\n",
    "os.chdir(new_directory)\n",
    "\n",
    "# Use creds to create a client to interact with the Google Drive API\n",
    "scope = ['https://spreadsheets.google.com/feeds','https://www.googleapis.com/auth/drive']\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_name('thesis-432315-12daec8d1ff6.json', scope)\n",
    "\n",
    "service = build('sheets', 'v4', credentials=creds)\n",
    "\n",
    "client = gspread.authorize(creds)\n",
    "\n",
    "spreadsheet_id = '13Fk5oXX9B_mdHmNpMKQMy29y9iiHWrgQCa4hUTiQKD0' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d70bdb-0504-41ef-913d-e4b7f778f561",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7b193db-3f30-4e5f-a38b-c254bf1e1976",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:04:20.445705Z",
     "iopub.status.busy": "2024-09-25T07:04:20.445611Z",
     "iopub.status.idle": "2024-09-25T07:04:22.902965Z",
     "shell.execute_reply": "2024-09-25T07:04:22.902600Z",
     "shell.execute_reply.started": "2024-09-25T07:04:20.445696Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AutoConfig\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_recall_curve, f1_score, confusion_matrix, precision_score, recall_score, accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "# new directory path\n",
    "new_directory = '/Users/levan/ATENEO MASTERAL/Thesis/Development'\n",
    "\n",
    "# Change the current working directory\n",
    "os.chdir(new_directory)\n",
    "\n",
    "#Load Data\n",
    "df = pd.read_csv('Corpus/FiReCS/FiReCS_data_b.csv')\n",
    "X = df['review'].values\n",
    "y = df['label'].values\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a307e67b-00c3-47aa-8f83-34bc62c93f83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-11T10:08:58.783500Z",
     "iopub.status.busy": "2024-04-11T10:08:58.782872Z",
     "iopub.status.idle": "2024-04-11T10:08:58.788089Z",
     "shell.execute_reply": "2024-04-11T10:08:58.787147Z",
     "shell.execute_reply.started": "2024-04-11T10:08:58.783465Z"
    }
   },
   "source": [
    "## Load Models and Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e666f7e-9db0-4666-a112-2af127307162",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:04:22.903535Z",
     "iopub.status.busy": "2024-09-25T07:04:22.903460Z",
     "iopub.status.idle": "2024-09-25T07:04:25.733068Z",
     "shell.execute_reply": "2024-09-25T07:04:25.732739Z",
     "shell.execute_reply.started": "2024-09-25T07:04:22.903528Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_model_and_tokenizer(model_path, tokenizer_path, base_model):\n",
    "    # Load the tokenizer from the local directory\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "    \n",
    "    # Load the configuration from the base model, then update configuration if needed\n",
    "    config = AutoConfig.from_pretrained(base_model, num_labels=3)\n",
    "\n",
    "    # Initialize the model with the configuration\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_path, config=config)\n",
    "\n",
    "    # Ensure the model is in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    return model, tokenizer\n",
    "\n",
    "model_info = {\n",
    "    \n",
    "    'BERT cased': {\n",
    "        'model_path': 'BERT models/1 FiReCS/fire_bert-base-cased-finetuned',\n",
    "        'tokenizer_path': 'BERT models/1 FiReCS/fire_bert-base-cased-finetuned',\n",
    "        'base_model': 'google-bert/bert-base-cased'\n",
    "    },\n",
    "\n",
    "    'DistilBERT uncased': {\n",
    "        'model_path': 'BERT models/1 FiReCS/fire_distilbert-base-uncased-finetuned',\n",
    "        'tokenizer_path': 'BERT models/1 FiReCS/fire_distilbert-base-uncased-finetuned',\n",
    "        'base_model': 'distilbert/distilbert-base-uncased'\n",
    "    },\n",
    "\n",
    "    'DeBERTa': {\n",
    "        'model_path': 'BERT models/1 FiReCS/fire_DeBERTa-finetuned',\n",
    "        'tokenizer_path': 'BERT models/1 FiReCS/fire_DeBERTa-finetuned',\n",
    "        'base_model': 'microsoft/deberta-v3-base'\n",
    "    },\n",
    "    \n",
    "    'BERT uncased': {\n",
    "        'model_path': 'BERT models/1 FiReCS/fire_bert-base-uncased-finetuned',\n",
    "        'tokenizer_path': 'BERT models/1 FiReCS/fire_bert-base-uncased-finetuned',\n",
    "        'base_model': 'google-bert/bert-base-uncased'\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "models_and_tokenizers = {name: load_model_and_tokenizer(info['model_path'], \n",
    "                                                        info['tokenizer_path'], \n",
    "                                                        info['base_model']) \n",
    "                         for name, info in model_info.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a9b906-a837-4de8-b8a2-05aa44074c5c",
   "metadata": {},
   "source": [
    "## Apply Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05f7b2f9-3bc4-4d6d-8595-8971899238c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:04:25.734739Z",
     "iopub.status.busy": "2024-09-25T07:04:25.734640Z",
     "iopub.status.idle": "2024-09-25T07:04:25.737693Z",
     "shell.execute_reply": "2024-09-25T07:04:25.737346Z",
     "shell.execute_reply.started": "2024-09-25T07:04:25.734732Z"
    }
   },
   "outputs": [],
   "source": [
    "class MultiModelTextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, labels, models_and_tokenizers, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.models_and_tokenizers = models_and_tokenizers\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.texts[index])\n",
    "        label = self.labels[index]\n",
    "\n",
    "        model_inputs = {}\n",
    "        for name, (model, tokenizer) in self.models_and_tokenizers.items():\n",
    "            encoding = tokenizer.encode_plus(\n",
    "                text,\n",
    "                add_special_tokens=True,\n",
    "                max_length=self.max_len,\n",
    "                return_token_type_ids=False,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                return_attention_mask=True,\n",
    "                return_tensors='pt',\n",
    "            )\n",
    "            model_inputs[name] = {\n",
    "                'input_ids': encoding['input_ids'].squeeze(0),  # Remove batch dimension\n",
    "                'attention_mask': encoding['attention_mask'].squeeze(0)  # Remove batch dimension\n",
    "            }\n",
    "        return {'model_inputs': model_inputs, 'label': torch.tensor(label, dtype=torch.long)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d574483-f790-48ba-a7d0-07cc8f2973d4",
   "metadata": {},
   "source": [
    "## BERT Training for Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e6167c5-79fd-4536-815c-237ec599453a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:04:25.739031Z",
     "iopub.status.busy": "2024-09-25T07:04:25.738960Z",
     "iopub.status.idle": "2024-09-25T07:04:25.742618Z",
     "shell.execute_reply": "2024-09-25T07:04:25.742382Z",
     "shell.execute_reply.started": "2024-09-25T07:04:25.739024Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_base_learner(model, data_loader, optimizer, device):\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    correct_predictions = 0\n",
    "    losses = []\n",
    "\n",
    "    for batch in data_loader:\n",
    "        # Accessing inputs for the current model\n",
    "        inputs = batch['model_inputs']\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        for model_name, model_inputs in inputs.items():\n",
    "            # Forward pass\n",
    "            outputs = model(input_ids=model_inputs['input_ids'].squeeze(1).to(device),\n",
    "                attention_mask=model_inputs['attention_mask'].squeeze(1).to(device),\n",
    "                labels=labels)\n",
    "\n",
    "            loss = outputs.loss\n",
    "            preds = outputs.logits.argmax(dim=1)\n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    return correct_predictions.float() / len(data_loader.dataset), np.mean(losses).astype(np.float32)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def eval_model(model, data_loader, device):\n",
    "    model = model.eval()\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for d in data_loader:\n",
    "            input_ids = d[\"input_ids\"].to(device)\n",
    "            attention_mask = d[\"attention_mask\"].to(device)\n",
    "            labels = d[\"label\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            preds = outputs.logits.argmax(dim=1)\n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "\n",
    "    return correct_predictions.double() / len(data_loader.dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b36fee-48a1-4eda-bf0b-c59982cbba14",
   "metadata": {},
   "source": [
    "## Train Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99eb6be0-fb6e-441b-bfaa-853e75a01983",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:04:25.743174Z",
     "iopub.status.busy": "2024-09-25T07:04:25.743073Z",
     "iopub.status.idle": "2024-09-25T07:04:25.750957Z",
     "shell.execute_reply": "2024-09-25T07:04:25.750732Z",
     "shell.execute_reply.started": "2024-09-25T07:04:25.743165Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, confusion_matrix\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "\n",
    "def train_stacking_classifier(models_and_tokenizers, X_train, y_train, device, max_len=128):\n",
    "    n_splits = 4\n",
    "    skf = StratifiedKFold(n_splits=n_splits)\n",
    "    base_learners_predictions_train = np.zeros((len(X_train), len(models_and_tokenizers)))\n",
    "    fold_idx = 0\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_train, y_train):\n",
    "        fold_idx += 1\n",
    "        print(f\"Training fold {fold_idx}/{n_splits}...\")\n",
    "        train_texts, val_texts = X_train[train_idx], X_train[val_idx]\n",
    "        train_labels, val_labels = y_train[train_idx], y_train[val_idx]\n",
    "        \n",
    "        model_idx = 0\n",
    "        for name, info in model_info.items():\n",
    "            # Reload the model and tokenizer to reset weights\n",
    "            model, tokenizer = load_model_and_tokenizer(info['model_path'], info['tokenizer_path'], info['base_model'])\n",
    "            model.to(device)\n",
    "            \n",
    "            train_dataset = MultiModelTextDataset(train_texts, train_labels, {name: (model, tokenizer)}, max_len)\n",
    "            val_dataset = MultiModelTextDataset(val_texts, val_labels, {name: (model, tokenizer)}, max_len)\n",
    "            train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "            \n",
    "            optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "            train_base_learner(model, train_loader, optimizer, device)\n",
    "            \n",
    "            val_preds = []\n",
    "            model.eval()\n",
    "            for batch in val_loader:\n",
    "                inputs = batch['model_inputs'][name]\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(input_ids=inputs['input_ids'].to(device), attention_mask=inputs['attention_mask'].to(device))\n",
    "                val_preds.extend(outputs.logits.argmax(dim=1).cpu().numpy())\n",
    "            \n",
    "            base_learners_predictions_train[val_idx, model_idx] = np.array(val_preds)\n",
    "            model_idx += 1\n",
    "\n",
    "    return base_learners_predictions_train, y_train\n",
    "    \n",
    "\n",
    "def get_predictions(model_info, X, y, device, max_len=128):\n",
    "    predictions = np.zeros((len(X), len(model_info)))\n",
    "    model_idx = 0\n",
    "    for name, info in model_info.items():\n",
    "        # Reload the model and tokenizer\n",
    "        model, tokenizer = load_model_and_tokenizer(info['model_path'], info['tokenizer_path'], info['base_model'])\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        \n",
    "        dataset = MultiModelTextDataset(X, y, {name: (model, tokenizer)}, max_len)\n",
    "        loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
    "        \n",
    "        preds = []\n",
    "        for batch in loader:\n",
    "            inputs = batch['model_inputs'][name]\n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_ids=inputs['input_ids'].to(device), attention_mask=inputs['attention_mask'].to(device))\n",
    "            preds.extend(outputs.logits.argmax(dim=1).cpu().numpy())\n",
    "        \n",
    "        predictions[:, model_idx] = np.array(preds)\n",
    "        model_idx += 1\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58472c03-8cb9-4a28-b8f3-fd5227c0e620",
   "metadata": {},
   "source": [
    "## Perform Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da0e67bd-3f57-4bf1-aa4e-1537a9132002",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:04:25.751526Z",
     "iopub.status.busy": "2024-09-25T07:04:25.751415Z",
     "iopub.status.idle": "2024-09-25T07:04:25.754677Z",
     "shell.execute_reply": "2024-09-25T07:04:25.754452Z",
     "shell.execute_reply.started": "2024-09-25T07:04:25.751519Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36436c2d-846d-46ab-ae3c-b36c5bdda6a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:04:25.755115Z",
     "iopub.status.busy": "2024-09-25T07:04:25.755043Z",
     "iopub.status.idle": "2024-09-25T07:16:19.687438Z",
     "shell.execute_reply": "2024-09-25T07:16:19.687126Z",
     "shell.execute_reply.started": "2024-09-25T07:04:25.755109Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/transformers/optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 2/4...\n",
      "Training fold 3/4...\n",
      "Training fold 4/4...\n",
      "peak memory: 6568.47 MiB, increment: 4220.16 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# Train stacking classifier (using 4-fold cross validation for each BERT model) on Train Set and retrieve training meta-features\n",
    "train_meta_features, _ = train_stacking_classifier(model_info, X_train, y_train, device)\n",
    "\n",
    "# Generate predictions for the test set to be used as test meta-features\n",
    "test_meta_features = get_predictions(model_info, X_test, y_test, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "554932f2-8df8-4019-8e5a-6fa8b092c4c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:16:19.688028Z",
     "iopub.status.busy": "2024-09-25T07:16:19.687946Z",
     "iopub.status.idle": "2024-09-25T07:16:19.691458Z",
     "shell.execute_reply": "2024-09-25T07:16:19.691241Z",
     "shell.execute_reply.started": "2024-09-25T07:16:19.688020Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predictions from base learners on the test set:\n",
      "Base learner 1: [0. 1. 2.]\n",
      "Base learner 2: [0. 1. 2.]\n",
      "Base learner 3: [0. 1. 2.]\n",
      "Base learner 4: [0. 1. 2.]\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique predictions from base learners on the test set:\")\n",
    "for i in range(test_meta_features.shape[1]):\n",
    "    unique_preds = np.unique(test_meta_features[:, i])\n",
    "    print(f\"Base learner {i+1}: {unique_preds}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cade4792-6166-4217-be37-bed5318d717f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:16:19.691914Z",
     "iopub.status.busy": "2024-09-25T07:16:19.691842Z",
     "iopub.status.idle": "2024-09-25T07:16:19.696597Z",
     "shell.execute_reply": "2024-09-25T07:16:19.696377Z",
     "shell.execute_reply.started": "2024-09-25T07:16:19.691907Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Matrix of Base Learner Predictions on the Test Set:\n",
      "          Base_1    Base_2    Base_3    Base_4\n",
      "Base_1  1.000000  0.852029  0.843146  0.862713\n",
      "Base_2  0.852029  1.000000  0.843186  0.853686\n",
      "Base_3  0.843146  0.843186  1.000000  0.848554\n",
      "Base_4  0.862713  0.853686  0.848554  1.000000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Convert the meta-features to a DataFrame\n",
    "df_test_meta = pd.DataFrame(test_meta_features, columns=[f\"Base_{i+1}\" for i in range(test_meta_features.shape[1])])\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = df_test_meta.corr()\n",
    "print(\"Correlation Matrix of Base Learner Predictions on the Test Set:\")\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6141c9d1-7dbd-47d6-9fb4-c9ecedfa543e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:16:19.697010Z",
     "iopub.status.busy": "2024-09-25T07:16:19.696941Z",
     "iopub.status.idle": "2024-09-25T07:16:19.699375Z",
     "shell.execute_reply": "2024-09-25T07:16:19.699151Z",
     "shell.execute_reply.started": "2024-09-25T07:16:19.697004Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique meta-feature combinations: 55 out of 1416 samples\n"
     ]
    }
   ],
   "source": [
    "# Count unique rows in the meta-features\n",
    "unique_meta_features = np.unique(test_meta_features, axis=0)\n",
    "num_unique_combinations = len(unique_meta_features)\n",
    "num_samples = len(test_meta_features)\n",
    "print(f\"Number of unique meta-feature combinations: {num_unique_combinations} out of {num_samples} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d42e0b-1855-4774-8f83-599a6158e526",
   "metadata": {},
   "source": [
    "### Train LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "265a5311-c2a4-48a0-9f21-d803350fb89f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:16:19.699754Z",
     "iopub.status.busy": "2024-09-25T07:16:19.699665Z",
     "iopub.status.idle": "2024-09-25T07:16:20.478648Z",
     "shell.execute_reply": "2024-09-25T07:16:20.478270Z",
     "shell.execute_reply.started": "2024-09-25T07:16:19.699748Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 6210.91 MiB, increment: 0.59 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "\n",
    "lr_meta_classifier = LogisticRegression()\n",
    "lr_meta_classifier.fit(train_meta_features, y_train)\n",
    "\n",
    "lr_final_predictions = lr_meta_classifier.predict(test_meta_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ea06bb-fab4-4f49-99e4-19680ec1b870",
   "metadata": {},
   "source": [
    "### Train NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "244b0f68-e401-4d18-913f-a3a153dd8104",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:16:20.479371Z",
     "iopub.status.busy": "2024-09-25T07:16:20.479277Z",
     "iopub.status.idle": "2024-09-25T07:16:21.899161Z",
     "shell.execute_reply": "2024-09-25T07:16:21.898802Z",
     "shell.execute_reply.started": "2024-09-25T07:16:20.479362Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 6210.92 MiB, increment: 0.00 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "\n",
    "nb_meta_classifier = GaussianNB()\n",
    "nb_meta_classifier.fit(train_meta_features, y_train)\n",
    "\n",
    "nb_final_predictions = nb_meta_classifier.predict(test_meta_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e50604f-9bef-4db4-bf92-89f9d2874e89",
   "metadata": {},
   "source": [
    "### Train DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3990ca03-b860-4b65-97e7-47f551754ab7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:16:21.899822Z",
     "iopub.status.busy": "2024-09-25T07:16:21.899741Z",
     "iopub.status.idle": "2024-09-25T07:16:23.304401Z",
     "shell.execute_reply": "2024-09-25T07:16:23.304073Z",
     "shell.execute_reply.started": "2024-09-25T07:16:21.899813Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 6211.09 MiB, increment: 0.17 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "\n",
    "dt_meta_classifier = DecisionTreeClassifier(max_depth=None)\n",
    "dt_meta_classifier.fit(train_meta_features, y_train)\n",
    "\n",
    "dt_final_predictions = dt_meta_classifier.predict(test_meta_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986bd8f0-b569-4eaf-8e13-a51529e871e6",
   "metadata": {},
   "source": [
    "### Train SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "460a4087-b343-4249-b794-db90baabf11c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:16:23.305028Z",
     "iopub.status.busy": "2024-09-25T07:16:23.304949Z",
     "iopub.status.idle": "2024-09-25T07:16:24.183326Z",
     "shell.execute_reply": "2024-09-25T07:16:24.183005Z",
     "shell.execute_reply.started": "2024-09-25T07:16:23.305020Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 6212.30 MiB, increment: 1.20 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "\n",
    "svm_meta_classifier = SVC(kernel='linear', probability=True)\n",
    "svm_meta_classifier.fit(train_meta_features, y_train)\n",
    "\n",
    "svm_final_predictions = svm_meta_classifier.predict(test_meta_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad340b68-d07e-473a-bbc4-138ef8e0271a",
   "metadata": {},
   "source": [
    "## EVALUATE MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93ba0c5-a053-45fb-8e97-b09c67959bc8",
   "metadata": {},
   "source": [
    "### LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d015915-5eb9-4a73-9ef6-5fc1bd4d0e8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:16:24.184026Z",
     "iopub.status.busy": "2024-09-25T07:16:24.183937Z",
     "iopub.status.idle": "2024-09-25T07:16:24.189754Z",
     "shell.execute_reply": "2024-09-25T07:16:24.189536Z",
     "shell.execute_reply.started": "2024-09-25T07:16:24.184018Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Precision: 0.8235245033543211\n",
      "Recall: 0.8184910594217816\n",
      "Ensemble accuracy: 0.8177966101694916\n",
      "F1 Score: 0.8204395958329472\n",
      "Confusion Matrix:\n",
      "[[375  84   1]\n",
      " [ 62 383  46]\n",
      " [  4  61 400]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "precision = precision_score(y_test, lr_final_predictions, average='macro')\n",
    "recall = recall_score(y_test, lr_final_predictions, average='macro')\n",
    "accuracy = accuracy_score(y_test, lr_final_predictions)\n",
    "f1 = f1_score(y_test, lr_final_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_test, lr_final_predictions)\n",
    "\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Ensemble accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8c650bc-c7b7-4f3d-b8c7-c415ed29f2f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:16:24.190213Z",
     "iopub.status.busy": "2024-09-25T07:16:24.190140Z",
     "iopub.status.idle": "2024-09-25T07:16:24.199206Z",
     "shell.execute_reply": "2024-09-25T07:16:24.198953Z",
     "shell.execute_reply.started": "2024-09-25T07:16:24.190207Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized thresholds for each class: [0.25464822533832987, 0.5635565104377177, 0.30280071723613877]\n",
      "Logistic Regression\n",
      "Precision: 0.8285\n",
      "Recall: 0.8268\n",
      "Ensemble accuracy: 0.8256\n",
      "F1 Score: 0.8275098616724273\n",
      "Confusion Matrix:\n",
      "[[392  67   1]\n",
      " [ 69 376  46]\n",
      " [  4  60 401]]\n"
     ]
    }
   ],
   "source": [
    "probabilities = lr_meta_classifier.predict_proba(test_meta_features)\n",
    "\n",
    "# Calculate precision-recall curve and find optimal thresholds for each class\n",
    "lr_thresh = []\n",
    "for i in range(probabilities.shape[1]):  # Iterate over each class\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test == i, probabilities[:, i])\n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "    optimal_idx = np.nanargmax(f1_scores)  # Handle cases where precision and recall are both zero\n",
    "    lr_thresh.append(thresholds[optimal_idx])\n",
    "\n",
    "# Apply the optimized thresholds to make adjusted predictions\n",
    "adjusted_predictions = np.array([np.argmax([probabilities[i, j] if probabilities[i, j] >= lr_thresh[j] else 0\n",
    "                                         for j in range(probabilities.shape[1])])\n",
    "                              for i in range(len(probabilities))])\n",
    "\n",
    "# Evaluate\n",
    "adjusted_precision = precision_score(y_test, adjusted_predictions, average='macro')\n",
    "adjusted_recall = recall_score(y_test, adjusted_predictions, average='macro')\n",
    "adjusted_accuracy = accuracy_score(y_test, adjusted_predictions)\n",
    "adjusted_f1 = f1_score(y_test, adjusted_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_test, adjusted_predictions)\n",
    "\n",
    "print(\"Optimized thresholds for each class:\", lr_thresh)\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Precision: {adjusted_precision:.4f}\")\n",
    "print(f\"Recall: {adjusted_recall:.4f}\")\n",
    "print(f\"Ensemble accuracy: {adjusted_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {adjusted_f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cfc6b32b-5f2a-4017-8a2b-e393ee1f85b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:16:24.202438Z",
     "iopub.status.busy": "2024-09-25T07:16:24.202333Z",
     "iopub.status.idle": "2024-09-25T07:16:30.652940Z",
     "shell.execute_reply": "2024-09-25T07:16:30.650759Z",
     "shell.execute_reply.started": "2024-09-25T07:16:24.202430Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated cells count: 4\n"
     ]
    }
   ],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '4-1!B4:E4'  \n",
    "\n",
    "values = [[\n",
    "    f\"{adjusted_precision * 100:.2f}\",\n",
    "    f\"{adjusted_recall * 100:.2f}\",\n",
    "    f\"{adjusted_accuracy * 100:.2f}\",\n",
    "    f\"{adjusted_f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f311d02-936c-467e-ae14-e0c9cd0f0211",
   "metadata": {},
   "source": [
    "### NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3cde7aba-1d7b-4fbd-94f0-98b9e5b2756a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:16:30.661094Z",
     "iopub.status.busy": "2024-09-25T07:16:30.659486Z",
     "iopub.status.idle": "2024-09-25T07:16:30.678996Z",
     "shell.execute_reply": "2024-09-25T07:16:30.678471Z",
     "shell.execute_reply.started": "2024-09-25T07:16:30.661050Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes\n",
      "Precision: 0.8202543159072034\n",
      "Recall: 0.8117103975660376\n",
      "Ensemble accuracy: 0.8114406779661016\n",
      "F1 Score: 0.814554625268911\n",
      "Confusion Matrix:\n",
      "[[362  97   1]\n",
      " [ 56 389  46]\n",
      " [  4  63 398]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "precision = precision_score(y_test, nb_final_predictions, average='macro')\n",
    "recall = recall_score(y_test, nb_final_predictions, average='macro')\n",
    "accuracy = accuracy_score(y_test, nb_final_predictions)\n",
    "f1 = f1_score(y_test, nb_final_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_test, nb_final_predictions)\n",
    "\n",
    "print(\"Naive Bayes\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Ensemble accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07991bda-71ea-4786-996b-61a3ae0132ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:16:30.679971Z",
     "iopub.status.busy": "2024-09-25T07:16:30.679743Z",
     "iopub.status.idle": "2024-09-25T07:16:30.697913Z",
     "shell.execute_reply": "2024-09-25T07:16:30.697490Z",
     "shell.execute_reply.started": "2024-09-25T07:16:30.679955Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized thresholds for each class: [0.037746478555672584, 0.9263218803681593, 0.6535968125662914]\n",
      "Naive Bayes\n",
      "Precision: 0.8277\n",
      "Recall: 0.8271\n",
      "Ensemble accuracy: 0.8256\n",
      "F1 Score: 0.8270965613094822\n",
      "Confusion Matrix:\n",
      "[[402  57   1]\n",
      " [ 76 369  46]\n",
      " [  4  63 398]]\n"
     ]
    }
   ],
   "source": [
    "probabilities = nb_meta_classifier.predict_proba(test_meta_features)\n",
    "\n",
    "# Calculate precision-recall curve and find optimal thresholds for each class\n",
    "nb_thresh = []\n",
    "for i in range(probabilities.shape[1]):  # Iterate over each class\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test == i, probabilities[:, i])\n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "    optimal_idx = np.nanargmax(f1_scores)  # Handle cases where precision and recall are both zero\n",
    "    nb_thresh.append(thresholds[optimal_idx])\n",
    "\n",
    "# Apply the optimized thresholds to make adjusted predictions\n",
    "adjusted_predictions = np.array([np.argmax([probabilities[i, j] if probabilities[i, j] >= nb_thresh[j] else 0\n",
    "                                         for j in range(probabilities.shape[1])])\n",
    "                              for i in range(len(probabilities))])\n",
    "\n",
    "# Evaluate\n",
    "adjusted_precision = precision_score(y_test, adjusted_predictions, average='macro')\n",
    "adjusted_recall = recall_score(y_test, adjusted_predictions, average='macro')\n",
    "adjusted_accuracy = accuracy_score(y_test, adjusted_predictions)\n",
    "adjusted_f1 = f1_score(y_test, adjusted_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_test, adjusted_predictions)\n",
    "\n",
    "print(\"Optimized thresholds for each class:\", nb_thresh)\n",
    "print(\"Naive Bayes\")\n",
    "print(f\"Precision: {adjusted_precision:.4f}\")\n",
    "print(f\"Recall: {adjusted_recall:.4f}\")\n",
    "print(f\"Ensemble accuracy: {adjusted_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {adjusted_f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aecf64b8-5a1a-4cea-a077-2049e0459dd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:16:30.698638Z",
     "iopub.status.busy": "2024-09-25T07:16:30.698501Z",
     "iopub.status.idle": "2024-09-25T07:16:31.383627Z",
     "shell.execute_reply": "2024-09-25T07:16:31.379545Z",
     "shell.execute_reply.started": "2024-09-25T07:16:30.698626Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated cells count: 4\n"
     ]
    }
   ],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '4-1!B5:E5'  \n",
    "\n",
    "values = [[\n",
    "    f\"{adjusted_precision * 100:.2f}\",\n",
    "    f\"{adjusted_recall * 100:.2f}\",\n",
    "    f\"{adjusted_accuracy * 100:.2f}\",\n",
    "    f\"{adjusted_f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958d063b-7c6a-43d7-aaa2-0b93e3d56610",
   "metadata": {},
   "source": [
    "### DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c799950-2309-4a08-9778-351ab70a85db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:16:31.386060Z",
     "iopub.status.busy": "2024-09-25T07:16:31.385483Z",
     "iopub.status.idle": "2024-09-25T07:16:31.408064Z",
     "shell.execute_reply": "2024-09-25T07:16:31.407504Z",
     "shell.execute_reply.started": "2024-09-25T07:16:31.386022Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Precision: 0.8126025558556403\n",
      "Recall: 0.8045273549415425\n",
      "Ensemble accuracy: 0.8043785310734464\n",
      "F1 Score: 0.8071886614976552\n",
      "Confusion Matrix:\n",
      "[[365  90   5]\n",
      " [ 70 390  31]\n",
      " [ 19  62 384]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "precision = precision_score(y_test, dt_final_predictions, average='macro')\n",
    "recall = recall_score(y_test, dt_final_predictions, average='macro')\n",
    "accuracy = accuracy_score(y_test, dt_final_predictions)\n",
    "f1 = f1_score(y_test, dt_final_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_test, dt_final_predictions)\n",
    "\n",
    "print(\"Decision Tree\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Ensemble accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a63b5fc-8c61-409f-86bf-470f00eb6d99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:16:31.409215Z",
     "iopub.status.busy": "2024-09-25T07:16:31.409000Z",
     "iopub.status.idle": "2024-09-25T07:16:31.429499Z",
     "shell.execute_reply": "2024-09-25T07:16:31.429026Z",
     "shell.execute_reply.started": "2024-09-25T07:16:31.409200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized thresholds for each class: [0.359375, 0.4411764705882353, 0.5]\n",
      "Decision Tree\n",
      "Precision: 0.8126\n",
      "Recall: 0.8045\n",
      "Ensemble accuracy: 0.8044\n",
      "F1 Score: 0.8071886614976552\n",
      "Confusion Matrix:\n",
      "[[365  90   5]\n",
      " [ 70 390  31]\n",
      " [ 19  62 384]]\n"
     ]
    }
   ],
   "source": [
    "probabilities = dt_meta_classifier.predict_proba(test_meta_features)\n",
    "\n",
    "# Calculate precision-recall curve and find optimal thresholds for each class\n",
    "dt_thresh = []\n",
    "for i in range(probabilities.shape[1]):  # Iterate over each class\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test == i, probabilities[:, i])\n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "    optimal_idx = np.nanargmax(f1_scores)  # Handle cases where precision and recall are both zero\n",
    "    dt_thresh.append(thresholds[optimal_idx])\n",
    "\n",
    "# Apply the optimized thresholds to make adjusted predictions\n",
    "adjusted_predictions = np.array([np.argmax([probabilities[i, j] if probabilities[i, j] >= dt_thresh[j] else 0\n",
    "                                         for j in range(probabilities.shape[1])])\n",
    "                              for i in range(len(probabilities))])\n",
    "\n",
    "# Evaluate\n",
    "adjusted_precision = precision_score(y_test, adjusted_predictions, average='macro')\n",
    "adjusted_recall = recall_score(y_test, adjusted_predictions, average='macro')\n",
    "adjusted_accuracy = accuracy_score(y_test, adjusted_predictions)\n",
    "adjusted_f1 = f1_score(y_test, adjusted_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_test, adjusted_predictions)\n",
    "\n",
    "print(\"Optimized thresholds for each class:\", dt_thresh)\n",
    "print(\"Decision Tree\")\n",
    "print(f\"Precision: {adjusted_precision:.4f}\")\n",
    "print(f\"Recall: {adjusted_recall:.4f}\")\n",
    "print(f\"Ensemble accuracy: {adjusted_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {adjusted_f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9653e844-4196-4d63-9b61-4998f3dba2d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:16:31.430303Z",
     "iopub.status.busy": "2024-09-25T07:16:31.430194Z",
     "iopub.status.idle": "2024-09-25T07:16:31.887853Z",
     "shell.execute_reply": "2024-09-25T07:16:31.886193Z",
     "shell.execute_reply.started": "2024-09-25T07:16:31.430294Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated cells count: 4\n"
     ]
    }
   ],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '4-1!B6:E6'  \n",
    "\n",
    "values = [[\n",
    "    f\"{adjusted_precision * 100:.2f}\",\n",
    "    f\"{adjusted_recall * 100:.2f}\",\n",
    "    f\"{adjusted_accuracy * 100:.2f}\",\n",
    "    f\"{adjusted_f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24614471-4cf3-4349-b8bb-98715c2db8a9",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f5a4d67-5a7a-4f32-b9c4-6f5c7612a256",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:16:31.893291Z",
     "iopub.status.busy": "2024-09-25T07:16:31.892407Z",
     "iopub.status.idle": "2024-09-25T07:16:31.917740Z",
     "shell.execute_reply": "2024-09-25T07:16:31.916500Z",
     "shell.execute_reply.started": "2024-09-25T07:16:31.893256Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "Precision: 0.8275921833701633\n",
      "Recall: 0.8253564313478675\n",
      "Ensemble accuracy: 0.8241525423728814\n",
      "F1 Score: 0.826186768001253\n",
      "Confusion Matrix:\n",
      "[[394  65   1]\n",
      " [ 72 376  43]\n",
      " [  5  63 397]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "precision = precision_score(y_test, svm_final_predictions, average='macro')\n",
    "recall = recall_score(y_test, svm_final_predictions, average='macro')\n",
    "accuracy = accuracy_score(y_test, svm_final_predictions)\n",
    "f1 = f1_score(y_test, svm_final_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_test, svm_final_predictions)\n",
    "\n",
    "print(\"SVM\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Ensemble accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f4bf24f-5e38-4acf-b0d1-c42ddb5a862f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:16:31.919306Z",
     "iopub.status.busy": "2024-09-25T07:16:31.919067Z",
     "iopub.status.idle": "2024-09-25T07:16:31.960023Z",
     "shell.execute_reply": "2024-09-25T07:16:31.959673Z",
     "shell.execute_reply.started": "2024-09-25T07:16:31.919285Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized thresholds for each class: [0.14522214373579767, 0.42119295394355516, 0.5100039263429087]\n",
      "SVM\n",
      "Precision: 0.8201\n",
      "Recall: 0.8022\n",
      "Ensemble accuracy: 0.8030\n",
      "F1 Score: 0.806287587411107\n",
      "Confusion Matrix:\n",
      "[[333 126   1]\n",
      " [ 42 406  43]\n",
      " [  5  62 398]]\n"
     ]
    }
   ],
   "source": [
    "probabilities = svm_meta_classifier.predict_proba(test_meta_features)\n",
    "\n",
    "# Calculate precision-recall curve and find optimal thresholds for each class\n",
    "svm_thresh = []\n",
    "for i in range(probabilities.shape[1]):  # Iterate over each class\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test == i, probabilities[:, i])\n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "    optimal_idx = np.nanargmax(f1_scores)  # Handle cases where precision and recall are both zero\n",
    "    svm_thresh.append(thresholds[optimal_idx])\n",
    "\n",
    "# Apply the optimized thresholds to make adjusted predictions\n",
    "adjusted_predictions = np.array([np.argmax([probabilities[i, j] if probabilities[i, j] >= svm_thresh[j] else 0\n",
    "                                         for j in range(probabilities.shape[1])])\n",
    "                              for i in range(len(probabilities))])\n",
    "\n",
    "# Evaluate\n",
    "adjusted_precision = precision_score(y_test, adjusted_predictions, average='macro')\n",
    "adjusted_recall = recall_score(y_test, adjusted_predictions, average='macro')\n",
    "adjusted_accuracy = accuracy_score(y_test, adjusted_predictions)\n",
    "adjusted_f1 = f1_score(y_test, adjusted_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_test, adjusted_predictions)\n",
    "\n",
    "print(\"Optimized thresholds for each class:\", svm_thresh)\n",
    "print(\"SVM\")\n",
    "print(f\"Precision: {adjusted_precision:.4f}\")\n",
    "print(f\"Recall: {adjusted_recall:.4f}\")\n",
    "print(f\"Ensemble accuracy: {adjusted_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {adjusted_f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "92382252-0d77-45d8-bb20-8c5c7f2a983b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:16:31.960633Z",
     "iopub.status.busy": "2024-09-25T07:16:31.960534Z",
     "iopub.status.idle": "2024-09-25T07:16:32.473369Z",
     "shell.execute_reply": "2024-09-25T07:16:32.472186Z",
     "shell.execute_reply.started": "2024-09-25T07:16:31.960625Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated cells count: 4\n"
     ]
    }
   ],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '4-1!B7:E7'  \n",
    "\n",
    "values = [[\n",
    "    f\"{adjusted_precision * 100:.2f}\",\n",
    "    f\"{adjusted_recall * 100:.2f}\",\n",
    "    f\"{adjusted_accuracy * 100:.2f}\",\n",
    "    f\"{adjusted_f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0143f6-14c3-431a-b08b-7f182a0c7c96",
   "metadata": {},
   "source": [
    "## TEST DATA C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a7c1fca-bf56-43cf-8559-e8acfd5dc262",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:16:32.476738Z",
     "iopub.status.busy": "2024-09-25T07:16:32.475933Z",
     "iopub.status.idle": "2024-09-25T07:16:55.423346Z",
     "shell.execute_reply": "2024-09-25T07:16:55.422963Z",
     "shell.execute_reply.started": "2024-09-25T07:16:32.476697Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Load validation data\n",
    "validation_file_path = 'Corpus/FiReCS/FiReCS_data_c.csv'\n",
    "validation_df = pd.read_csv(validation_file_path)\n",
    "\n",
    "X_val = validation_df['review'].values \n",
    "y_val = validation_df['label'].values\n",
    "\n",
    "# Generate meta-features for data c dataset\n",
    "val_meta_features = get_predictions(model_info, X_val, y_val, device) \n",
    "\n",
    "# Predict using the logistic regression meta-classifier\n",
    "val_lr_predictions = lr_meta_classifier.predict(val_meta_features)\n",
    "\n",
    "# Predict using the naive bayes meta-classifier\n",
    "val_nb_predictions = nb_meta_classifier.predict(val_meta_features)\n",
    "\n",
    "# Predict using the decision tree meta-classifier\n",
    "val_dt_predictions = dt_meta_classifier.predict(val_meta_features)\n",
    "\n",
    "# Predict using the svm meta-classifier\n",
    "val_svm_predictions = svm_meta_classifier.predict(val_meta_features)\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0693ac-17b2-4645-be71-fe4c1f337e38",
   "metadata": {},
   "source": [
    "### LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5303f868-1507-4252-9f50-136aa337f630",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:16:55.423826Z",
     "iopub.status.busy": "2024-09-25T07:16:55.423744Z",
     "iopub.status.idle": "2024-09-25T07:16:55.428732Z",
     "shell.execute_reply": "2024-09-25T07:16:55.428504Z",
     "shell.execute_reply.started": "2024-09-25T07:16:55.423819Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on HS-Data C Dataset\n",
      "Precision: 0.8073078368959546\n",
      "Recall: 0.8024954852599263\n",
      "Accuracy: 0.8017159199237369\n",
      "F1 Score: 0.8041957308433526\n",
      "Confusion Matrix:\n",
      "[[266  72   3]\n",
      " [ 48 276  40]\n",
      " [  2  43 299]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the predictions\n",
    "precision = precision_score(y_val, val_lr_predictions, average='macro')\n",
    "recall = recall_score(y_val, val_lr_predictions, average='macro')\n",
    "accuracy = accuracy_score(y_val, val_lr_predictions)\n",
    "f1 = f1_score(y_val, val_lr_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_val, val_lr_predictions)\n",
    "\n",
    "print(\"Evaluation on HS-Data C Dataset\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d732e24d-540c-4934-a359-e7098db0eaaf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:16:55.429172Z",
     "iopub.status.busy": "2024-09-25T07:16:55.429105Z",
     "iopub.status.idle": "2024-09-25T07:16:55.436883Z",
     "shell.execute_reply": "2024-09-25T07:16:55.436637Z",
     "shell.execute_reply.started": "2024-09-25T07:16:55.429166Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results\n",
      "Precision: 0.8047\n",
      "Recall: 0.8029\n",
      "Accuracy: 0.8017\n",
      "F1 Score: 0.8036\n",
      "Confusion Matrix:\n",
      "[[272  64   5]\n",
      " [ 54 270  40]\n",
      " [  3  42 299]]\n"
     ]
    }
   ],
   "source": [
    "lr_validation_probabilities = lr_meta_classifier.predict_proba(val_meta_features)\n",
    "\n",
    "# Apply thresholds to the validation set probabilities to make final predictions\n",
    "lr_validation_predictions = np.array([np.argmax([lr_validation_probabilities[i, j] if lr_validation_probabilities[i, j] >= lr_thresh[j] else 0\n",
    "                                              for j in range(lr_validation_probabilities.shape[1])])\n",
    "                                   for i in range(len(lr_validation_probabilities))])\n",
    "\n",
    "# Evaluate threshold on validation set\n",
    "adjusted_precision = precision_score(y_val, lr_validation_predictions, average='macro')\n",
    "adjusted_recall = recall_score(y_val, lr_validation_predictions, average='macro')\n",
    "adjusted_accuracy = accuracy_score(y_val, lr_validation_predictions)\n",
    "adjusted_f1 = f1_score(y_val, lr_validation_predictions, average='macro')\n",
    "adjusted_conf_matrix = confusion_matrix(y_val, lr_validation_predictions)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Validation Results\")\n",
    "print(f\"Precision: {adjusted_precision:.4f}\")\n",
    "print(f\"Recall: {adjusted_recall:.4f}\")\n",
    "print(f\"Accuracy: {adjusted_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {adjusted_f1:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(adjusted_conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "35d847f4-0bc4-4f4f-a1ff-22d5d990820f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:16:55.437253Z",
     "iopub.status.busy": "2024-09-25T07:16:55.437190Z",
     "iopub.status.idle": "2024-09-25T07:16:55.922528Z",
     "shell.execute_reply": "2024-09-25T07:16:55.921113Z",
     "shell.execute_reply.started": "2024-09-25T07:16:55.437247Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated cells count: 4\n"
     ]
    }
   ],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '4-1!F4:I4'  \n",
    "\n",
    "values = [[\n",
    "    f\"{adjusted_precision * 100:.2f}\",\n",
    "    f\"{adjusted_recall * 100:.2f}\",\n",
    "    f\"{adjusted_accuracy * 100:.2f}\",\n",
    "    f\"{adjusted_f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d20e88-5a01-4b56-ad36-37c984d10277",
   "metadata": {},
   "source": [
    "#### Save CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3ca78187-3e76-4798-b348-64b200b29eb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:16:55.925371Z",
     "iopub.status.busy": "2024-09-25T07:16:55.924752Z",
     "iopub.status.idle": "2024-09-25T07:16:56.146451Z",
     "shell.execute_reply": "2024-09-25T07:16:56.146203Z",
     "shell.execute_reply.started": "2024-09-25T07:16:55.925334Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-ed3151d23a154a28a10f6cb4efe2ff39.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-ed3151d23a154a28a10f6cb4efe2ff39.vega-embed details,\n",
       "  #altair-viz-ed3151d23a154a28a10f6cb4efe2ff39.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-ed3151d23a154a28a10f6cb4efe2ff39\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-ed3151d23a154a28a10f6cb4efe2ff39\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-ed3151d23a154a28a10f6cb4efe2ff39\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"rect\"}, \"encoding\": {\"color\": {\"field\": \"Count\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"True\", \"type\": \"ordinal\"}, {\"field\": \"Predicted\", \"type\": \"ordinal\"}, {\"field\": \"Count\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Predicted\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}, \"y\": {\"field\": \"True\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}}, \"title\": \"OF_Using_FIRE 4STK-1 LR\"}, {\"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"middle\", \"fontSize\": 12}, \"encoding\": {\"color\": {\"condition\": {\"test\": \"(datum.Count > 149.5)\", \"value\": \"white\"}, \"value\": \"black\"}, \"text\": {\"field\": \"Count\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"True\", \"type\": \"ordinal\"}, {\"field\": \"Predicted\", \"type\": \"ordinal\"}, {\"field\": \"Count\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Predicted\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}, \"y\": {\"field\": \"True\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}}, \"title\": \"OF_Using_FIRE 4STK-1 LR\"}], \"data\": {\"name\": \"data-8f008137b98747bde20ab5ac358552d2\"}, \"height\": 300, \"width\": 400, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-8f008137b98747bde20ab5ac358552d2\": [{\"True\": \"Negative\", \"Predicted\": \"Negative\", \"Count\": 272}, {\"True\": \"Neutral\", \"Predicted\": \"Negative\", \"Count\": 54}, {\"True\": \"Positive\", \"Predicted\": \"Negative\", \"Count\": 3}, {\"True\": \"Negative\", \"Predicted\": \"Neutral\", \"Count\": 64}, {\"True\": \"Neutral\", \"Predicted\": \"Neutral\", \"Count\": 270}, {\"True\": \"Positive\", \"Predicted\": \"Neutral\", \"Count\": 42}, {\"True\": \"Negative\", \"Predicted\": \"Positive\", \"Count\": 5}, {\"True\": \"Neutral\", \"Predicted\": \"Positive\", \"Count\": 40}, {\"True\": \"Positive\", \"Predicted\": \"Positive\", \"Count\": 299}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import altair as alt\n",
    "import altair_saver\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_val, lr_validation_predictions)\n",
    "\n",
    "# Define class names\n",
    "class_names = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "# Convert confusion matrix to DataFrame\n",
    "cm_df = pd.DataFrame(cm, index=class_names, columns=class_names).reset_index().melt(id_vars='index')\n",
    "cm_df.columns = ['True', 'Predicted', 'Count']\n",
    "\n",
    "# Ensure the order of categories\n",
    "cm_df['True'] = pd.Categorical(cm_df['True'], categories=class_names, ordered=True)\n",
    "cm_df['Predicted'] = pd.Categorical(cm_df['Predicted'], categories=class_names, ordered=True)\n",
    "\n",
    "# Create the Altair plot\n",
    "heatmap = alt.Chart(cm_df).mark_rect().encode(\n",
    "    x=alt.X('Predicted:O', sort=class_names),\n",
    "    y=alt.Y('True:O', sort=class_names),\n",
    "    color='Count:Q',\n",
    "    tooltip=['True', 'Predicted', 'Count']\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=300,\n",
    "    title='OF_Using_FIRE 4STK-1 LR'\n",
    ")\n",
    "\n",
    "# Add text labels\n",
    "text = heatmap.mark_text(\n",
    "    align='center',\n",
    "    baseline='middle',\n",
    "    fontSize=12\n",
    ").encode(\n",
    "    text='Count:Q',\n",
    "    color=alt.condition(\n",
    "        alt.datum.Count > cm.max() / 2,\n",
    "        alt.value('white'),\n",
    "        alt.value('black')\n",
    "    )\n",
    ")\n",
    "\n",
    "# Combine heatmap and text\n",
    "final_chart = heatmap + text\n",
    "\n",
    "# Display the plot\n",
    "final_chart.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4018e7ba-2de6-44d9-9a6f-bf13ccb33108",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:16:56.146958Z",
     "iopub.status.busy": "2024-09-25T07:16:56.146890Z",
     "iopub.status.idle": "2024-09-25T07:16:56.650297Z",
     "shell.execute_reply": "2024-09-25T07:16:56.650030Z",
     "shell.execute_reply.started": "2024-09-25T07:16:56.146951Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to Results/Ensemble Model Results/On FireCS dataset/OF Using FIRE ENSEMBLE/Stacking/OF_Using_FIRE 4STK-1 LR.png\n"
     ]
    }
   ],
   "source": [
    "# Specify the folder path\n",
    "folder_path = os.path.expanduser('Results/Ensemble Model Results/On FireCS dataset/OF Using FIRE ENSEMBLE/Stacking/')\n",
    "\n",
    "# Save the plot using vl-convert\n",
    "file_path_png = os.path.join(folder_path, 'OF_Using_FIRE 4STK-1 LR.png')\n",
    "final_chart.save(file_path_png)\n",
    "\n",
    "print(f\"Plot saved to {file_path_png}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e3bc0f-597f-47e3-ba99-5d9cafd1aea3",
   "metadata": {},
   "source": [
    "### NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0af5051f-834f-4646-afef-37bfdfdc43d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:16:56.650904Z",
     "iopub.status.busy": "2024-09-25T07:16:56.650805Z",
     "iopub.status.idle": "2024-09-25T07:16:56.655524Z",
     "shell.execute_reply": "2024-09-25T07:16:56.655318Z",
     "shell.execute_reply.started": "2024-09-25T07:16:56.650896Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on HS-Data C Dataset\n",
      "Precision: 0.8025095852213315\n",
      "Recall: 0.7944900498351362\n",
      "Accuracy: 0.7940896091515729\n",
      "F1 Score: 0.7968316260429851\n",
      "Confusion Matrix:\n",
      "[[255  83   3]\n",
      " [ 45 279  40]\n",
      " [  2  43 299]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the predictions\n",
    "precision = precision_score(y_val, val_nb_predictions, average='macro')\n",
    "recall = recall_score(y_val, val_nb_predictions, average='macro')\n",
    "accuracy = accuracy_score(y_val, val_nb_predictions)\n",
    "f1 = f1_score(y_val, val_nb_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_val, val_nb_predictions)\n",
    "\n",
    "print(\"Evaluation on HS-Data C Dataset\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d1acd42b-ca2c-40be-b90e-e7fb7f6eeb2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:16:56.655885Z",
     "iopub.status.busy": "2024-09-25T07:16:56.655822Z",
     "iopub.status.idle": "2024-09-25T07:16:56.663077Z",
     "shell.execute_reply": "2024-09-25T07:16:56.662849Z",
     "shell.execute_reply.started": "2024-09-25T07:16:56.655879Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results\n",
      "Precision: 0.8122\n",
      "Recall: 0.8117\n",
      "Accuracy: 0.8103\n",
      "F1 Score: 0.8120\n",
      "Confusion Matrix:\n",
      "[[282  56   3]\n",
      " [ 55 269  40]\n",
      " [  3  42 299]]\n"
     ]
    }
   ],
   "source": [
    "nb_validation_probabilities = nb_meta_classifier.predict_proba(val_meta_features)\n",
    "\n",
    "# Apply thresholds to the validation set probabilities to make final predictions\n",
    "nb_validation_predictions = np.array([np.argmax([nb_validation_probabilities[i, j] if nb_validation_probabilities[i, j] >= nb_thresh[j] else 0\n",
    "                                              for j in range(nb_validation_probabilities.shape[1])])\n",
    "                                   for i in range(len(nb_validation_probabilities))])\n",
    "\n",
    "# Evaluate threshold on validation set\n",
    "adjusted_precision = precision_score(y_val, nb_validation_predictions, average='macro')\n",
    "adjusted_recall = recall_score(y_val, nb_validation_predictions, average='macro')\n",
    "adjusted_accuracy = accuracy_score(y_val, nb_validation_predictions)\n",
    "adjusted_f1 = f1_score(y_val, nb_validation_predictions, average='macro')\n",
    "adjusted_conf_matrix = confusion_matrix(y_val, nb_validation_predictions)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Validation Results\")\n",
    "print(f\"Precision: {adjusted_precision:.4f}\")\n",
    "print(f\"Recall: {adjusted_recall:.4f}\")\n",
    "print(f\"Accuracy: {adjusted_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {adjusted_f1:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(adjusted_conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fe5b7918-e4a2-4fd5-bfc3-74bb308a085b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:16:56.663422Z",
     "iopub.status.busy": "2024-09-25T07:16:56.663361Z",
     "iopub.status.idle": "2024-09-25T07:16:56.994999Z",
     "shell.execute_reply": "2024-09-25T07:16:56.993765Z",
     "shell.execute_reply.started": "2024-09-25T07:16:56.663416Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated cells count: 4\n"
     ]
    }
   ],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '4-1!F5:I5'  \n",
    "\n",
    "values = [[\n",
    "    f\"{adjusted_precision * 100:.2f}\",\n",
    "    f\"{adjusted_recall * 100:.2f}\",\n",
    "    f\"{adjusted_accuracy * 100:.2f}\",\n",
    "    f\"{adjusted_f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65529983-86a3-4c32-b155-c08fcdf20b31",
   "metadata": {},
   "source": [
    "#### Save CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ea993771-7e1b-4a65-8e32-29912f2564d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:16:56.998159Z",
     "iopub.status.busy": "2024-09-25T07:16:56.997188Z",
     "iopub.status.idle": "2024-09-25T07:16:57.049875Z",
     "shell.execute_reply": "2024-09-25T07:16:57.049345Z",
     "shell.execute_reply.started": "2024-09-25T07:16:56.998122Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-1534f84241a54c5fb6b36f668e57c925.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-1534f84241a54c5fb6b36f668e57c925.vega-embed details,\n",
       "  #altair-viz-1534f84241a54c5fb6b36f668e57c925.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-1534f84241a54c5fb6b36f668e57c925\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-1534f84241a54c5fb6b36f668e57c925\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-1534f84241a54c5fb6b36f668e57c925\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"rect\"}, \"encoding\": {\"color\": {\"field\": \"Count\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"True\", \"type\": \"ordinal\"}, {\"field\": \"Predicted\", \"type\": \"ordinal\"}, {\"field\": \"Count\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Predicted\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}, \"y\": {\"field\": \"True\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}}, \"title\": \"OF_Using_FIRE 4STK-1 NB\"}, {\"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"middle\", \"fontSize\": 12}, \"encoding\": {\"color\": {\"condition\": {\"test\": \"(datum.Count > 149.5)\", \"value\": \"white\"}, \"value\": \"black\"}, \"text\": {\"field\": \"Count\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"True\", \"type\": \"ordinal\"}, {\"field\": \"Predicted\", \"type\": \"ordinal\"}, {\"field\": \"Count\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Predicted\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}, \"y\": {\"field\": \"True\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}}, \"title\": \"OF_Using_FIRE 4STK-1 NB\"}], \"data\": {\"name\": \"data-15b0428ed068a0b21f589af5a06ab92c\"}, \"height\": 300, \"width\": 400, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-15b0428ed068a0b21f589af5a06ab92c\": [{\"True\": \"Negative\", \"Predicted\": \"Negative\", \"Count\": 282}, {\"True\": \"Neutral\", \"Predicted\": \"Negative\", \"Count\": 55}, {\"True\": \"Positive\", \"Predicted\": \"Negative\", \"Count\": 3}, {\"True\": \"Negative\", \"Predicted\": \"Neutral\", \"Count\": 56}, {\"True\": \"Neutral\", \"Predicted\": \"Neutral\", \"Count\": 269}, {\"True\": \"Positive\", \"Predicted\": \"Neutral\", \"Count\": 42}, {\"True\": \"Negative\", \"Predicted\": \"Positive\", \"Count\": 3}, {\"True\": \"Neutral\", \"Predicted\": \"Positive\", \"Count\": 40}, {\"True\": \"Positive\", \"Predicted\": \"Positive\", \"Count\": 299}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import altair as alt\n",
    "import altair_saver\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_val, nb_validation_predictions)\n",
    "\n",
    "# Define class names\n",
    "class_names = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "# Convert confusion matrix to DataFrame\n",
    "cm_df = pd.DataFrame(cm, index=class_names, columns=class_names).reset_index().melt(id_vars='index')\n",
    "cm_df.columns = ['True', 'Predicted', 'Count']\n",
    "\n",
    "# Ensure the order of categories\n",
    "cm_df['True'] = pd.Categorical(cm_df['True'], categories=class_names, ordered=True)\n",
    "cm_df['Predicted'] = pd.Categorical(cm_df['Predicted'], categories=class_names, ordered=True)\n",
    "\n",
    "# Create the Altair plot\n",
    "heatmap = alt.Chart(cm_df).mark_rect().encode(\n",
    "    x=alt.X('Predicted:O', sort=class_names),\n",
    "    y=alt.Y('True:O', sort=class_names),\n",
    "    color='Count:Q',\n",
    "    tooltip=['True', 'Predicted', 'Count']\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=300,\n",
    "    title='OF_Using_FIRE 4STK-1 NB'\n",
    ")\n",
    "\n",
    "# Add text labels\n",
    "text = heatmap.mark_text(\n",
    "    align='center',\n",
    "    baseline='middle',\n",
    "    fontSize=12\n",
    ").encode(\n",
    "    text='Count:Q',\n",
    "    color=alt.condition(\n",
    "        alt.datum.Count > cm.max() / 2,\n",
    "        alt.value('white'),\n",
    "        alt.value('black')\n",
    "    )\n",
    ")\n",
    "\n",
    "# Combine heatmap and text\n",
    "final_chart = heatmap + text\n",
    "\n",
    "# Display the plot\n",
    "final_chart.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "031b9ce6-7d92-4735-a298-e8f7812ebae0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:16:57.050591Z",
     "iopub.status.busy": "2024-09-25T07:16:57.050478Z",
     "iopub.status.idle": "2024-09-25T07:16:57.098069Z",
     "shell.execute_reply": "2024-09-25T07:16:57.097625Z",
     "shell.execute_reply.started": "2024-09-25T07:16:57.050580Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to Results/Ensemble Model Results/On FireCS dataset/OF Using FIRE ENSEMBLE/Stacking/OF_Using_FIRE 4STK-1 NB.png\n"
     ]
    }
   ],
   "source": [
    "# Specify the folder path\n",
    "folder_path = os.path.expanduser('Results/Ensemble Model Results/On FireCS dataset/OF Using FIRE ENSEMBLE/Stacking/')\n",
    "\n",
    "# Save the plot using vl-convert\n",
    "file_path_png = os.path.join(folder_path, 'OF_Using_FIRE 4STK-1 NB.png')\n",
    "final_chart.save(file_path_png)\n",
    "\n",
    "print(f\"Plot saved to {file_path_png}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba2269b-62c4-43d2-8394-9aa3c1a27678",
   "metadata": {},
   "source": [
    "### DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0448f107-62d6-4f1a-8b04-4378b79f3d3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:16:57.098760Z",
     "iopub.status.busy": "2024-09-25T07:16:57.098658Z",
     "iopub.status.idle": "2024-09-25T07:16:57.104585Z",
     "shell.execute_reply": "2024-09-25T07:16:57.104301Z",
     "shell.execute_reply.started": "2024-09-25T07:16:57.098752Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on HS-Data C Dataset\n",
      "Precision: 0.7943999669004324\n",
      "Recall: 0.7896344715549518\n",
      "Accuracy: 0.7893231649189705\n",
      "F1 Score: 0.7913948660345519\n",
      "Confusion Matrix:\n",
      "[[260  72   9]\n",
      " [ 53 280  31]\n",
      " [ 15  41 288]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the predictions\n",
    "precision = precision_score(y_val, val_dt_predictions, average='macro')\n",
    "recall = recall_score(y_val, val_dt_predictions, average='macro')\n",
    "accuracy = accuracy_score(y_val, val_dt_predictions)\n",
    "f1 = f1_score(y_val, val_dt_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_val, val_dt_predictions)\n",
    "\n",
    "print(\"Evaluation on HS-Data C Dataset\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9a0f105d-eb8f-4450-9d41-d90c97cf028c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:16:57.105174Z",
     "iopub.status.busy": "2024-09-25T07:16:57.105080Z",
     "iopub.status.idle": "2024-09-25T07:16:57.114665Z",
     "shell.execute_reply": "2024-09-25T07:16:57.114436Z",
     "shell.execute_reply.started": "2024-09-25T07:16:57.105166Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results\n",
      "Precision: 0.7944\n",
      "Recall: 0.7896\n",
      "Accuracy: 0.7893\n",
      "F1 Score: 0.7914\n",
      "Confusion Matrix:\n",
      "[[260  72   9]\n",
      " [ 53 280  31]\n",
      " [ 15  41 288]]\n"
     ]
    }
   ],
   "source": [
    "dt_validation_probabilities = dt_meta_classifier.predict_proba(val_meta_features)\n",
    "\n",
    "# Apply thresholds to the validation set probabilities to make final predictions\n",
    "dt_validation_predictions = np.array([np.argmax([dt_validation_probabilities[i, j] if dt_validation_probabilities[i, j] >= dt_thresh[j] else 0\n",
    "                                              for j in range(dt_validation_probabilities.shape[1])])\n",
    "                                   for i in range(len(dt_validation_probabilities))])\n",
    "\n",
    "# Evaluate threshold on validation set\n",
    "adjusted_precision = precision_score(y_val, dt_validation_predictions, average='macro')\n",
    "adjusted_recall = recall_score(y_val, dt_validation_predictions, average='macro')\n",
    "adjusted_accuracy = accuracy_score(y_val, dt_validation_predictions)\n",
    "adjusted_f1 = f1_score(y_val, dt_validation_predictions, average='macro')\n",
    "adjusted_conf_matrix = confusion_matrix(y_val, dt_validation_predictions)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Validation Results\")\n",
    "print(f\"Precision: {adjusted_precision:.4f}\")\n",
    "print(f\"Recall: {adjusted_recall:.4f}\")\n",
    "print(f\"Accuracy: {adjusted_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {adjusted_f1:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(adjusted_conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dec85bf2-3044-4247-90ec-703089be962b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:16:57.115245Z",
     "iopub.status.busy": "2024-09-25T07:16:57.115124Z",
     "iopub.status.idle": "2024-09-25T07:16:57.662220Z",
     "shell.execute_reply": "2024-09-25T07:16:57.660851Z",
     "shell.execute_reply.started": "2024-09-25T07:16:57.115237Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated cells count: 4\n"
     ]
    }
   ],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '4-1!F6:I6'  \n",
    "\n",
    "values = [[\n",
    "    f\"{adjusted_precision * 100:.2f}\",\n",
    "    f\"{adjusted_recall * 100:.2f}\",\n",
    "    f\"{adjusted_accuracy * 100:.2f}\",\n",
    "    f\"{adjusted_f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8589d71-c489-4214-9c56-4a3a7ed69506",
   "metadata": {},
   "source": [
    "#### Save CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bb07bbd3-2021-4e16-8b59-3908f095b7cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:16:57.664717Z",
     "iopub.status.busy": "2024-09-25T07:16:57.664187Z",
     "iopub.status.idle": "2024-09-25T07:16:57.717135Z",
     "shell.execute_reply": "2024-09-25T07:16:57.716719Z",
     "shell.execute_reply.started": "2024-09-25T07:16:57.664645Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-37fb648786f64762b2679931d4617407.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-37fb648786f64762b2679931d4617407.vega-embed details,\n",
       "  #altair-viz-37fb648786f64762b2679931d4617407.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-37fb648786f64762b2679931d4617407\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-37fb648786f64762b2679931d4617407\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-37fb648786f64762b2679931d4617407\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"rect\"}, \"encoding\": {\"color\": {\"field\": \"Count\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"True\", \"type\": \"ordinal\"}, {\"field\": \"Predicted\", \"type\": \"ordinal\"}, {\"field\": \"Count\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Predicted\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}, \"y\": {\"field\": \"True\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}}, \"title\": \"OF_Using_FIRE 4STK-1 DT\"}, {\"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"middle\", \"fontSize\": 12}, \"encoding\": {\"color\": {\"condition\": {\"test\": \"(datum.Count > 144.0)\", \"value\": \"white\"}, \"value\": \"black\"}, \"text\": {\"field\": \"Count\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"True\", \"type\": \"ordinal\"}, {\"field\": \"Predicted\", \"type\": \"ordinal\"}, {\"field\": \"Count\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Predicted\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}, \"y\": {\"field\": \"True\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}}, \"title\": \"OF_Using_FIRE 4STK-1 DT\"}], \"data\": {\"name\": \"data-2d42ed9d6182fad2a7fc2cae964f9537\"}, \"height\": 300, \"width\": 400, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-2d42ed9d6182fad2a7fc2cae964f9537\": [{\"True\": \"Negative\", \"Predicted\": \"Negative\", \"Count\": 260}, {\"True\": \"Neutral\", \"Predicted\": \"Negative\", \"Count\": 53}, {\"True\": \"Positive\", \"Predicted\": \"Negative\", \"Count\": 15}, {\"True\": \"Negative\", \"Predicted\": \"Neutral\", \"Count\": 72}, {\"True\": \"Neutral\", \"Predicted\": \"Neutral\", \"Count\": 280}, {\"True\": \"Positive\", \"Predicted\": \"Neutral\", \"Count\": 41}, {\"True\": \"Negative\", \"Predicted\": \"Positive\", \"Count\": 9}, {\"True\": \"Neutral\", \"Predicted\": \"Positive\", \"Count\": 31}, {\"True\": \"Positive\", \"Predicted\": \"Positive\", \"Count\": 288}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import altair as alt\n",
    "import altair_saver\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_val, dt_validation_predictions)\n",
    "\n",
    "# Define class names\n",
    "class_names = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "# Convert confusion matrix to DataFrame\n",
    "cm_df = pd.DataFrame(cm, index=class_names, columns=class_names).reset_index().melt(id_vars='index')\n",
    "cm_df.columns = ['True', 'Predicted', 'Count']\n",
    "\n",
    "# Ensure the order of categories\n",
    "cm_df['True'] = pd.Categorical(cm_df['True'], categories=class_names, ordered=True)\n",
    "cm_df['Predicted'] = pd.Categorical(cm_df['Predicted'], categories=class_names, ordered=True)\n",
    "\n",
    "# Create the Altair plot\n",
    "heatmap = alt.Chart(cm_df).mark_rect().encode(\n",
    "    x=alt.X('Predicted:O', sort=class_names),\n",
    "    y=alt.Y('True:O', sort=class_names),\n",
    "    color='Count:Q',\n",
    "    tooltip=['True', 'Predicted', 'Count']\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=300,\n",
    "    title='OF_Using_FIRE 4STK-1 DT'\n",
    ")\n",
    "\n",
    "# Add text labels\n",
    "text = heatmap.mark_text(\n",
    "    align='center',\n",
    "    baseline='middle',\n",
    "    fontSize=12\n",
    ").encode(\n",
    "    text='Count:Q',\n",
    "    color=alt.condition(\n",
    "        alt.datum.Count > cm.max() / 2,\n",
    "        alt.value('white'),\n",
    "        alt.value('black')\n",
    "    )\n",
    ")\n",
    "\n",
    "# Combine heatmap and text\n",
    "final_chart = heatmap + text\n",
    "\n",
    "# Display the plot\n",
    "final_chart.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5445e621-6288-4a87-9e75-bf4511b2d9a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:16:57.717812Z",
     "iopub.status.busy": "2024-09-25T07:16:57.717714Z",
     "iopub.status.idle": "2024-09-25T07:16:57.763790Z",
     "shell.execute_reply": "2024-09-25T07:16:57.763290Z",
     "shell.execute_reply.started": "2024-09-25T07:16:57.717803Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to Results/Ensemble Model Results/On FireCS dataset/OF Using FIRE ENSEMBLE/Stacking/OF_Using_FIRE 4STK-1 DT.png\n"
     ]
    }
   ],
   "source": [
    "# Specify the folder path\n",
    "folder_path = os.path.expanduser('Results/Ensemble Model Results/On FireCS dataset/OF Using FIRE ENSEMBLE/Stacking/')\n",
    "\n",
    "# Save the plot using vl-convert\n",
    "file_path_png = os.path.join(folder_path, 'OF_Using_FIRE 4STK-1 DT.png')\n",
    "final_chart.save(file_path_png)\n",
    "\n",
    "print(f\"Plot saved to {file_path_png}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6165ef-d0ff-4230-9fdb-3c6a774d728f",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "660f90df-3de4-41b1-9fc6-4285133ec0a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:16:57.764466Z",
     "iopub.status.busy": "2024-09-25T07:16:57.764364Z",
     "iopub.status.idle": "2024-09-25T07:16:57.770405Z",
     "shell.execute_reply": "2024-09-25T07:16:57.770077Z",
     "shell.execute_reply.started": "2024-09-25T07:16:57.764458Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on HS-Data C Dataset\n",
      "Precision: 0.8169426066707034\n",
      "Recall: 0.8131416907673472\n",
      "Accuracy: 0.8122020972354623\n",
      "F1 Score: 0.8147093849296737\n",
      "Confusion Matrix:\n",
      "[[277  62   2]\n",
      " [ 52 278  34]\n",
      " [  2  45 297]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the predictions\n",
    "precision = precision_score(y_val, val_svm_predictions, average='macro')\n",
    "recall = recall_score(y_val, val_svm_predictions, average='macro')\n",
    "accuracy = accuracy_score(y_val, val_svm_predictions)\n",
    "f1 = f1_score(y_val, val_svm_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_val, val_svm_predictions)\n",
    "\n",
    "print(\"Evaluation on HS-Data C Dataset\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ad2fba87-04de-46b7-bc1d-1fbf7d1bb263",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:16:57.770844Z",
     "iopub.status.busy": "2024-09-25T07:16:57.770768Z",
     "iopub.status.idle": "2024-09-25T07:16:57.790909Z",
     "shell.execute_reply": "2024-09-25T07:16:57.790539Z",
     "shell.execute_reply.started": "2024-09-25T07:16:57.770833Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results\n",
      "Precision: 0.8161\n",
      "Recall: 0.7950\n",
      "Accuracy: 0.7960\n",
      "F1 Score: 0.7989\n",
      "Confusion Matrix:\n",
      "[[236 103   2]\n",
      " [ 28 302  34]\n",
      " [  3  44 297]]\n"
     ]
    }
   ],
   "source": [
    "svm_validation_probabilities = svm_meta_classifier.predict_proba(val_meta_features)\n",
    "\n",
    "# Apply thresholds to the validation set probabilities to make final predictions\n",
    "svm_validation_predictions = np.array([np.argmax([svm_validation_probabilities[i, j] if svm_validation_probabilities[i, j] >= svm_thresh[j] else 0\n",
    "                                              for j in range(svm_validation_probabilities.shape[1])])\n",
    "                                   for i in range(len(svm_validation_probabilities))])\n",
    "\n",
    "# Evaluate threshold on validation set\n",
    "adjusted_precision = precision_score(y_val, svm_validation_predictions, average='macro')\n",
    "adjusted_recall = recall_score(y_val, svm_validation_predictions, average='macro')\n",
    "adjusted_accuracy = accuracy_score(y_val, svm_validation_predictions)\n",
    "adjusted_f1 = f1_score(y_val, svm_validation_predictions, average='macro')\n",
    "adjusted_conf_matrix = confusion_matrix(y_val, svm_validation_predictions)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Validation Results\")\n",
    "print(f\"Precision: {adjusted_precision:.4f}\")\n",
    "print(f\"Recall: {adjusted_recall:.4f}\")\n",
    "print(f\"Accuracy: {adjusted_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {adjusted_f1:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(adjusted_conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7644868d-4140-415e-be20-4db4bfbf21b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:16:57.791436Z",
     "iopub.status.busy": "2024-09-25T07:16:57.791366Z",
     "iopub.status.idle": "2024-09-25T07:16:58.175267Z",
     "shell.execute_reply": "2024-09-25T07:16:58.173780Z",
     "shell.execute_reply.started": "2024-09-25T07:16:57.791427Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated cells count: 4\n"
     ]
    }
   ],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '4-1!F7:I7'  \n",
    "\n",
    "values = [[\n",
    "    f\"{adjusted_precision * 100:.2f}\",\n",
    "    f\"{adjusted_recall * 100:.2f}\",\n",
    "    f\"{adjusted_accuracy * 100:.2f}\",\n",
    "    f\"{adjusted_f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682be1a4-7bf8-4e44-9da2-2b7f48eac91c",
   "metadata": {},
   "source": [
    "#### Save CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "939272d5-856b-49da-99a2-4a25d818d2ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:16:58.178371Z",
     "iopub.status.busy": "2024-09-25T07:16:58.177614Z",
     "iopub.status.idle": "2024-09-25T07:16:58.230675Z",
     "shell.execute_reply": "2024-09-25T07:16:58.230282Z",
     "shell.execute_reply.started": "2024-09-25T07:16:58.178338Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-984ae0061fc54cbc9597b4291885baa3.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-984ae0061fc54cbc9597b4291885baa3.vega-embed details,\n",
       "  #altair-viz-984ae0061fc54cbc9597b4291885baa3.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-984ae0061fc54cbc9597b4291885baa3\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-984ae0061fc54cbc9597b4291885baa3\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-984ae0061fc54cbc9597b4291885baa3\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"rect\"}, \"encoding\": {\"color\": {\"field\": \"Count\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"True\", \"type\": \"ordinal\"}, {\"field\": \"Predicted\", \"type\": \"ordinal\"}, {\"field\": \"Count\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Predicted\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}, \"y\": {\"field\": \"True\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}}, \"title\": \"OF_Using_FIRE 4STK-1 SVM\"}, {\"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"middle\", \"fontSize\": 12}, \"encoding\": {\"color\": {\"condition\": {\"test\": \"(datum.Count > 151.0)\", \"value\": \"white\"}, \"value\": \"black\"}, \"text\": {\"field\": \"Count\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"True\", \"type\": \"ordinal\"}, {\"field\": \"Predicted\", \"type\": \"ordinal\"}, {\"field\": \"Count\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Predicted\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}, \"y\": {\"field\": \"True\", \"sort\": [\"Negative\", \"Neutral\", \"Positive\"], \"type\": \"ordinal\"}}, \"title\": \"OF_Using_FIRE 4STK-1 SVM\"}], \"data\": {\"name\": \"data-18165b85cd99fee261946de92f07f9f0\"}, \"height\": 300, \"width\": 400, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-18165b85cd99fee261946de92f07f9f0\": [{\"True\": \"Negative\", \"Predicted\": \"Negative\", \"Count\": 236}, {\"True\": \"Neutral\", \"Predicted\": \"Negative\", \"Count\": 28}, {\"True\": \"Positive\", \"Predicted\": \"Negative\", \"Count\": 3}, {\"True\": \"Negative\", \"Predicted\": \"Neutral\", \"Count\": 103}, {\"True\": \"Neutral\", \"Predicted\": \"Neutral\", \"Count\": 302}, {\"True\": \"Positive\", \"Predicted\": \"Neutral\", \"Count\": 44}, {\"True\": \"Negative\", \"Predicted\": \"Positive\", \"Count\": 2}, {\"True\": \"Neutral\", \"Predicted\": \"Positive\", \"Count\": 34}, {\"True\": \"Positive\", \"Predicted\": \"Positive\", \"Count\": 297}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import altair as alt\n",
    "import altair_saver\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_val, svm_validation_predictions)\n",
    "\n",
    "# Define class names\n",
    "class_names = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "# Convert confusion matrix to DataFrame\n",
    "cm_df = pd.DataFrame(cm, index=class_names, columns=class_names).reset_index().melt(id_vars='index')\n",
    "cm_df.columns = ['True', 'Predicted', 'Count']\n",
    "\n",
    "# Ensure the order of categories\n",
    "cm_df['True'] = pd.Categorical(cm_df['True'], categories=class_names, ordered=True)\n",
    "cm_df['Predicted'] = pd.Categorical(cm_df['Predicted'], categories=class_names, ordered=True)\n",
    "\n",
    "# Create the Altair plot\n",
    "heatmap = alt.Chart(cm_df).mark_rect().encode(\n",
    "    x=alt.X('Predicted:O', sort=class_names),\n",
    "    y=alt.Y('True:O', sort=class_names),\n",
    "    color='Count:Q',\n",
    "    tooltip=['True', 'Predicted', 'Count']\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=300,\n",
    "    title='OF_Using_FIRE 4STK-1 SVM'\n",
    ")\n",
    "\n",
    "# Add text labels\n",
    "text = heatmap.mark_text(\n",
    "    align='center',\n",
    "    baseline='middle',\n",
    "    fontSize=12\n",
    ").encode(\n",
    "    text='Count:Q',\n",
    "    color=alt.condition(\n",
    "        alt.datum.Count > cm.max() / 2,\n",
    "        alt.value('white'),\n",
    "        alt.value('black')\n",
    "    )\n",
    ")\n",
    "\n",
    "# Combine heatmap and text\n",
    "final_chart = heatmap + text\n",
    "\n",
    "# Display the plot\n",
    "final_chart.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4ab1dbec-94d8-4f9c-b5e8-843b853a71cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:16:58.231313Z",
     "iopub.status.busy": "2024-09-25T07:16:58.231217Z",
     "iopub.status.idle": "2024-09-25T07:16:58.275417Z",
     "shell.execute_reply": "2024-09-25T07:16:58.274964Z",
     "shell.execute_reply.started": "2024-09-25T07:16:58.231304Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to Results/Ensemble Model Results/On FireCS dataset/OF Using FIRE ENSEMBLE/Stacking/OF_Using_FIRE 4STK-1 SVM.png\n"
     ]
    }
   ],
   "source": [
    "# Specify the folder path\n",
    "folder_path = os.path.expanduser('Results/Ensemble Model Results/On FireCS dataset/OF Using FIRE ENSEMBLE/Stacking/')\n",
    "\n",
    "# Save the plot using vl-convert\n",
    "file_path_png = os.path.join(folder_path, 'OF_Using_FIRE 4STK-1 SVM.png')\n",
    "final_chart.save(file_path_png)\n",
    "\n",
    "print(f\"Plot saved to {file_path_png}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a298f212-36ec-4e75-ad74-d7b272d094a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80391c9f-64d7-4e98-b9f0-6ee41cb035f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
