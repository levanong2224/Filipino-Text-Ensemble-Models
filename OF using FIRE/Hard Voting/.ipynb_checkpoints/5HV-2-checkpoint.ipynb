{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rAnJPEXtfyAH"
   },
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T14:01:51.895209Z",
     "iopub.status.busy": "2024-08-27T14:01:51.894974Z",
     "iopub.status.idle": "2024-08-27T14:01:52.021934Z",
     "shell.execute_reply": "2024-08-27T14:01:52.021692Z",
     "shell.execute_reply.started": "2024-08-27T14:01:51.895187Z"
    }
   },
   "outputs": [],
   "source": [
    "# This automates data tabulation onto google sheets \n",
    "\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "import os\n",
    "\n",
    "# new directory path\n",
    "new_directory = '/Users/levan/ATENEO MASTERAL/Thesis'\n",
    "\n",
    "# Change the current working directory\n",
    "os.chdir(new_directory)\n",
    "\n",
    "# Use creds to create a client to interact with the Google Drive API\n",
    "scope = ['https://spreadsheets.google.com/feeds','https://www.googleapis.com/auth/drive']\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_name('thesis-432315-12daec8d1ff6.json', scope)\n",
    "\n",
    "service = build('sheets', 'v4', credentials=creds)\n",
    "\n",
    "client = gspread.authorize(creds)\n",
    "\n",
    "spreadsheet_id = '13Fk5oXX9B_mdHmNpMKQMy29y9iiHWrgQCa4hUTiQKD0' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "huMwc5Rqej4Z"
   },
   "source": [
    "# Hard Voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T14:01:52.022366Z",
     "iopub.status.busy": "2024-08-27T14:01:52.022280Z",
     "iopub.status.idle": "2024-08-27T14:01:52.024478Z",
     "shell.execute_reply": "2024-08-27T14:01:52.024131Z",
     "shell.execute_reply.started": "2024-08-27T14:01:52.022358Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Specify the new directory path\n",
    "new_directory = '/Users/levan/ATENEO MASTERAL/Thesis/Development'\n",
    "\n",
    "# Change the current working directory\n",
    "os.chdir(new_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-08-27T14:01:52.025095Z",
     "iopub.status.busy": "2024-08-27T14:01:52.024979Z",
     "iopub.status.idle": "2024-08-27T14:01:53.649042Z",
     "shell.execute_reply": "2024-08-27T14:01:53.648802Z",
     "shell.execute_reply.started": "2024-08-27T14:01:52.025089Z"
    },
    "executionInfo": {
     "elapsed": 8623,
     "status": "ok",
     "timestamp": 1711542962088,
     "user": {
      "displayName": "LEONARD EVAN ONG",
      "userId": "13738954157101619104"
     },
     "user_tz": -480
    },
    "id": "sem7dvIrhBcS",
    "outputId": "a4b45244-dbd0-44d7-a7e6-06c6ef54678b"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AutoConfig\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "file_path = 'Corpus/FiReCS/FiReCS_data_b.csv'\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "num_labels = df['label'].nunique()\n",
    "\n",
    "# Split the data into training and test sets (70-30 split)\n",
    "train_df, test_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "\n",
    "# Extract texts and labels\n",
    "train_texts = train_df['review'].tolist()\n",
    "train_labels = train_df['label'].tolist()\n",
    "\n",
    "test_texts = test_df['review'].tolist()\n",
    "test_labels = test_df['label'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Models and Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T14:01:53.649552Z",
     "iopub.status.busy": "2024-08-27T14:01:53.649486Z",
     "iopub.status.idle": "2024-08-27T14:01:57.715264Z",
     "shell.execute_reply": "2024-08-27T14:01:57.714898Z",
     "shell.execute_reply.started": "2024-08-27T14:01:53.649545Z"
    },
    "executionInfo": {
     "elapsed": 8097,
     "status": "ok",
     "timestamp": 1711543494761,
     "user": {
      "displayName": "LEONARD EVAN ONG",
      "userId": "13738954157101619104"
     },
     "user_tz": -480
    },
    "id": "WJA7YA-s0ZoY"
   },
   "outputs": [],
   "source": [
    "def load_model_and_tokenizer(model_path, tokenizer_path, base_model):\n",
    "    # Load the tokenizer from the local directory\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "    \n",
    "    # Load the model configuration dynamically based on num_labels\n",
    "    config = AutoConfig.from_pretrained(base_model, num_labels=num_labels)\n",
    "\n",
    "    # Initialize the model with the configuration\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_path, config=config)\n",
    "\n",
    "    # Ensure the model is in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    return model, tokenizer\n",
    "\n",
    "model_info = {\n",
    "\n",
    "    'DistilBERT cased': {\n",
    "        'model_path': 'BERT models/1 FiReCS/fire_distilbert-base-cased-finetuned',\n",
    "        'tokenizer_path': 'BERT models/1 FiReCS/fire_distilbert-base-cased-finetuned',\n",
    "        'base_model': 'distilbert/distilbert-base-cased'\n",
    "    },\n",
    "\n",
    "    'DeBERTa': {\n",
    "        'model_path': 'BERT models/1 FiReCS/fire_DeBERTa-finetuned',\n",
    "        'tokenizer_path': 'BERT models/1 FiReCS/fire_DeBERTa-finetuned',\n",
    "        'base_model': 'microsoft/deberta-v3-base'\n",
    "    },\n",
    "\n",
    "    'HateBERT': {\n",
    "        'model_path': 'BERT models/1 FiReCS/fire_HateBERT-finetuned',\n",
    "        'tokenizer_path': 'BERT models/1 FiReCS/fire_HateBERT-finetuned',\n",
    "        'base_model': 'GroNLP/hateBERT'\n",
    "    },\n",
    "\n",
    "    'BERT cased': {\n",
    "        'model_path': 'BERT models/1 FiReCS/fire_bert-base-cased-finetuned',\n",
    "        'tokenizer_path': 'BERT models/1 FiReCS/fire_bert-base-cased-finetuned',\n",
    "        'base_model': 'google-bert/bert-base-cased'\n",
    "    },\n",
    "\n",
    "    'Roberta Tag cased': {\n",
    "        'model_path': 'BERT models/1 FiReCS/fire_Tag-Roberta-finetuned',\n",
    "        'tokenizer_path': 'BERT models/1 FiReCS/fire_Tag-Roberta-finetuned',\n",
    "        'base_model': 'jcblaise/roberta-tagalog-base'\n",
    "    },\n",
    "    \n",
    "}\n",
    "\n",
    "models_and_tokenizers = {name: load_model_and_tokenizer(info['model_path'], \n",
    "                                                        info['tokenizer_path'], \n",
    "                                                        info['base_model'],\n",
    "                                                        ) \n",
    "                         for name, info in model_info.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T14:01:57.716011Z",
     "iopub.status.busy": "2024-08-27T14:01:57.715872Z",
     "iopub.status.idle": "2024-08-27T14:01:57.718562Z",
     "shell.execute_reply": "2024-08-27T14:01:57.718204Z",
     "shell.execute_reply.started": "2024-08-27T14:01:57.715952Z"
    }
   },
   "outputs": [],
   "source": [
    "def texts_to_dataloader(texts, tokenizer, batch_size=32):\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    encodings = tokenizer(texts, truncation=True, padding=True, max_length=512, return_tensors=\"pt\")\n",
    "\n",
    "    # Move tensors to the specified device\n",
    "    input_ids = encodings['input_ids'].to(device)\n",
    "    attention_mask = encodings['attention_mask'].to(device)\n",
    "    \n",
    "    dataset = TensorDataset(encodings['input_ids'], encodings['attention_mask'])\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Hard Voting and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T14:01:57.720602Z",
     "iopub.status.busy": "2024-08-27T14:01:57.720463Z",
     "iopub.status.idle": "2024-08-27T14:01:57.725388Z",
     "shell.execute_reply": "2024-08-27T14:01:57.724995Z",
     "shell.execute_reply.started": "2024-08-27T14:01:57.720590Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-08-27T14:01:57.725888Z",
     "iopub.status.busy": "2024-08-27T14:01:57.725794Z",
     "iopub.status.idle": "2024-08-27T14:02:30.633069Z",
     "shell.execute_reply": "2024-08-27T14:02:30.632726Z",
     "shell.execute_reply.started": "2024-08-27T14:01:57.725881Z"
    },
    "executionInfo": {
     "elapsed": 597765,
     "status": "ok",
     "timestamp": 1711544099100,
     "user": {
      "displayName": "LEONARD EVAN ONG",
      "userId": "13738954157101619104"
     },
     "user_tz": -480
    },
    "id": "BJBwRQqX5cGz",
    "outputId": "e75bd4e5-ea47-4f7f-9727-5b479b46d2e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 2768.83 MiB, increment: 0.00 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "\n",
    "def hard_voting_predict(models_and_tokenizers, texts):\n",
    "    votes = []\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    \n",
    "    # Loop through each model and its corresponding tokenizer\n",
    "    for name, (model, tokenizer) in models_and_tokenizers.items():\n",
    "        # Explicitly move each model to the MPS device if available\n",
    "        model.to(device)\n",
    "        \n",
    "        dataloader = texts_to_dataloader(texts, tokenizer)\n",
    "        model_preds = []\n",
    "        for batch in dataloader:\n",
    "            input_ids, attention_mask = batch\n",
    "            input_ids, attention_mask = input_ids.to(device), attention_mask.to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                preds = torch.argmax(outputs.logits, dim=-1)\n",
    "                model_preds.extend(preds.cpu().numpy())\n",
    "        votes.append(model_preds)\n",
    "\n",
    "    # Transpose to get lists of votes per sample\n",
    "    votes = np.array(votes).T  \n",
    "    # Perform voting\n",
    "    final_preds = []\n",
    "    for vote in votes:\n",
    "        vote_count = np.bincount(vote)\n",
    "        max_votes = np.max(vote_count)\n",
    "        candidates = np.where(vote_count == max_votes)[0]  # find all classes with the maximum votes\n",
    "        if len(candidates) > 1:\n",
    "            final_preds.append(random.choice(candidates))  # randomly choose among the candidates\n",
    "        else:\n",
    "            final_preds.append(candidates[0])  # choose the single candidate\n",
    "    return final_preds\n",
    "\n",
    "\n",
    "# Perform inference and voting\n",
    "final_predictions = hard_voting_predict(models_and_tokenizers, test_texts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-08-27T14:02:30.633708Z",
     "iopub.status.busy": "2024-08-27T14:02:30.633626Z",
     "iopub.status.idle": "2024-08-27T14:02:30.642586Z",
     "shell.execute_reply": "2024-08-27T14:02:30.642312Z",
     "shell.execute_reply.started": "2024-08-27T14:02:30.633700Z"
    },
    "executionInfo": {
     "elapsed": 353,
     "status": "ok",
     "timestamp": 1711544865406,
     "user": {
      "displayName": "LEONARD EVAN ONG",
      "userId": "13738954157101619104"
     },
     "user_tz": -480
    },
    "id": "kfOa-DfAAvim",
    "outputId": "4f0a53a2-b147-49bc-ade9-efd21112bff2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7522485690923958\n",
      "Recall: 0.8048993875765529\n",
      "Ensemble accuracy: 0.7890092258323306\n",
      "F1 Score: 0.7776838546069316\n",
      "Confusion Matrix:\n",
      "[[1047  303]\n",
      " [ 223  920]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Calculate precision, recall, accuracy, and F1 score\n",
    "precision = precision_score(test_labels, final_predictions, average='macro')  # Adjust 'macro' as needed\n",
    "recall = recall_score(test_labels, final_predictions, average='macro')  # Adjust 'macro' as needed\n",
    "accuracy = accuracy_score(test_labels, final_predictions)  # Use the original test_labels list\n",
    "f1 = f1_score(test_labels, final_predictions, average='macro')  # Adjust 'macro' as needed\n",
    "\n",
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, final_predictions)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Ensemble accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T14:02:30.643136Z",
     "iopub.status.busy": "2024-08-27T14:02:30.643058Z",
     "iopub.status.idle": "2024-08-27T14:02:31.391533Z",
     "shell.execute_reply": "2024-08-27T14:02:31.390358Z",
     "shell.execute_reply.started": "2024-08-27T14:02:30.643131Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated cells count: 4\n"
     ]
    }
   ],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '5-2!B2:E2'  \n",
    "\n",
    "values = [[\n",
    "    f\"{precision * 100:.2f}\",\n",
    "    f\"{recall * 100:.2f}\",\n",
    "    f\"{accuracy * 100:.2f}\",\n",
    "    f\"{f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate on Data C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T14:02:31.393554Z",
     "iopub.status.busy": "2024-08-27T14:02:31.393215Z",
     "iopub.status.idle": "2024-08-27T14:02:31.408386Z",
     "shell.execute_reply": "2024-08-27T14:02:31.407654Z",
     "shell.execute_reply.started": "2024-08-27T14:02:31.393524Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Load validation data\n",
    "validation_file_path = 'Corpus/FiReCS/FiReCS_data_c.csv'\n",
    "validation_df = pd.read_csv(validation_file_path)\n",
    "\n",
    "num_labels = validation_df['label'].nunique()\n",
    "\n",
    "# Prepare the validation texts and labels\n",
    "validation_texts = validation_df['review'].tolist()\n",
    "validation_labels = validation_df['label'].values  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Hard Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T14:02:31.409868Z",
     "iopub.status.busy": "2024-08-27T14:02:31.409452Z",
     "iopub.status.idle": "2024-08-27T14:03:02.601096Z",
     "shell.execute_reply": "2024-08-27T14:03:02.600737Z",
     "shell.execute_reply.started": "2024-08-27T14:02:31.409846Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1048.19 MiB, increment: 189.62 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "# Perform inference and voting on the validation texts\n",
    "validation_predictions = hard_voting_predict(models_and_tokenizers, validation_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T14:03:02.601740Z",
     "iopub.status.busy": "2024-08-27T14:03:02.601652Z",
     "iopub.status.idle": "2024-08-27T14:03:02.608197Z",
     "shell.execute_reply": "2024-08-27T14:03:02.607986Z",
     "shell.execute_reply.started": "2024-08-27T14:03:02.601732Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7610810810810811\n",
      "Recall: 0.8186046511627907\n",
      "Accuracy: 0.7958852192744992\n",
      "F1 Score: 0.7887955182072829\n",
      "Confusion Matrix:\n",
      "[[766 221]\n",
      " [156 704]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate precision, recall, accuracy, and F1 score\n",
    "precision = precision_score(validation_labels, validation_predictions, average='macro')  \n",
    "recall = recall_score(validation_labels, validation_predictions, average='macro')  \n",
    "accuracy = accuracy_score(validation_labels, validation_predictions)\n",
    "f1 = f1_score(validation_labels, validation_predictions, average='macro')  \n",
    "\n",
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(validation_labels, validation_predictions)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T14:03:02.608620Z",
     "iopub.status.busy": "2024-08-27T14:03:02.608552Z",
     "iopub.status.idle": "2024-08-27T14:03:03.007049Z",
     "shell.execute_reply": "2024-08-27T14:03:03.005763Z",
     "shell.execute_reply.started": "2024-08-27T14:03:02.608614Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated cells count: 4\n"
     ]
    }
   ],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '5-2!F2:I2'  \n",
    "\n",
    "values = [[\n",
    "    f\"{precision * 100:.2f}\",\n",
    "    f\"{recall * 100:.2f}\",\n",
    "    f\"{accuracy * 100:.2f}\",\n",
    "    f\"{f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T14:03:03.008701Z",
     "iopub.status.busy": "2024-08-27T14:03:03.008431Z",
     "iopub.status.idle": "2024-08-27T14:03:03.176954Z",
     "shell.execute_reply": "2024-08-27T14:03:03.176701Z",
     "shell.execute_reply.started": "2024-08-27T14:03:03.008677Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-46bb16669a2a4565a0586ab6153db8ed.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-46bb16669a2a4565a0586ab6153db8ed.vega-embed details,\n",
       "  #altair-viz-46bb16669a2a4565a0586ab6153db8ed.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-46bb16669a2a4565a0586ab6153db8ed\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-46bb16669a2a4565a0586ab6153db8ed\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-46bb16669a2a4565a0586ab6153db8ed\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"rect\"}, \"encoding\": {\"color\": {\"field\": \"Count\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"True\", \"type\": \"ordinal\"}, {\"field\": \"Predicted\", \"type\": \"ordinal\"}, {\"field\": \"Count\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Predicted\", \"sort\": [\"Hate Speech\", \"Non Hatespeech\"], \"type\": \"ordinal\"}, \"y\": {\"field\": \"True\", \"sort\": [\"Hate Speech\", \"Non Hatespeech\"], \"type\": \"ordinal\"}}, \"title\": \"5 Hard Voting-2\"}, {\"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"middle\", \"fontSize\": 12}, \"encoding\": {\"color\": {\"condition\": {\"test\": \"(datum.Count > 383.0)\", \"value\": \"white\"}, \"value\": \"black\"}, \"text\": {\"field\": \"Count\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"True\", \"type\": \"ordinal\"}, {\"field\": \"Predicted\", \"type\": \"ordinal\"}, {\"field\": \"Count\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Predicted\", \"sort\": [\"Hate Speech\", \"Non Hatespeech\"], \"type\": \"ordinal\"}, \"y\": {\"field\": \"True\", \"sort\": [\"Hate Speech\", \"Non Hatespeech\"], \"type\": \"ordinal\"}}, \"title\": \"5 Hard Voting-2\"}], \"data\": {\"name\": \"data-285f229623bd4bc0f01795c868d32a1b\"}, \"height\": 300, \"width\": 400, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-285f229623bd4bc0f01795c868d32a1b\": [{\"True\": \"Hate Speech\", \"Predicted\": \"Hate Speech\", \"Count\": 766}, {\"True\": \"Non Hatespeech\", \"Predicted\": \"Hate Speech\", \"Count\": 156}, {\"True\": \"Hate Speech\", \"Predicted\": \"Non Hatespeech\", \"Count\": 221}, {\"True\": \"Non Hatespeech\", \"Predicted\": \"Non Hatespeech\", \"Count\": 704}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import altair as alt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(validation_labels, validation_predictions)\n",
    "\n",
    "# Define class names\n",
    "class_names = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "# Convert confusion matrix to DataFrame\n",
    "cm_df = pd.DataFrame(cm, index=class_names, columns=class_names).reset_index().melt(id_vars='index')\n",
    "cm_df.columns = ['True', 'Predicted', 'Count']\n",
    "\n",
    "# Ensure the order of categories\n",
    "cm_df['True'] = pd.Categorical(cm_df['True'], categories=class_names, ordered=True)\n",
    "cm_df['Predicted'] = pd.Categorical(cm_df['Predicted'], categories=class_names, ordered=True)\n",
    "\n",
    "# Create the Altair plot\n",
    "heatmap = alt.Chart(cm_df).mark_rect().encode(\n",
    "    x=alt.X('Predicted:O', sort=class_names),\n",
    "    y=alt.Y('True:O', sort=class_names),\n",
    "    color='Count:Q',\n",
    "    tooltip=['True', 'Predicted', 'Count']\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=300,\n",
    "    title='OF_Using_FIRE 5HV-2'\n",
    ")\n",
    "\n",
    "# Add text labels\n",
    "text = heatmap.mark_text(\n",
    "    align='center',\n",
    "    baseline='middle',\n",
    "    fontSize=12\n",
    ").encode(\n",
    "    text='Count:Q',\n",
    "    color=alt.condition(\n",
    "        alt.datum.Count > cm.max() / 2,\n",
    "        alt.value('white'),\n",
    "        alt.value('black')\n",
    "    )\n",
    ")\n",
    "\n",
    "# Combine heatmap and text\n",
    "final_chart = heatmap + text\n",
    "\n",
    "# Display the plot\n",
    "final_chart.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T14:03:03.177532Z",
     "iopub.status.busy": "2024-08-27T14:03:03.177428Z",
     "iopub.status.idle": "2024-08-27T14:03:03.585514Z",
     "shell.execute_reply": "2024-08-27T14:03:03.585264Z",
     "shell.execute_reply.started": "2024-08-27T14:03:03.177525Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to Results/Ensemble Model Results/On Hatespeech dataset/OH Using HS_Finetuned Models/Hard Voting/5HV-2.png\n"
     ]
    }
   ],
   "source": [
    "# Specify the folder path\n",
    "folder_path = os.path.expanduser('Results/Ensemble Model Results/On FireCS dataset/OF Using FIRE ENSEMBLE/Hard Voting/')\n",
    "\n",
    "# Save the plot using vl-convert\n",
    "file_path_png = os.path.join(folder_path, 'OF_Using_FIRE 5HV-2.png')\n",
    "final_chart.save(file_path_png)\n",
    "\n",
    "print(f\"Plot saved to {file_path_png}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOelzqcxikjHNiyC4eC309U",
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0638df159ea540faae91dfa869dd2569": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ef14f76cfd8d43dfbe7ee25186cc759d",
      "placeholder": "​",
      "style": "IPY_MODEL_98b190a34515469c8018d8ea86ef64e9",
      "value": "config.json: 100%"
     }
    },
    "18ca60da34f74f01877b9cdd4f9e7b3f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2152101fab2c4bcdb6de728e2727e8ab",
      "max": 604,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_86388af23c6b444599df0eccfcd09aeb",
      "value": 604
     }
    },
    "2152101fab2c4bcdb6de728e2727e8ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6e37394538a842949cb0eac6ba4b715e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "86388af23c6b444599df0eccfcd09aeb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "98b190a34515469c8018d8ea86ef64e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b2bd860e5a134a4c824f1351502cd420": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6e37394538a842949cb0eac6ba4b715e",
      "placeholder": "​",
      "style": "IPY_MODEL_f04b6c43b7f0487ca4998f083cecac63",
      "value": " 604/604 [00:00&lt;00:00, 45.8kB/s]"
     }
    },
    "cd6b3893819949d6b46c44d4f34e1d44": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e3eb10c00acc4167b879e893e7784d80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0638df159ea540faae91dfa869dd2569",
       "IPY_MODEL_18ca60da34f74f01877b9cdd4f9e7b3f",
       "IPY_MODEL_b2bd860e5a134a4c824f1351502cd420"
      ],
      "layout": "IPY_MODEL_cd6b3893819949d6b46c44d4f34e1d44"
     }
    },
    "ef14f76cfd8d43dfbe7ee25186cc759d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f04b6c43b7f0487ca4998f083cecac63": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
