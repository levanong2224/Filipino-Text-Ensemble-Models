{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rAnJPEXtfyAH"
   },
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-04-11T16:57:44.210833Z",
     "iopub.status.busy": "2024-04-11T16:57:44.210752Z",
     "iopub.status.idle": "2024-04-11T16:57:45.126923Z",
     "shell.execute_reply": "2024-04-11T16:57:45.126234Z",
     "shell.execute_reply.started": "2024-04-11T16:57:44.210826Z"
    },
    "executionInfo": {
     "elapsed": 61789,
     "status": "ok",
     "timestamp": 1711541571499,
     "user": {
      "displayName": "LEONARD EVAN ONG",
      "userId": "13738954157101619104"
     },
     "user_tz": -480
    },
    "id": "lUT7AZcc1vgS",
    "outputId": "de0df3e0-048d-43ed-f146-28de1f7bf832"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/anaconda3/envs/thesis/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: transformers in /opt/anaconda3/envs/thesis/lib/python3.10/site-packages (4.39.3)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/thesis/lib/python3.10/site-packages (2.2.1)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/thesis/lib/python3.10/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/envs/thesis/lib/python3.10/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/envs/thesis/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/envs/thesis/lib/python3.10/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/thesis/lib/python3.10/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/envs/thesis/lib/python3.10/site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/anaconda3/envs/thesis/lib/python3.10/site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/envs/thesis/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/thesis/lib/python3.10/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/thesis/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/envs/thesis/lib/python3.10/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/thesis/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/anaconda3/envs/thesis/lib/python3.10/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/anaconda3/envs/thesis/lib/python3.10/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/envs/thesis/lib/python3.10/site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/thesis/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/thesis/lib/python3.10/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/thesis/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/thesis/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/thesis/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/thesis/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/thesis/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/thesis/lib/python3.10/site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/thesis/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/anaconda3/envs/thesis/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch transformers pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "huMwc5Rqej4Z"
   },
   "source": [
    "# SOFT Voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-11T16:57:45.128151Z",
     "iopub.status.busy": "2024-04-11T16:57:45.127880Z",
     "iopub.status.idle": "2024-04-11T16:57:45.130578Z",
     "shell.execute_reply": "2024-04-11T16:57:45.130246Z",
     "shell.execute_reply.started": "2024-04-11T16:57:45.128135Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Specify the new directory path\n",
    "new_directory = '/Users/levan/ATENEO MASTERAL/Thesis/Development'\n",
    "\n",
    "# Change the current working directory\n",
    "os.chdir(new_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-04-11T16:57:45.131390Z",
     "iopub.status.busy": "2024-04-11T16:57:45.131114Z",
     "iopub.status.idle": "2024-04-11T16:57:46.433316Z",
     "shell.execute_reply": "2024-04-11T16:57:46.432997Z",
     "shell.execute_reply.started": "2024-04-11T16:57:45.131380Z"
    },
    "executionInfo": {
     "elapsed": 8623,
     "status": "ok",
     "timestamp": 1711542962088,
     "user": {
      "displayName": "LEONARD EVAN ONG",
      "userId": "13738954157101619104"
     },
     "user_tz": -480
    },
    "id": "sem7dvIrhBcS",
    "outputId": "a4b45244-dbd0-44d7-a7e6-06c6ef54678b"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AutoConfig\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Adjust file paths to your local system\n",
    "file_path = 'Corpus/test_data_b.csv'\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Split the data into training and test sets (70-30 split)\n",
    "train_df, test_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "\n",
    "# Extract texts and labels\n",
    "train_texts = train_df['text'].tolist()\n",
    "train_labels = train_df['label'].tolist()\n",
    "\n",
    "test_texts = test_df['text'].tolist()\n",
    "test_labels = test_df['label'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Models and Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-11T16:57:46.433790Z",
     "iopub.status.busy": "2024-04-11T16:57:46.433710Z",
     "iopub.status.idle": "2024-04-11T16:57:53.143232Z",
     "shell.execute_reply": "2024-04-11T16:57:53.142819Z",
     "shell.execute_reply.started": "2024-04-11T16:57:46.433783Z"
    },
    "executionInfo": {
     "elapsed": 8097,
     "status": "ok",
     "timestamp": 1711543494761,
     "user": {
      "displayName": "LEONARD EVAN ONG",
      "userId": "13738954157101619104"
     },
     "user_tz": -480
    },
    "id": "WJA7YA-s0ZoY"
   },
   "outputs": [],
   "source": [
    "def load_model_and_tokenizer(model_path, tokenizer_path, base_model):\n",
    "    tokenizer = BertTokenizer.from_pretrained(tokenizer_path)\n",
    "    config = AutoConfig.from_pretrained(base_model, num_labels=2)\n",
    "    model = BertForSequenceClassification(config)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")), strict=False)\n",
    "    model.eval()\n",
    "    return model, tokenizer\n",
    "\n",
    "# Adjust paths to your models and tokenizers on your local machine\n",
    "model_info = {\n",
    "\n",
    "    'HateBERT': {\n",
    "        'model_path': 'BERT models/HateBERT-finetuned.bin',\n",
    "        'tokenizer_path': 'BERT models/HateBERT-finetuned-tokenizer',\n",
    "        'base_model': 'GroNLP/hateBERT'\n",
    "    },\n",
    "    \n",
    "    'fBERT': {\n",
    "        'model_path': 'BERT models/fBERT-finetuned.bin',\n",
    "        'tokenizer_path': 'BERT models/fBERT-finetuned-tokenizer',\n",
    "        'base_model': 'diptanu/fBERT'\n",
    "    },\n",
    "\n",
    "    'mBERT': {\n",
    "        'model_path': 'BERT models/mbert-base-uncased-finetuned.bin',\n",
    "        'tokenizer_path': 'BERT models/mbert-base-uncased-finetuned-tokenizer',\n",
    "        'base_model': 'google-bert/bert-base-multilingual-uncased'\n",
    "    }\n",
    "}\n",
    "\n",
    "models_and_tokenizers = {name: load_model_and_tokenizer(info['model_path'], info['tokenizer_path'], info['base_model']) for name, info in model_info.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-11T16:57:53.143676Z",
     "iopub.status.busy": "2024-04-11T16:57:53.143588Z",
     "iopub.status.idle": "2024-04-11T16:57:53.145856Z",
     "shell.execute_reply": "2024-04-11T16:57:53.145581Z",
     "shell.execute_reply.started": "2024-04-11T16:57:53.143667Z"
    }
   },
   "outputs": [],
   "source": [
    "def texts_to_dataloader(texts, tokenizer, batch_size=32):\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    encodings = tokenizer(texts, truncation=True, padding=True, max_length=512, return_tensors=\"pt\")\n",
    "\n",
    "    # Move tensors to the specified device\n",
    "    input_ids = encodings['input_ids'].to(device)\n",
    "    attention_mask = encodings['attention_mask'].to(device)\n",
    "    \n",
    "    dataset = TensorDataset(encodings['input_ids'], encodings['attention_mask'])\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Soft Voting and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-04-11T16:57:53.147162Z",
     "iopub.status.busy": "2024-04-11T16:57:53.147096Z",
     "iopub.status.idle": "2024-04-11T16:58:27.070528Z",
     "shell.execute_reply": "2024-04-11T16:58:27.070141Z",
     "shell.execute_reply.started": "2024-04-11T16:57:53.147157Z"
    },
    "executionInfo": {
     "elapsed": 597765,
     "status": "ok",
     "timestamp": 1711544099100,
     "user": {
      "displayName": "LEONARD EVAN ONG",
      "userId": "13738954157101619104"
     },
     "user_tz": -480
    },
    "id": "BJBwRQqX5cGz",
    "outputId": "e75bd4e5-ea47-4f7f-9727-5b479b46d2e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 2307.09 MiB, increment: -0.31 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "\n",
    "def soft_voting_predict(models_and_tokenizers, texts):\n",
    "    sum_probs = None\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    \n",
    "    # Loop through each model and its corresponding tokenizer\n",
    "    for name, (model, tokenizer) in models_and_tokenizers.items():\n",
    "        \n",
    "        # Explicitly move each model to the MPS device if available\n",
    "        model.to(device)\n",
    "        \n",
    "        dataloader = texts_to_dataloader(texts, tokenizer)\n",
    "        model_probs_list = []\n",
    "        for batch in dataloader:\n",
    "            input_ids, attention_mask = batch\n",
    "            input_ids, attention_mask = input_ids.to(device), attention_mask.to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "                model_probs_list.append(probs.cpu().numpy())\n",
    "        \n",
    "        model_probs = np.concatenate(model_probs_list)\n",
    "        \n",
    "        if sum_probs is None:\n",
    "            sum_probs = model_probs\n",
    "        else:\n",
    "            sum_probs += model_probs\n",
    "\n",
    "    # Average the probabilities\n",
    "    avg_probs = sum_probs / len(models_and_tokenizers)\n",
    "    \n",
    "    # Perform voting based on highest average probabilities\n",
    "    final_preds = np.argmax(avg_probs, axis=-1)\n",
    "    return final_preds\n",
    "\n",
    "# Perform inference and voting\n",
    "final_predictions = soft_voting_predict(models_and_tokenizers, test_texts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-04-11T16:58:27.071086Z",
     "iopub.status.busy": "2024-04-11T16:58:27.070954Z",
     "iopub.status.idle": "2024-04-11T16:58:27.079518Z",
     "shell.execute_reply": "2024-04-11T16:58:27.079267Z",
     "shell.execute_reply.started": "2024-04-11T16:58:27.071078Z"
    },
    "executionInfo": {
     "elapsed": 353,
     "status": "ok",
     "timestamp": 1711544865406,
     "user": {
      "displayName": "LEONARD EVAN ONG",
      "userId": "13738954157101619104"
     },
     "user_tz": -480
    },
    "id": "kfOa-DfAAvim",
    "outputId": "4f0a53a2-b147-49bc-ade9-efd21112bff2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8535117056856187\n",
      "Recall: 0.8523714094856379\n",
      "Ensemble accuracy: 0.8655256723716381\n",
      "F1 Score: 0.8529411764705882\n",
      "Confusion Matrix:\n",
      "[[1556  219]\n",
      " [ 221 1276]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Calculate precision, recall, accuracy, and F1 score\n",
    "precision = precision_score(test_labels, final_predictions, average='binary')  # Adjust 'binary' as needed\n",
    "recall = recall_score(test_labels, final_predictions, average='binary')  # Adjust 'binary' as needed\n",
    "accuracy = accuracy_score(test_labels, final_predictions)  # Use the original test_labels list\n",
    "f1 = f1_score(test_labels, final_predictions, average='binary')  # Adjust 'binary' as needed\n",
    "\n",
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, final_predictions)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Ensemble accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate on Data C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-11T16:58:27.080075Z",
     "iopub.status.busy": "2024-04-11T16:58:27.079985Z",
     "iopub.status.idle": "2024-04-11T16:58:27.084974Z",
     "shell.execute_reply": "2024-04-11T16:58:27.084707Z",
     "shell.execute_reply.started": "2024-04-11T16:58:27.080067Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Load validation data\n",
    "validation_file_path = 'Corpus/data_c.csv'\n",
    "validation_df = pd.read_csv(validation_file_path)\n",
    "\n",
    "\n",
    "# Prepare the validation texts and labels\n",
    "validation_texts = validation_df['text'].tolist()\n",
    "validation_labels = validation_df['label'].values  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Soft Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-11T16:58:27.085629Z",
     "iopub.status.busy": "2024-04-11T16:58:27.085504Z",
     "iopub.status.idle": "2024-04-11T16:58:48.041165Z",
     "shell.execute_reply": "2024-04-11T16:58:48.040812Z",
     "shell.execute_reply.started": "2024-04-11T16:58:27.085623Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1867.45 MiB, increment: 0.00 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "# Perform inference and voting on the validation texts\n",
    "validation_predictions = soft_voting_predict(models_and_tokenizers, validation_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-11T16:58:48.041756Z",
     "iopub.status.busy": "2024-04-11T16:58:48.041670Z",
     "iopub.status.idle": "2024-04-11T16:58:48.048078Z",
     "shell.execute_reply": "2024-04-11T16:58:48.047866Z",
     "shell.execute_reply.started": "2024-04-11T16:58:48.041746Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8567567567567568\n",
      "Recall: 0.844582593250444\n",
      "Validation accuracy: 0.8622112211221122\n",
      "F1 Score: 0.8506261180679785\n",
      "Confusion Matrix:\n",
      "[[1139  159]\n",
      " [ 175  951]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate precision, recall, accuracy, and F1 score\n",
    "precision = precision_score(validation_labels, validation_predictions, average='binary')  \n",
    "recall = recall_score(validation_labels, validation_predictions, average='binary')  \n",
    "accuracy = accuracy_score(validation_labels, validation_predictions)\n",
    "f1 = f1_score(validation_labels, validation_predictions, average='binary')  \n",
    "\n",
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(validation_labels, validation_predictions)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Validation accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOelzqcxikjHNiyC4eC309U",
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0638df159ea540faae91dfa869dd2569": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ef14f76cfd8d43dfbe7ee25186cc759d",
      "placeholder": "​",
      "style": "IPY_MODEL_98b190a34515469c8018d8ea86ef64e9",
      "value": "config.json: 100%"
     }
    },
    "18ca60da34f74f01877b9cdd4f9e7b3f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2152101fab2c4bcdb6de728e2727e8ab",
      "max": 604,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_86388af23c6b444599df0eccfcd09aeb",
      "value": 604
     }
    },
    "2152101fab2c4bcdb6de728e2727e8ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6e37394538a842949cb0eac6ba4b715e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "86388af23c6b444599df0eccfcd09aeb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "98b190a34515469c8018d8ea86ef64e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b2bd860e5a134a4c824f1351502cd420": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6e37394538a842949cb0eac6ba4b715e",
      "placeholder": "​",
      "style": "IPY_MODEL_f04b6c43b7f0487ca4998f083cecac63",
      "value": " 604/604 [00:00&lt;00:00, 45.8kB/s]"
     }
    },
    "cd6b3893819949d6b46c44d4f34e1d44": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e3eb10c00acc4167b879e893e7784d80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0638df159ea540faae91dfa869dd2569",
       "IPY_MODEL_18ca60da34f74f01877b9cdd4f9e7b3f",
       "IPY_MODEL_b2bd860e5a134a4c824f1351502cd420"
      ],
      "layout": "IPY_MODEL_cd6b3893819949d6b46c44d4f34e1d44"
     }
    },
    "ef14f76cfd8d43dfbe7ee25186cc759d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f04b6c43b7f0487ca4998f083cecac63": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
