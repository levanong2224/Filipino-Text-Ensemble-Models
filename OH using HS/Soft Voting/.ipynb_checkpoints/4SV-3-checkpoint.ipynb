{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rAnJPEXtfyAH"
   },
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-08-27T15:26:20.935387Z",
     "iopub.status.busy": "2024-08-27T15:26:20.935314Z",
     "iopub.status.idle": "2024-08-27T15:26:21.011984Z",
     "shell.execute_reply": "2024-08-27T15:26:21.011651Z",
     "shell.execute_reply.started": "2024-08-27T15:26:20.935379Z"
    },
    "executionInfo": {
     "elapsed": 61789,
     "status": "ok",
     "timestamp": 1711541571499,
     "user": {
      "displayName": "LEONARD EVAN ONG",
      "userId": "13738954157101619104"
     },
     "user_tz": -480
    },
    "id": "lUT7AZcc1vgS",
    "outputId": "de0df3e0-048d-43ed-f146-28de1f7bf832"
   },
   "outputs": [],
   "source": [
    "# This automates data tabulation onto google sheets \n",
    "\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "import os\n",
    "\n",
    "# new directory path\n",
    "new_directory = '/Users/levan/ATENEO MASTERAL/Thesis'\n",
    "\n",
    "# Change the current working directory\n",
    "os.chdir(new_directory)\n",
    "\n",
    "# Use creds to create a client to interact with the Google Drive API\n",
    "scope = ['https://spreadsheets.google.com/feeds','https://www.googleapis.com/auth/drive']\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_name('thesis-432315-12daec8d1ff6.json', scope)\n",
    "\n",
    "service = build('sheets', 'v4', credentials=creds)\n",
    "\n",
    "client = gspread.authorize(creds)\n",
    "\n",
    "spreadsheet_id = '18Hi92aObP2ST7OrpVlsH8C8j0KS05a93sDRsMN0ZFPM' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "huMwc5Rqej4Z"
   },
   "source": [
    "# SOFT Voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T15:26:21.013166Z",
     "iopub.status.busy": "2024-08-27T15:26:21.013094Z",
     "iopub.status.idle": "2024-08-27T15:26:21.014948Z",
     "shell.execute_reply": "2024-08-27T15:26:21.014722Z",
     "shell.execute_reply.started": "2024-08-27T15:26:21.013158Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Specify the new directory path\n",
    "new_directory = '/Users/levan/ATENEO MASTERAL/Thesis/Development'\n",
    "\n",
    "# Change the current working directory\n",
    "os.chdir(new_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-08-27T15:26:21.015281Z",
     "iopub.status.busy": "2024-08-27T15:26:21.015219Z",
     "iopub.status.idle": "2024-08-27T15:26:22.371501Z",
     "shell.execute_reply": "2024-08-27T15:26:22.371074Z",
     "shell.execute_reply.started": "2024-08-27T15:26:21.015274Z"
    },
    "executionInfo": {
     "elapsed": 8623,
     "status": "ok",
     "timestamp": 1711542962088,
     "user": {
      "displayName": "LEONARD EVAN ONG",
      "userId": "13738954157101619104"
     },
     "user_tz": -480
    },
    "id": "sem7dvIrhBcS",
    "outputId": "a4b45244-dbd0-44d7-a7e6-06c6ef54678b"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AutoConfig\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Adjust file paths to your local system\n",
    "file_path = 'Corpus/data_b.csv'\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Split the data into training and test sets (70-30 split)\n",
    "train_df, test_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "\n",
    "# Extract texts and labels\n",
    "train_texts = train_df['text'].tolist()\n",
    "train_labels = train_df['label'].tolist()\n",
    "\n",
    "test_texts = test_df['text'].tolist()\n",
    "test_labels = test_df['label'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Models and Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T15:26:22.372056Z",
     "iopub.status.busy": "2024-08-27T15:26:22.371978Z",
     "iopub.status.idle": "2024-08-27T15:26:26.273193Z",
     "shell.execute_reply": "2024-08-27T15:26:26.272882Z",
     "shell.execute_reply.started": "2024-08-27T15:26:22.372047Z"
    },
    "executionInfo": {
     "elapsed": 8097,
     "status": "ok",
     "timestamp": 1711543494761,
     "user": {
      "displayName": "LEONARD EVAN ONG",
      "userId": "13738954157101619104"
     },
     "user_tz": -480
    },
    "id": "WJA7YA-s0ZoY"
   },
   "outputs": [],
   "source": [
    "def load_model_and_tokenizer(model_path, tokenizer_path, base_model):\n",
    "    # Load the tokenizer from the local directory\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "    \n",
    "    # Load the configuration from the base model, then update configuration if needed\n",
    "    config = AutoConfig.from_pretrained(base_model, num_labels=2)\n",
    "\n",
    "    # Initialize the model with the configuration\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_path, config=config)\n",
    "\n",
    "    # Ensure the model is in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    return model, tokenizer\n",
    "\n",
    "model_info = {   \n",
    "    \n",
    "    'HateBERT': {\n",
    "        'model_path': 'BERT models/hs_HateBERT-finetuned',\n",
    "        'tokenizer_path': 'BERT models/hs_HateBERT-finetuned',\n",
    "        'base_model': 'GroNLP/hateBERT'\n",
    "    },\n",
    "\n",
    "    'TagBERT': {\n",
    "        'model_path': 'BERT models/hs_Tag-Roberta-finetuned',\n",
    "        'tokenizer_path': 'BERT models/hs_Tag-Roberta-finetuned',\n",
    "        'base_model': 'jcblaise/roberta-tagalog-base'\n",
    "    },\n",
    "\n",
    "    'DeBERTa': {\n",
    "        'model_path': 'BERT models/hs_DeBERTa-finetuned',\n",
    "        'tokenizer_path': 'BERT models/hs_DeBERTa-finetuned',\n",
    "        'base_model': 'microsoft/deberta-v3-base'\n",
    "    },\n",
    "\n",
    "    'DistilBERT uncased': {\n",
    "        'model_path': 'BERT models/hs_distilbert-base-uncased-finetuned',\n",
    "        'tokenizer_path': 'BERT models/hs_distilbert-base-uncased-finetuned',\n",
    "        'base_model': 'distilbert/distilbert-base-uncased'\n",
    "    },\n",
    "    \n",
    "    'fBERT': {\n",
    "        'model_path': 'BERT models/hs_fBERT-finetuned',\n",
    "        'tokenizer_path': 'BERT models/hs_fBERT-finetuned',\n",
    "        'base_model': 'diptanu/fBERT'\n",
    "    },\n",
    "\n",
    "}\n",
    "\n",
    "models_and_tokenizers = {name: load_model_and_tokenizer(info['model_path'], \n",
    "                                                        info['tokenizer_path'], \n",
    "                                                        info['base_model']) \n",
    "                         for name, info in model_info.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T15:26:26.275045Z",
     "iopub.status.busy": "2024-08-27T15:26:26.274915Z",
     "iopub.status.idle": "2024-08-27T15:26:26.277576Z",
     "shell.execute_reply": "2024-08-27T15:26:26.277283Z",
     "shell.execute_reply.started": "2024-08-27T15:26:26.275037Z"
    }
   },
   "outputs": [],
   "source": [
    "def texts_to_dataloader(texts, tokenizer, batch_size=32):\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    encodings = tokenizer(texts, truncation=True, padding=True, max_length=512, return_tensors=\"pt\")\n",
    "\n",
    "    # Move tensors to the specified device\n",
    "    input_ids = encodings['input_ids'].to(device)\n",
    "    attention_mask = encodings['attention_mask'].to(device)\n",
    "    \n",
    "    dataset = TensorDataset(encodings['input_ids'], encodings['attention_mask'])\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Soft Voting and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T15:26:26.278108Z",
     "iopub.status.busy": "2024-08-27T15:26:26.278037Z",
     "iopub.status.idle": "2024-08-27T15:26:26.281471Z",
     "shell.execute_reply": "2024-08-27T15:26:26.281149Z",
     "shell.execute_reply.started": "2024-08-27T15:26:26.278102Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-08-27T15:26:26.281903Z",
     "iopub.status.busy": "2024-08-27T15:26:26.281838Z"
    },
    "executionInfo": {
     "elapsed": 597765,
     "status": "ok",
     "timestamp": 1711544099100,
     "user": {
      "displayName": "LEONARD EVAN ONG",
      "userId": "13738954157101619104"
     },
     "user_tz": -480
    },
    "id": "BJBwRQqX5cGz",
    "outputId": "e75bd4e5-ea47-4f7f-9727-5b479b46d2e7"
   },
   "outputs": [],
   "source": [
    "%%memit\n",
    "\n",
    "def soft_voting_predict(models_and_tokenizers, texts):\n",
    "    sum_probs = None\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    \n",
    "    # Loop through each model and its corresponding tokenizer\n",
    "    for name, (model, tokenizer) in models_and_tokenizers.items():\n",
    "        \n",
    "        # Explicitly move each model to the MPS device if available\n",
    "        model.to(device)\n",
    "        \n",
    "        dataloader = texts_to_dataloader(texts, tokenizer)\n",
    "        model_probs_list = []\n",
    "        for batch in dataloader:\n",
    "            input_ids, attention_mask = batch\n",
    "            input_ids, attention_mask = input_ids.to(device), attention_mask.to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "                model_probs_list.append(probs.cpu().numpy())\n",
    "        \n",
    "        model_probs = np.concatenate(model_probs_list)\n",
    "        \n",
    "        if sum_probs is None:\n",
    "            sum_probs = model_probs\n",
    "        else:\n",
    "            sum_probs += model_probs\n",
    "\n",
    "    # Average the probabilities\n",
    "    avg_probs = sum_probs / len(models_and_tokenizers)\n",
    "    \n",
    "    # Perform voting based on highest average probabilities\n",
    "    final_preds = np.argmax(avg_probs, axis=-1)\n",
    "    return final_preds\n",
    "\n",
    "# Perform inference and voting\n",
    "final_predictions = soft_voting_predict(models_and_tokenizers, test_texts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 353,
     "status": "ok",
     "timestamp": 1711544865406,
     "user": {
      "displayName": "LEONARD EVAN ONG",
      "userId": "13738954157101619104"
     },
     "user_tz": -480
    },
    "id": "kfOa-DfAAvim",
    "outputId": "4f0a53a2-b147-49bc-ade9-efd21112bff2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Calculate precision, recall, accuracy, and F1 score\n",
    "precision = precision_score(test_labels, final_predictions, average='binary')  # Adjust 'binary' as needed\n",
    "recall = recall_score(test_labels, final_predictions, average='binary')  # Adjust 'binary' as needed\n",
    "accuracy = accuracy_score(test_labels, final_predictions)  # Use the original test_labels list\n",
    "f1 = f1_score(test_labels, final_predictions, average='binary')  # Adjust 'binary' as needed\n",
    "\n",
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, final_predictions)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Ensemble accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '5-3!B3:E3'  \n",
    "\n",
    "values = [[\n",
    "    f\"{precision * 100:.2f}\",\n",
    "    f\"{recall * 100:.2f}\",\n",
    "    f\"{accuracy * 100:.2f}\",\n",
    "    f\"{f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate on Data C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Load validation data\n",
    "validation_file_path = 'Corpus/data_c.csv'\n",
    "validation_df = pd.read_csv(validation_file_path)\n",
    "\n",
    "\n",
    "# Prepare the validation texts and labels\n",
    "validation_texts = validation_df['text'].tolist()\n",
    "validation_labels = validation_df['label'].values  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Soft Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%memit\n",
    "# Perform inference and voting on the validation texts\n",
    "validation_predictions = soft_voting_predict(models_and_tokenizers, validation_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate precision, recall, accuracy, and F1 score\n",
    "precision = precision_score(validation_labels, validation_predictions, average='binary')  \n",
    "recall = recall_score(validation_labels, validation_predictions, average='binary')  \n",
    "accuracy = accuracy_score(validation_labels, validation_predictions)\n",
    "f1 = f1_score(validation_labels, validation_predictions, average='binary')  \n",
    "\n",
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(validation_labels, validation_predictions)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Validation accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE TO GOOGLE SHEET\n",
    "\n",
    "# Define the range and values to update\n",
    "range_name = '5-3!F3:I3'  \n",
    "\n",
    "values = [[\n",
    "    f\"{precision * 100:.2f}\",\n",
    "    f\"{recall * 100:.2f}\",\n",
    "    f\"{accuracy * 100:.2f}\",\n",
    "    f\"{f1 * 100:.2f}\"\n",
    "]]\n",
    "\n",
    "# Prepare the request body\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the values\n",
    "result = service.spreadsheets().values().update(\n",
    "    spreadsheetId=spreadsheet_id, \n",
    "    range=range_name,\n",
    "    valueInputOption='USER_ENTERED',\n",
    "    body=body\n",
    ").execute()\n",
    "\n",
    "print('Updated cells count:', result.get('updatedCells'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(validation_labels, validation_predictions)\n",
    "\n",
    "# Define class names\n",
    "class_names = ['Hate Speech', 'Non Hatespeech']\n",
    "\n",
    "# Convert confusion matrix to DataFrame\n",
    "cm_df = pd.DataFrame(cm, index=class_names, columns=class_names).reset_index().melt(id_vars='index')\n",
    "cm_df.columns = ['True', 'Predicted', 'Count']\n",
    "\n",
    "# Ensure the order of categories\n",
    "cm_df['True'] = pd.Categorical(cm_df['True'], categories=class_names, ordered=True)\n",
    "cm_df['Predicted'] = pd.Categorical(cm_df['Predicted'], categories=class_names, ordered=True)\n",
    "\n",
    "# Create the Altair plot\n",
    "heatmap = alt.Chart(cm_df).mark_rect().encode(\n",
    "    x=alt.X('Predicted:O', sort=class_names),\n",
    "    y=alt.Y('True:O', sort=class_names),\n",
    "    color='Count:Q',\n",
    "    tooltip=['True', 'Predicted', 'Count']\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=300,\n",
    "    title='5 Soft Voting-3'\n",
    ")\n",
    "\n",
    "# Add text labels\n",
    "text = heatmap.mark_text(\n",
    "    align='center',\n",
    "    baseline='middle',\n",
    "    fontSize=12\n",
    ").encode(\n",
    "    text='Count:Q',\n",
    "    color=alt.condition(\n",
    "        alt.datum.Count > cm.max() / 2,\n",
    "        alt.value('white'),\n",
    "        alt.value('black')\n",
    "    )\n",
    ")\n",
    "\n",
    "# Combine heatmap and text\n",
    "final_chart = heatmap + text\n",
    "\n",
    "# Display the plot\n",
    "final_chart.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the folder path\n",
    "folder_path = os.path.expanduser('Results/Ensemble Model Results/On Hatespeech dataset/OH Using HS_Finetuned Models/Soft Voting/')\n",
    "\n",
    "# Save the plot using vl-convert\n",
    "file_path_png = os.path.join(folder_path, '5SV-3.png')\n",
    "final_chart.save(file_path_png)\n",
    "\n",
    "print(f\"Plot saved to {file_path_png}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOelzqcxikjHNiyC4eC309U",
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0638df159ea540faae91dfa869dd2569": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ef14f76cfd8d43dfbe7ee25186cc759d",
      "placeholder": "​",
      "style": "IPY_MODEL_98b190a34515469c8018d8ea86ef64e9",
      "value": "config.json: 100%"
     }
    },
    "18ca60da34f74f01877b9cdd4f9e7b3f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2152101fab2c4bcdb6de728e2727e8ab",
      "max": 604,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_86388af23c6b444599df0eccfcd09aeb",
      "value": 604
     }
    },
    "2152101fab2c4bcdb6de728e2727e8ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6e37394538a842949cb0eac6ba4b715e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "86388af23c6b444599df0eccfcd09aeb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "98b190a34515469c8018d8ea86ef64e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b2bd860e5a134a4c824f1351502cd420": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6e37394538a842949cb0eac6ba4b715e",
      "placeholder": "​",
      "style": "IPY_MODEL_f04b6c43b7f0487ca4998f083cecac63",
      "value": " 604/604 [00:00&lt;00:00, 45.8kB/s]"
     }
    },
    "cd6b3893819949d6b46c44d4f34e1d44": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e3eb10c00acc4167b879e893e7784d80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0638df159ea540faae91dfa869dd2569",
       "IPY_MODEL_18ca60da34f74f01877b9cdd4f9e7b3f",
       "IPY_MODEL_b2bd860e5a134a4c824f1351502cd420"
      ],
      "layout": "IPY_MODEL_cd6b3893819949d6b46c44d4f34e1d44"
     }
    },
    "ef14f76cfd8d43dfbe7ee25186cc759d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f04b6c43b7f0487ca4998f083cecac63": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
